{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e3a0f4c-1cfb-4a14-b8f2-fdea31c390ec",
   "metadata": {},
   "source": [
    "# NGAME training pipeline with clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddda97e8-16ac-42c7-9ad4-f981e21c0aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp 16-ngame-training-pipeline-with-clustering-3-0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f35d8be-1323-400a-b78e-d0a4d2697801",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13077b86-1326-4b43-a125-ef67bd11a70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d685e35e-9a13-4186-b7f4-b831b10086bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os,torch, torch.multiprocessing as mp\n",
    "from xcai.basics import *\n",
    "from xcai.models.MMM00X import DBT012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff71f136",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['WANDB_MODE'] = 'disabled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53768670-9905-46b0-9a6d-b6e91d50b918",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "os.environ['WANDB_PROJECT']='xc-nlg_16-ngame-training-pipeline-with-clustering-3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba38fcb0-3ebf-4f79-aa20-1a1321b791c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/ptca/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/ptca/lib/python3.9/site-packages/scipy/sparse/_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "block = XCBlock.from_cfg('/home/aiscuser/scratch/datasets', 'data', valid_pct=0.001, tfm='ng', \n",
    "                         tokenizer='sentence-transformers/msmarco-distilbert-base-v4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73b6a059-3409-4c00-a575-dcdb5775adc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "args = XCLearningArguments(\n",
    "    output_dir='/home/aiscuser/outputs/16-ngame-training-pipeline-with-clustering-3-0',\n",
    "    logging_first_step=True,\n",
    "    per_device_train_batch_size=1024,\n",
    "    per_device_eval_batch_size=64,\n",
    "    representation_num_beams=200,\n",
    "    representation_accumulation_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps=1000,\n",
    "    save_steps=1000,\n",
    "    save_total_limit=5,\n",
    "    num_train_epochs=50,\n",
    "    predict_with_representation=True,\n",
    "    label_names=['plbl2data_idx', 'plbl2data_data2ptr'],\n",
    "    target_indices_key='plbl2data_idx',\n",
    "    target_pointer_key='plbl2data_data2ptr',\n",
    "    adam_epsilon=1e-6,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    learning_rate=2e-4,\n",
    "    group_by_cluster=True,\n",
    "    num_clustering_warmup_epochs=10,\n",
    "    num_cluster_update_epochs=5,\n",
    "    num_cluster_size_update_epochs=5,\n",
    "    clustering_type='EXPO',\n",
    "    minimum_cluster_size=1,\n",
    "    maximum_cluster_size=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe151a46-83cf-4f96-9755-8beb8ff5c59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "metric = PrecRecl(block.n_lbl, block.test.data_lbl_filterer, prop=block.train.dset.data.data_lbl,\n",
    "                  pk=10, rk=200, rep_pk=[1, 3, 5, 10], rep_rk=[10, 100, 200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15f5ebfa-5262-4977-88ef-f1b29ec09597",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/ptca/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "model = DBT012.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', margin=0.3, tau=0.1, \n",
    "                               apply_softmax=True, n_negatives=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd656b48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "431b4af7-38e1-4f50-8950-9d9e0e574ddd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "learn = XCLearner(\n",
    "    model=model, \n",
    "    args=args,\n",
    "    train_dataset=block.train.dset,\n",
    "    eval_dataset=block.test.dset,\n",
    "    data_collator=block.collator,\n",
    "    compute_metrics=metric,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e84ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c8e2b6-4a55-4559-8c75-6cc36bcc5b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7826d8324f04d1cb54932e37067f201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5410 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating clusters with size 1\n",
      "Tree depth = 20\n",
      "doing random split\n",
      "lengths: [346194, 346195]\n",
      "remaining levels for GPU split=19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> gpu splitting random clusters 0 to 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " rank=0 => Total clusters 2\tAvg. Cluster size                 173097.00\tTime to split nodes on this level 0.85 sec\n",
      " rank=0 => Total clusters 4\tAvg. Cluster size                 86548.50\tTime to split nodes on this level 0.05 sec\n",
      " rank=1 => Total clusters 2\tAvg. Cluster size                 173097.50\tTime to split nodes on this level 0.69 sec\n",
      " rank=1 => Total clusters 4\tAvg. Cluster size                 86548.75\tTime to split nodes on this level 0.04 sec\n",
      " rank=0 => Total clusters 8\tAvg. Cluster size                 43274.25\tTime to split nodes on this level 0.07 sec\n",
      " rank=1 => Total clusters 8\tAvg. Cluster size                 43274.38\tTime to split nodes on this level 0.07 sec\n",
      " rank=0 => Total clusters 16\tAvg. Cluster size                 21637.12\tTime to split nodes on this level 0.08 sec\n",
      " rank=1 => Total clusters 16\tAvg. Cluster size                 21637.19\tTime to split nodes on this level 0.09 sec\n",
      " rank=0 => Total clusters 32\tAvg. Cluster size                 10818.56\tTime to split nodes on this level 0.10 sec\n",
      " rank=1 => Total clusters 32\tAvg. Cluster size                 10818.59\tTime to split nodes on this level 0.10 sec\n",
      " rank=0 => Total clusters 64\tAvg. Cluster size                 5409.28\tTime to split nodes on this level 0.14 sec\n",
      " rank=1 => Total clusters 64\tAvg. Cluster size                 5409.30\tTime to split nodes on this level 0.13 sec\n",
      " rank=0 => Total clusters 128\tAvg. Cluster size                 2704.64\tTime to split nodes on this level 0.22 sec\n",
      " rank=1 => Total clusters 128\tAvg. Cluster size                 2704.65\tTime to split nodes on this level 0.21 sec\n",
      " rank=0 => Total clusters 256\tAvg. Cluster size                 1352.32\tTime to split nodes on this level 0.45 sec\n",
      " rank=1 => Total clusters 256\tAvg. Cluster size                 1352.32\tTime to split nodes on this level 0.43 sec\n",
      " rank=1 => Total clusters 512\tAvg. Cluster size                 676.16\tTime to split nodes on this level 0.76 sec\n",
      " rank=0 => Total clusters 512\tAvg. Cluster size                 676.16\tTime to split nodes on this level 0.80 sec\n",
      " rank=1 => Total clusters 1024\tAvg. Cluster size                 338.08\tTime to split nodes on this level 1.45 sec\n",
      " rank=0 => Total clusters 1024\tAvg. Cluster size                 338.08\tTime to split nodes on this level 1.53 sec\n",
      " rank=1 => Total clusters 2048\tAvg. Cluster size                 169.04\tTime to split nodes on this level 3.10 sec\n",
      " rank=0 => Total clusters 2048\tAvg. Cluster size                 169.04\tTime to split nodes on this level 3.08 sec\n",
      " rank=0 => Total clusters 4096\tAvg. Cluster size                 84.52\tTime to split nodes on this level 5.84 sec\n",
      " rank=1 => Total clusters 4096\tAvg. Cluster size                 84.52\tTime to split nodes on this level 6.09 sec\n",
      " rank=0 => Total clusters 8192\tAvg. Cluster size                 42.26\tTime to split nodes on this level 9.28 sec\n",
      " rank=1 => Total clusters 8192\tAvg. Cluster size                 42.26\tTime to split nodes on this level 10.09 sec\n",
      " rank=0 => Total clusters 16384\tAvg. Cluster size                 21.13\tTime to split nodes on this level 11.68 sec\n",
      " rank=1 => Total clusters 16384\tAvg. Cluster size                 21.13\tTime to split nodes on this level 11.97 sec\n",
      " rank=0 => Total clusters 32768\tAvg. Cluster size                 10.57\tTime to split nodes on this level 18.74 sec\n",
      " rank=1 => Total clusters 32768\tAvg. Cluster size                 10.57\tTime to split nodes on this level 18.73 sec\n",
      " rank=0 => Total clusters 65536\tAvg. Cluster size                 5.28\tTime to split nodes on this level 36.00 sec\n",
      " rank=1 => Total clusters 65536\tAvg. Cluster size                 5.28\tTime to split nodes on this level 35.96 sec\n",
      " rank=0 => Total clusters 131072\tAvg. Cluster size                 2.64\tTime to split nodes on this level 73.35 sec\n",
      " rank=1 => Total clusters 131072\tAvg. Cluster size                 2.64\tTime to split nodes on this level 74.72 sec\n",
      " rank=0 => Total clusters 262144\tAvg. Cluster size                 1.32\tTime to split nodes on this level 148.54 sec\n",
      " rank=1 => Total clusters 262144\tAvg. Cluster size                 1.32\tTime to split nodes on this level 149.73 sec\n",
      " rank=0 => Total clusters 346194\tAvg. Cluster size                 1.00\tTime to split nodes on this level 96.97 sec\n",
      " rank=1 => Total clusters 346195\tAvg. Cluster size                 1.00\tTime to split nodes on this level 98.51 sec\n",
      "\n",
      "node-0:178939:178939 [0] NCCL INFO Bootstrap : Using eth0:10.13.41.92<0>\n",
      "node-0:178939:178939 [0] NCCL INFO NET/Plugin : Plugin load (librccl-net.so) returned 2 : librccl-net.so: cannot open shared object file: No such file or directory\n",
      "node-0:178939:178939 [0] NCCL INFO NET/Plugin : No plugin found, using internal implementation\n",
      "node-0:178939:178939 [0] NCCL INFO Kernel version: 5.15.0-1042-azure\n",
      "RCCL version 2.17.1+hip5.7 HEAD:cbbb3d8+\n",
      "\n",
      "node-0:178939:184351 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/misc/ibvwrap.cc:222 NCCL WARN Call to ibv_open_device failed\n",
      "\n",
      "node-0:178939:184351 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/transport/net_ib.cc:199 NCCL WARN NET/IB : Unable to open device mlx5_0\n",
      "\n",
      "node-0:178939:184351 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/misc/ibvwrap.cc:222 NCCL WARN Call to ibv_open_device failed\n",
      "\n",
      "node-0:178939:184351 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/transport/net_ib.cc:199 NCCL WARN NET/IB : Unable to open device mlx5_1\n",
      "\n",
      "node-0:178939:184351 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/misc/ibvwrap.cc:222 NCCL WARN Call to ibv_open_device failed\n",
      "\n",
      "node-0:178939:184351 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/transport/net_ib.cc:199 NCCL WARN NET/IB : Unable to open device mlx5_2\n",
      "\n",
      "node-0:178939:184351 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/misc/ibvwrap.cc:222 NCCL WARN Call to ibv_open_device failed\n",
      "\n",
      "node-0:178939:184351 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/transport/net_ib.cc:199 NCCL WARN NET/IB : Unable to open device mlx5_3\n",
      "\n",
      "node-0:178939:184351 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/misc/ibvwrap.cc:222 NCCL WARN Call to ibv_open_device failed\n",
      "\n",
      "node-0:178939:184351 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/transport/net_ib.cc:199 NCCL WARN NET/IB : Unable to open device mlx5_4\n",
      "\n",
      "node-0:178939:184351 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/misc/ibvwrap.cc:222 NCCL WARN Call to ibv_open_device failed\n",
      "\n",
      "node-0:178939:184351 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/transport/net_ib.cc:199 NCCL WARN NET/IB : Unable to open device mlx5_5\n",
      "\n",
      "node-0:178939:184351 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/misc/ibvwrap.cc:222 NCCL WARN Call to ibv_open_device failed\n",
      "\n",
      "node-0:178939:184351 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/transport/net_ib.cc:199 NCCL WARN NET/IB : Unable to open device mlx5_6\n",
      "\n",
      "node-0:178939:184351 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/misc/ibvwrap.cc:222 NCCL WARN Call to ibv_open_device failed\n",
      "\n",
      "node-0:178939:184351 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/transport/net_ib.cc:199 NCCL WARN NET/IB : Unable to open device mlx5_7\n",
      "node-0:178939:184351 [0] NCCL INFO NET/IB : No device found.\n",
      "node-0:178939:184351 [0] NCCL INFO NET/Socket : Using [0]eth0:10.13.41.92<0>\n",
      "node-0:178939:184351 [0] NCCL INFO Using network Socket\n",
      "node-0:178939:184352 [1] NCCL INFO Using network Socket\n",
      "node-0:178939:184352 [1] NCCL INFO Topology detection : could not read /sys/devices/LNXSYSTM:00/LNXSYBUS:00/ACPI0004:00/VMBUS:00/47505500-0005-0000-3130-303237343043/pci0005:00/0005:00:00.0/../max_link_speed, ignoring\n",
      "node-0:178939:184351 [0] NCCL INFO Topology detection : could not read /sys/devices/LNXSYSTM:00/LNXSYBUS:00/ACPI0004:00/VMBUS:00/47505500-0005-0000-3130-303237343043/pci0005:00/0005:00:00.0/../max_link_speed, ignoring\n",
      "node-0:178939:184352 [1] NCCL INFO Topology detection : could not read /sys/devices/LNXSYSTM:00/LNXSYBUS:00/ACPI0004:00/VMBUS:00/47505500-0005-0000-3130-303237343043/pci0005:00/0005:00:00.0/../max_link_width, ignoring\n",
      "node-0:178939:184351 [0] NCCL INFO Topology detection : could not read /sys/devices/LNXSYSTM:00/LNXSYBUS:00/ACPI0004:00/VMBUS:00/47505500-0005-0000-3130-303237343043/pci0005:00/0005:00:00.0/../max_link_width, ignoring\n",
      "node-0:178939:184352 [1] NCCL INFO rocm_smi_lib: version 5.0.0.0\n",
      "node-0:178939:184351 [0] NCCL INFO rocm_smi_lib: version 5.0.0.0\n",
      "node-0:178939:184352 [1] NCCL INFO Topology detection : could not read /sys/devices/LNXSYSTM:00/LNXSYBUS:00/ACPI0004:00/VMBUS:00/47505500-0006-0000-3130-303237343043/pci0006:00/0006:00:00.0/../max_link_speed, ignoring\n",
      "node-0:178939:184351 [0] NCCL INFO Topology detection : could not read /sys/devices/LNXSYSTM:00/LNXSYBUS:00/ACPI0004:00/VMBUS:00/47505500-0006-0000-3130-303237343043/pci0006:00/0006:00:00.0/../max_link_speed, ignoring\n",
      "node-0:178939:184352 [1] NCCL INFO Topology detection : could not read /sys/devices/LNXSYSTM:00/LNXSYBUS:00/ACPI0004:00/VMBUS:00/47505500-0006-0000-3130-303237343043/pci0006:00/0006:00:00.0/../max_link_width, ignoring\n",
      "node-0:178939:184351 [0] NCCL INFO Topology detection : could not read /sys/devices/LNXSYSTM:00/LNXSYBUS:00/ACPI0004:00/VMBUS:00/47505500-0006-0000-3130-303237343043/pci0006:00/0006:00:00.0/../max_link_width, ignoring\n",
      "node-0:178939:184352 [1] NCCL INFO === System : maxBw 24.0 totalBw 24.0 ===\n",
      "node-0:178939:184352 [1] NCCL INFO CPU/0 (1/2/4)\n",
      "node-0:178939:184352 [1] NCCL INFO + PCI[5000.0] - NIC/0\n",
      "node-0:178939:184352 [1] NCCL INFO + PCI[24.0] - GPU/500000 (0)\n",
      "node-0:178939:184352 [1] NCCL INFO + PCI[24.0] - GPU/600000 (1)\n",
      "node-0:178939:184352 [1] NCCL INFO ==========================================\n",
      "node-0:178939:184352 [1] NCCL INFO GPU/500000 :GPU/500000 (0/5000.000000/LOC) GPU/600000 (2/24.000000/PHB) CPU/0 (1/24.000000/PHB) \n",
      "node-0:178939:184352 [1] NCCL INFO GPU/600000 :GPU/500000 (2/24.000000/PHB) GPU/600000 (0/5000.000000/LOC) CPU/0 (1/24.000000/PHB) \n",
      "node-0:178939:184352 [1] NCCL INFO Setting affinity for GPU 1 to ffffff\n",
      "node-0:178939:184351 [0] NCCL INFO === System : maxBw 24.0 totalBw 24.0 ===\n",
      "node-0:178939:184351 [0] NCCL INFO CPU/0 (1/2/4)\n",
      "node-0:178939:184351 [0] NCCL INFO + PCI[5000.0] - NIC/0\n",
      "node-0:178939:184351 [0] NCCL INFO + PCI[24.0] - GPU/500000 (0)\n",
      "node-0:178939:184351 [0] NCCL INFO + PCI[24.0] - GPU/600000 (1)\n",
      "node-0:178939:184351 [0] NCCL INFO ==========================================\n",
      "node-0:178939:184351 [0] NCCL INFO GPU/500000 :GPU/500000 (0/5000.000000/LOC) GPU/600000 (2/24.000000/PHB) CPU/0 (1/24.000000/PHB) \n",
      "node-0:178939:184351 [0] NCCL INFO GPU/600000 :GPU/500000 (2/24.000000/PHB) GPU/600000 (0/5000.000000/LOC) CPU/0 (1/24.000000/PHB) \n",
      "node-0:178939:184351 [0] NCCL INFO Setting affinity for GPU 0 to ffffff\n",
      "node-0:178939:184352 [1] NCCL INFO Pattern 4, crossNic 0, nChannels 1, bw 24.000000/24.000000, type PHB/PIX, sameChannels 1\n",
      "node-0:178939:184352 [1] NCCL INFO  0 : GPU/0 GPU/1\n",
      "node-0:178939:184351 [0] NCCL INFO Pattern 4, crossNic 0, nChannels 1, bw 24.000000/24.000000, type PHB/PIX, sameChannels 1\n",
      "node-0:178939:184351 [0] NCCL INFO  0 : GPU/0 GPU/1\n",
      "node-0:178939:184352 [1] NCCL INFO Pattern 1, crossNic 0, nChannels 1, bw 24.000000/24.000000, type PHB/PIX, sameChannels 1\n",
      "node-0:178939:184352 [1] NCCL INFO  0 : GPU/0 GPU/1\n",
      "node-0:178939:184351 [0] NCCL INFO Pattern 1, crossNic 0, nChannels 1, bw 24.000000/24.000000, type PHB/PIX, sameChannels 1\n",
      "node-0:178939:184351 [0] NCCL INFO  0 : GPU/0 GPU/1\n",
      "node-0:178939:184352 [1] NCCL INFO Pattern 3, crossNic 0, nChannels 1, bw 24.000000/24.000000, type PHB/PIX, sameChannels 1\n",
      "node-0:178939:184352 [1] NCCL INFO  0 : GPU/0 GPU/1\n",
      "node-0:178939:184351 [0] NCCL INFO Pattern 3, crossNic 0, nChannels 1, bw 24.000000/24.000000, type PHB/PIX, sameChannels 1\n",
      "node-0:178939:184351 [0] NCCL INFO  0 : GPU/0 GPU/1\n",
      "node-0:178939:184351 [0] NCCL INFO Tree 0 : -1 -> 0 -> 1/-1/-1\n",
      "node-0:178939:184351 [0] NCCL INFO Tree 1 : -1 -> 0 -> 1/-1/-1\n",
      "node-0:178939:184352 [1] NCCL INFO Tree 0 : 0 -> 1 -> -1/-1/-1\n",
      "node-0:178939:184352 [1] NCCL INFO Tree 1 : 0 -> 1 -> -1/-1/-1\n",
      "node-0:178939:184351 [0] NCCL INFO Channel 00/04 :    0   1\n",
      "node-0:178939:184351 [0] NCCL INFO Channel 01/04 :    0   1\n",
      "node-0:178939:184352 [1] NCCL INFO Ring 0 : 0 -> 1 -> 0 comm 0x1832bb30 nRanks 02 busId 600000\n",
      "node-0:178939:184351 [0] NCCL INFO Channel 02/04 :    0   1\n",
      "node-0:178939:184351 [0] NCCL INFO Channel 03/04 :    0   1\n",
      "node-0:178939:184352 [1] NCCL INFO Ring 1 : 0 -> 1 -> 0 comm 0x1832bb30 n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiscuser/scratch/Projects/xcai/xcai/losses.py:21: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:54.)\n",
      "  return torch.sparse_csr_tensor(data_ptr, data_idx, scores, device=data_ptr.device)\n",
      "/opt/conda/envs/ptca/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/envs/ptca/lib/python3.9/site-packages/transformers/utils/import_utils.py:521: FutureWarning: `is_torch_tpu_available` is deprecated and will be removed in 4.41.0. Please use the `is_torch_xla_available` instead.\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1001' max='16950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 1001/16950 37:20 < 9:56:14, 0.45 it/s, Epoch 2.95/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='839' max='1387' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 839/1387 07:26 < 04:52, 1.87 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "753fdfac991e424183f79e224c6e8775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5410 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating clusters with size 2\n",
      "Tree depth = 19\n",
      "doing random split\n",
      "lengths: [346194, 346195]\n",
      "remaining levels for GPU split=18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> gpu splitting random clusters 0 to 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " rank=1 => Total clusters 2\tAvg. Cluster size                 173097.50\tTime to split nodes on this level 0.97 sec\n",
      " rank=1 => Total clusters 4\tAvg. Cluster size                 86548.75\tTime to split nodes on this level 0.06 sec\n",
      " rank=0 => Total clusters 2\tAvg. Cluster size                 173097.00\tTime to split nodes on this level 0.88 sec\n",
      " rank=0 => Total clusters 4\tAvg. Cluster size                 86548.50\tTime to split nodes on this level 0.04 sec\n",
      " rank=1 => Total clusters 8\tAvg. Cluster size                 43274.38\tTime to split nodes on this level 0.08 sec\n",
      " rank=0 => Total clusters 8\tAvg. Cluster size                 43274.25\tTime to split nodes on this level 0.07 sec\n",
      " rank=1 => Total clusters 16\tAvg. Cluster size                 21637.19\tTime to split nodes on this level 0.08 sec\n",
      " rank=0 => Total clusters 16\tAvg. Cluster size                 21637.12\tTime to split nodes on this level 0.07 sec\n",
      " rank=1 => Total clusters 32\tAvg. Cluster size                 10818.59\tTime to split nodes on this level 0.11 sec\n",
      " rank=0 => Total clusters 32\tAvg. Cluster size                 10818.56\tTime to split nodes on this level 0.10 sec\n",
      " rank=1 => Total clusters 64\tAvg. Cluster size                 5409.30\tTime to split nodes on this level 0.14 sec\n",
      " rank=0 => Total clusters 64\tAvg. Cluster size                 5409.28\tTime to split nodes on this level 0.14 sec\n",
      " rank=1 => Total clusters 128\tAvg. Cluster size                 2704.65\tTime to split nodes on this level 0.21 sec\n",
      " rank=0 => Total clusters 128\tAvg. Cluster size                 2704.64\tTime to split nodes on this level 0.20 sec\n",
      " rank=1 => Total clusters 256\tAvg. Cluster size                 1352.32\tTime to split nodes on this level 0.59 sec\n",
      " rank=0 => Total clusters 256\tAvg. Cluster size                 1352.32\tTime to split nodes on this level 0.63 sec\n",
      " rank=1 => Total clusters 512\tAvg. Cluster size                 676.16\tTime to split nodes on this level 0.85 sec\n",
      " rank=0 => Total clusters 512\tAvg. Cluster size                 676.16\tTime to split nodes on this level 0.97 sec\n",
      " rank=1 => Total clusters 1024\tAvg. Cluster size                 338.08\tTime to split nodes on this level 1.47 sec\n",
      " rank=0 => Total clusters 1024\tAvg. Cluster size                 338.08\tTime to split nodes on this level 1.66 sec\n",
      " rank=1 => Total clusters 2048\tAvg. Cluster size                 169.04\tTime to split nodes on this level 3.01 sec\n",
      " rank=0 => Total clusters 2048\tAvg. Cluster size                 169.04\tTime to split nodes on this level 3.00 sec\n",
      " rank=1 => Total clusters 4096\tAvg. Cluster size                 84.52\tTime to split nodes on this level 5.86 sec\n",
      " rank=0 => Total clusters 4096\tAvg. Cluster size                 84.52\tTime to split nodes on this level 5.74 sec\n",
      " rank=1 => Total clusters 8192\tAvg. Cluster size                 42.26\tTime to split nodes on this level 8.38 sec\n",
      " rank=0 => Total clusters 8192\tAvg. Cluster size                 42.26\tTime to split nodes on this level 8.23 sec\n",
      " rank=1 => Total clusters 16384\tAvg. Cluster size                 21.13\tTime to split nodes on this level 11.93 sec\n",
      " rank=0 => Total clusters 16384\tAvg. Cluster size                 21.13\tTime to split nodes on this level 11.93 sec\n",
      " rank=0 => Total clusters 32768\tAvg. Cluster size                 10.57\tTime to split nodes on this level 18.35 sec\n",
      " rank=1 => Total clusters 32768\tAvg. Cluster size                 10.57\tTime to split nodes on this level 18.72 sec\n",
      " rank=1 => Total clusters 65536\tAvg. Cluster size                 5.28\tTime to split nodes on this level 36.30 sec\n",
      " rank=0 => Total clusters 65536\tAvg. Cluster size                 5.28\tTime to split nodes on this level 36.67 sec\n",
      " rank=0 => Total clusters 131072\tAvg. Cluster size                 2.64\tTime to split nodes on this level 71.06 sec\n",
      " rank=1 => Total clusters 131072\tAvg. Cluster size                 2.64\tTime to split nodes on this level 74.69 sec\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "if __name__ == '__main__':\n",
    "    mp.freeze_support()\n",
    "    learn.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53df981",
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b636268",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f1143233",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03b94278",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.where(a == 0, -1e9, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27299ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.0000e+09, -1.0000e+09,  1.0000e-01, -1.0000e+09])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "231a3b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 1., 0.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.softmax(x, dim=0)/(torch.tensor([1, 0, 1, 1])+1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eab76737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 1, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668a31c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
