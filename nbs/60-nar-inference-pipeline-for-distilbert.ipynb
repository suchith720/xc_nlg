{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c74389c-e612-4bf8-a44d-059e54b18024",
   "metadata": {},
   "source": [
    "# NAR training pipeline for distilbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903254a4-afff-4186-9ecb-bcf840e65070",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp 60-nar-inference-pipeline-for-distilbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7e60d6-c737-4eba-b12f-ddce335f17fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cdfeba-6ded-4fbf-be92-94f36c016829",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942e984d-59e3-4834-8169-71a1d43e6d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "comet_ml is installed but `COMET_API_KEY` is not set.\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import os, torch, torch.nn.functional as F, pickle\n",
    "from tqdm.auto import tqdm\n",
    "from xcai.basics import *\n",
    "from xcai.models.MMM0XX import DBT007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6972c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['WANDB_MODE'] = 'disabled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ab86b7-0dbe-4c90-9fdf-8fc4af83fefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "os.environ['WANDB_PROJECT']='xc-nlg_20-nar-training-pipeline-for-distilbert'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb818577",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "pkl_dir = '/home/scai/phd/aiz218323/scratch/datasets'\n",
    "pkl_file = f'{pkl_dir}/processed/wikiseealso_data_distilbert-base-uncased_xcnlg_ngame.pkl'\n",
    "\n",
    "with open(pkl_file, 'rb') as file: block = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734fd5df-2438-4962-bb0f-c76dbbc359b8",
   "metadata": {},
   "source": [
    "## BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16896119-42db-4c3e-801a-91f41af19de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import tiktoken, math, pickle\n",
    "from stop_words import get_stop_words\n",
    "from langdetect import detect\n",
    "from typing import List\n",
    "from rank_bm25 import BM25Okapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e8c0d3-0c68-4b03-b936-435827919ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def remove_multilingual_stopwords(text: str) -> str:\n",
    "    # Detect the language of the text\n",
    "    try: lang = detect(text)\n",
    "    except: return text\n",
    "\n",
    "    # Get the list of stop words for the detected language\n",
    "    try: stop_words = set(get_stop_words(lang))\n",
    "    except: return text\n",
    "\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "encoder = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "def preprocess_func(text: str) -> List[str]:\n",
    "    lowered = text.lower()\n",
    "    tokens = encoder.encode(lowered)\n",
    "    return [str(token) for token in tokens]\n",
    "\n",
    "def tokenize(text): return preprocess_func(remove_multilingual_stopwords(text))\n",
    "\n",
    "def tokenizer(text): \n",
    "    return [tokenize(o) for o in tqdm(text, total=len(text))]\n",
    "\n",
    "def get_scores(text):\n",
    "    preds = []\n",
    "    for o in tqdm(text, total=len(text)):\n",
    "        sc = torch.tensor(bm25.get_scores(tokenize(o)))\n",
    "        sc, idx = torch.topk(sc, 200)\n",
    "        preds.append((sc,idx))\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e7f781-28aa-4ba0-831a-0f24f6096f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from multiprocessing import Pool\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88341d79-7d83-48a1-b089-4c86c94cf4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_proc, n_lbl = 8, block.n_lbl\n",
    "bsz = math.ceil(n_lbl/n_proc)\n",
    "\n",
    "lbl_text = [block.train.dset.data.lbl_info['input_text'][i*bsz:(i+1)*bsz] for i in range(n_proc)]\n",
    "    \n",
    "with Pool(processes=n_proc) as pool:\n",
    "    lbl_text = list(chain(*tqdm(pool.map(tokenizer, lbl_text))))\n",
    "\n",
    "data_dir = '/home/scai/phd/aiz218323/scratch/outputs/60-nar-inference-pipeline-for-distilbert'\n",
    "with open(f'{data_dir}/wikiseealso-lbl.bow', 'wb') as file: \n",
    "    pickle.dump(lbl_text, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7794dc73-d759-4c76-b12a-460bfb82f276",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "data_dir = '/home/scai/phd/aiz218323/scratch/outputs/60-nar-inference-pipeline-for-distilbert'\n",
    "with open(f'{data_dir}/wikiseealso-lbl.bow', 'rb') as file: \n",
    "    lbl_text = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e641ced9-6de1-4b26-9c10-1198a59cec34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "bm25 = BM25Okapi(lbl_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d24e745-c171-43f2-9685-d199f6b8d6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "n_proc, n_data = 8, block.test.dset.data.n_data\n",
    "bsz = math.ceil(n_data/n_proc)\n",
    "\n",
    "data_text = block.test.dset.data.data_info['input_text']\n",
    "data_text = [data_text[i*bsz:(i+1)*bsz] for i in range(n_proc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1c5827-e9c3-4ba3-a3e5-0d3d17c36a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "with Pool(processes=n_proc) as pool:\n",
    "    output = list(tqdm(pool.map(get_scores, data_text)))\n",
    "\n",
    "data_dir = '/home/scai/phd/aiz218323/scratch/outputs/60-nar-inference-pipeline-for-distilbert'\n",
    "with open(f'{data_dir}/wikiseealso-bm25-output.bow', 'wb') as file: \n",
    "    pickle.dump(lbl_text, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0d2716-e4b6-4e70-9d81-96887497a263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69faaee7b1e94dcebbb5169f7ed3ed41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = get_scores(block.test.dset.data.data_info['input_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b6ad5a-8fae-4a7f-baea-3fb155625beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/scai/phd/aiz218323/scratch/outputs/60-nar-inference-pipeline-for-distilbert'\n",
    "with open(f'{data_dir}/wikiseealso-bm25-output.bow', 'wb') as file: \n",
    "    pickle.dump(lbl_text, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de33ed12-ba7e-4ecc-bd06-962f4b679f75",
   "metadata": {},
   "source": [
    "## DBT007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ac99f9-1d8a-4759-b7f6-b8f9d2111a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_idf = get_tok_idf(block.train.dset, field='lbl2data_input_ids', n_cols=30522)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f682407f-e2f8-421c-ab4f-cc0d88c389cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = XCLearningArguments(\n",
    "    output_dir='/home/scai/phd/aiz218323/scratch/outputs/20-nar-training-pipeline-for-distilbert-2-1',\n",
    "    logging_first_step=True,\n",
    "    per_device_train_batch_size=1024,\n",
    "    per_device_eval_batch_size=1024,\n",
    "    representation_num_beams=200,\n",
    "    representation_accumulation_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps=2000,\n",
    "    save_steps=2000,\n",
    "    save_total_limit=5,\n",
    "    num_train_epochs=100,\n",
    "    adam_epsilon=1e-8,\n",
    "    warmup_steps=0,\n",
    "    weight_decay=0.1,\n",
    "    learning_rate=2e-4,\n",
    "    generation_num_beams=10,\n",
    "    generation_length_penalty=1.5,\n",
    "    predict_with_generation=True,\n",
    "    label_names=['lbl2data_idx'],\n",
    "    target_indices_key='plbl2data_idx',\n",
    "    target_pointer_key='plbl2data_data2ptr',\n",
    "    fp16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9b5323-dd83-45bd-95c4-afd1c4c5ac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dset = block.test.dset.sample(n=2000, seed=50)\n",
    "metric = PrecRecl(block.n_lbl, test_dset.data.data_lbl_filterer, prop=block.train.dset.data.data_lbl,\n",
    "                  pk=10, rk=200, rep_pk=[1, 3, 5, 10], rep_rk=[10, 100, 200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336af894-d34b-42ef-a913-1ade26c7e19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mname = get_best_model(args.output_dir)\n",
    "model = DBT007.from_pretrained(mname, tn_targ=10_000, ig_tok=0, vocab_weights=tok_idf, reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf7efd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trie = XCTrie.from_block(block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411c409d-1183-4f90-a0db-4910d857088d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = XCLearner(\n",
    "    model=model, \n",
    "    args=args,\n",
    "    trie=trie,\n",
    "    train_dataset=block.train.dset,\n",
    "    eval_dataset=test_dset,\n",
    "    data_collator=block.collator,\n",
    "    compute_metrics=metric,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc62a188",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = learn.predict(test_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc34790a-ffa7-4f36-9d4e-a514295ec2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "o.metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
