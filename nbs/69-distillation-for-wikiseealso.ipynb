{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60b51bd-0144-4139-8be5-7602bad6a9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp 69-distillation-for-wikiseealso-1-0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e00e5c-ff88-425d-a828-7ca5d02215ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874750be-c904-447e-8754-3eefcb9586d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os,torch, torch.multiprocessing as mp, pickle, numpy as np\n",
    "from transformers import DistilBertConfig\n",
    "\n",
    "from xcai.basics import *\n",
    "from xcai.models.PPP0XX import DBT010\n",
    "from xcai.models.distillation import DTL001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd23053-8908-4615-a47f-96b2039b0cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['WANDB_MODE'] = 'disabled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44292259-cc09-4bd0-96f3-08206b948924",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n",
    "os.environ['WANDB_PROJECT']='xc-nlg_69-distillation-for-wikiseealso'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9117b606-5304-4d30-9fb3-4bdf91fb7fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "pkl_dir = '/home/scai/phd/aiz218323/scratch/datasets'\n",
    "pkl_file = f'{pkl_dir}/processed/wikiseealso_data-metas_distilbert-base-uncased_rm_radga-aug-cat-hlk-block-032.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a5bd41-8e37-457f-a36d-39e41a65ca6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "with open(pkl_file, 'rb') as file: block = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2d5077-4268-4418-8d1e-9536f2d5538b",
   "metadata": {},
   "outputs": [],
   "source": [
    "block.train.dset.data.data_info['input_ids'] = block.train.dset.data.data_info['input_ids_aug_cat']\n",
    "block.train.dset.data.data_info['attention_mask'] = block.train.dset.data.data_info['attention_mask_aug_cat']\n",
    "block.test.dset.data.data_info['input_ids'] = block.test.dset.data.data_info['input_ids_aug_cat']\n",
    "block.test.dset.data.data_info['attention_mask'] = block.test.dset.data.data_info['attention_mask_aug_cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bbb3b3-62a7-438f-98a9-ed95bdfe07f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "block.train.dset.data.data_info['aug_input_ids'] = block.train.dset.data.data_info['input_ids_aug_cat']\n",
    "block.train.dset.data.data_info['aug_attention_mask'] = block.train.dset.data.data_info['attention_mask_aug_cat']\n",
    "block.test.dset.data.data_info['aug_input_ids'] = block.test.dset.data.data_info['input_ids_aug_cat']\n",
    "block.test.dset.data.data_info['aug_attention_mask'] = block.test.dset.data.data_info['attention_mask_aug_cat']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb716ef-c80c-42ca-8096-5eed4ef7135b",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870ac001-4e36-4912-8c94-1f637d40d860",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "args = XCLearningArguments(\n",
    "    output_dir='/home/scai/phd/aiz218323/scratch/outputs/69-distillation-for-wikiseealso-1-0',\n",
    "    logging_first_step=True,\n",
    "    per_device_train_batch_size=800,\n",
    "    per_device_eval_batch_size=800,\n",
    "    representation_num_beams=200,\n",
    "    representation_accumulation_steps=10,\n",
    "    save_strategy=\"steps\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=3000,\n",
    "    save_steps=3000,\n",
    "    save_total_limit=5,\n",
    "    num_train_epochs=300,\n",
    "    predict_with_representation=True,\n",
    "    representation_search_type='INDEX',\n",
    "    adam_epsilon=1e-6,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    learning_rate=2e-4,\n",
    "    group_by_cluster=True,\n",
    "    num_clustering_warmup_epochs=10,\n",
    "    num_cluster_update_epochs=5,\n",
    "    num_cluster_size_update_epochs=25,\n",
    "    clustering_type='EXPO',\n",
    "    minimum_cluster_size=2,\n",
    "    maximum_cluster_size=1600,\n",
    "    target_indices_key='plbl2data_idx',\n",
    "    target_pointer_key='plbl2data_data2ptr',\n",
    "    use_encoder_parallel=True,\n",
    "    max_grad_norm=None,\n",
    "    fp16=True,\n",
    "    label_names=['lbl2data_idx', 'lbl2data_input_ids', 'lbl2data_attention_mask'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02772f56-3629-4f5b-91ad-ed4ab133a943",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from safetensors import safe_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36dfd9a-2f02-43bf-a6fc-507ab57dab8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DBT010 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.dr_layer_norm.bias', 'encoder.dr_layer_norm.weight', 'encoder.dr_projector.bias', 'encoder.dr_projector.weight', 'encoder.dr_transform.bias', 'encoder.dr_transform.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['distilbert.embeddings.word_embeddings.weight', 'distilbert.embeddings.position_embeddings.weight', 'distilbert.embeddings.LayerNorm.weight', 'distilbert.embeddings.LayerNorm.bias', 'distilbert.transformer.layer.0.attention.q_lin.weight', 'distilbert.transformer.layer.0.attention.q_lin.bias', 'distilbert.transformer.layer.0.attention.k_lin.weight', 'distilbert.transformer.layer.0.attention.k_lin.bias', 'distilbert.transformer.layer.0.attention.v_lin.weight', 'distilbert.transformer.layer.0.attention.v_lin.bias', 'distilbert.transformer.layer.0.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.out_lin.bias', 'distilbert.transformer.layer.0.sa_layer_norm.weight', 'distilbert.transformer.layer.0.sa_layer_norm.bias', 'distilbert.transformer.layer.0.ffn.lin1.weight', 'distilbert.transformer.layer.0.ffn.lin1.bias', 'distilbert.transformer.layer.0.ffn.lin2.weight', 'distilbert.transformer.layer.0.ffn.lin2.bias', 'distilbert.transformer.layer.0.output_layer_norm.weight', 'distilbert.transformer.layer.0.output_layer_norm.bias', 'distilbert.transformer.layer.1.attention.q_lin.weight', 'distilbert.transformer.layer.1.attention.q_lin.bias', 'distilbert.transformer.layer.1.attention.k_lin.weight', 'distilbert.transformer.layer.1.attention.k_lin.bias', 'distilbert.transformer.layer.1.attention.v_lin.weight', 'distilbert.transformer.layer.1.attention.v_lin.bias', 'distilbert.transformer.layer.1.attention.out_lin.weight', 'distilbert.transformer.layer.1.attention.out_lin.bias', 'distilbert.transformer.layer.1.sa_layer_norm.weight', 'distilbert.transformer.layer.1.sa_layer_norm.bias', 'distilbert.transformer.layer.1.ffn.lin1.weight', 'distilbert.transformer.layer.1.ffn.lin1.bias', 'distilbert.transformer.layer.1.ffn.lin2.weight', 'distilbert.transformer.layer.1.ffn.lin2.bias', 'distilbert.transformer.layer.1.output_layer_norm.weight', 'distilbert.transformer.layer.1.output_layer_norm.bias', 'distilbert.transformer.layer.2.attention.q_lin.weight', 'distilbert.transformer.layer.2.attention.q_lin.bias', 'distilbert.transformer.layer.2.attention.k_lin.weight', 'distilbert.transformer.layer.2.attention.k_lin.bias', 'distilbert.transformer.layer.2.attention.v_lin.weight', 'distilbert.transformer.layer.2.attention.v_lin.bias', 'distilbert.transformer.layer.2.attention.out_lin.weight', 'distilbert.transformer.layer.2.attention.out_lin.bias', 'distilbert.transformer.layer.2.sa_layer_norm.weight', 'distilbert.transformer.layer.2.sa_layer_norm.bias', 'distilbert.transformer.layer.2.ffn.lin1.weight', 'distilbert.transformer.layer.2.ffn.lin1.bias', 'distilbert.transformer.layer.2.ffn.lin2.weight', 'distilbert.transformer.layer.2.ffn.lin2.bias', 'distilbert.transformer.layer.2.output_layer_norm.weight', 'distilbert.transformer.layer.2.output_layer_norm.bias', 'distilbert.transformer.layer.3.attention.q_lin.weight', 'distilbert.transformer.layer.3.attention.q_lin.bias', 'distilbert.transformer.layer.3.attention.k_lin.weight', 'distilbert.transformer.layer.3.attention.k_lin.bias', 'distilbert.transformer.layer.3.attention.v_lin.weight', 'distilbert.transformer.layer.3.attention.v_lin.bias', 'distilbert.transformer.layer.3.attention.out_lin.weight', 'distilbert.transformer.layer.3.attention.out_lin.bias', 'distilbert.transformer.layer.3.sa_layer_norm.weight', 'distilbert.transformer.layer.3.sa_layer_norm.bias', 'distilbert.transformer.layer.3.ffn.lin1.weight', 'distilbert.transformer.layer.3.ffn.lin1.bias', 'distilbert.transformer.layer.3.ffn.lin2.weight', 'distilbert.transformer.layer.3.ffn.lin2.bias', 'distilbert.transformer.layer.3.output_layer_norm.weight', 'distilbert.transformer.layer.3.output_layer_norm.bias', 'distilbert.transformer.layer.4.attention.q_lin.weight', 'distilbert.transformer.layer.4.attention.q_lin.bias', 'distilbert.transformer.layer.4.attention.k_lin.weight', 'distilbert.transformer.layer.4.attention.k_lin.bias', 'distilbert.transformer.layer.4.attention.v_lin.weight', 'distilbert.transformer.layer.4.attention.v_lin.bias', 'distilbert.transformer.layer.4.attention.out_lin.weight', 'distilbert.transformer.layer.4.attention.out_lin.bias', 'distilbert.transformer.layer.4.sa_layer_norm.weight', 'distilbert.transformer.layer.4.sa_layer_norm.bias', 'distilbert.transformer.layer.4.ffn.lin1.weight', 'distilbert.transformer.layer.4.ffn.lin1.bias', 'distilbert.transformer.layer.4.ffn.lin2.weight', 'distilbert.transformer.layer.4.ffn.lin2.bias', 'distilbert.transformer.layer.4.output_layer_norm.weight', 'distilbert.transformer.layer.4.output_layer_norm.bias', 'distilbert.transformer.layer.5.attention.q_lin.weight', 'distilbert.transformer.layer.5.attention.q_lin.bias', 'distilbert.transformer.layer.5.attention.k_lin.weight', 'distilbert.transformer.layer.5.attention.k_lin.bias', 'distilbert.transformer.layer.5.attention.v_lin.weight', 'distilbert.transformer.layer.5.attention.v_lin.bias', 'distilbert.transformer.layer.5.attention.out_lin.weight', 'distilbert.transformer.layer.5.attention.out_lin.bias', 'distilbert.transformer.layer.5.sa_layer_norm.weight', 'distilbert.transformer.layer.5.sa_layer_norm.bias', 'distilbert.transformer.layer.5.ffn.lin1.weight', 'distilbert.transformer.layer.5.ffn.lin1.bias', 'distilbert.transformer.layer.5.ffn.lin2.weight', 'distilbert.transformer.layer.5.ffn.lin2.bias', 'distilbert.transformer.layer.5.output_layer_norm.weight', 'distilbert.transformer.layer.5.output_layer_norm.bias'], unexpected_keys=[])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| export\n",
    "bsz = max(args.per_device_train_batch_size, args.per_device_eval_batch_size)*torch.cuda.device_count()\n",
    "\n",
    "model_output = '/home/scai/phd/aiz218323/scratch/outputs/67-ngame-ep-for-wikiseealso-with-input-concatenation-1-1'\n",
    "output_dir = f\"/home/scai/phd/aiz218323/scratch/outputs/{os.path.basename(model_output)}\"\n",
    "mname = f'{output_dir}/{os.path.basename(get_best_model(output_dir))}'\n",
    "\n",
    "m_teacher = DBT010.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', bsz=bsz, tn_targ=5000, margin=0.3, tau=0.1, \n",
    "                                   n_negatives=10, apply_softmax=True, use_encoder_parallel=True)\n",
    "\n",
    "model_weight_file,model_weights = f'{mname}/model.safetensors',{}\n",
    "with safe_open(model_weight_file, framework=\"pt\") as file:\n",
    "    for k in file.keys(): model_weights[k] = file.get_tensor(k)\n",
    "\n",
    "m_teacher.load_state_dict(model_weights, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e7f916-80b5-49e3-ae91-cca10cf1331f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92245f60-99ac-4051-8644-1aac5662e48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DBT010 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.dr_layer_norm.bias', 'encoder.dr_layer_norm.weight', 'encoder.dr_projector.bias', 'encoder.dr_projector.weight', 'encoder.dr_transform.bias', 'encoder.dr_transform.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "bsz = max(args.per_device_train_batch_size, args.per_device_eval_batch_size)*torch.cuda.device_count()\n",
    "\n",
    "m_student = DBT010.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', bsz=bsz, tn_targ=5000, margin=0.3, tau=0.1, \n",
    "                                   n_negatives=10, apply_softmax=True, use_encoder_parallel=True)\n",
    "m_student.init_dr_head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfefc621-7df9-4308-8a29-d580ff215679",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd275020-fd37-4741-bfb6-66ecb82b0d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "metric = PrecRecl(block.n_lbl, block.test.data_lbl_filterer, prop=block.train.dset.data.data_lbl,\n",
    "                  pk=10, rk=200, rep_pk=[1, 3, 5, 10], rep_rk=[10, 100, 200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19144c29-bc7f-450c-8a85-c716ba9d9caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = XCLearner(\n",
    "    model=m_teacher, \n",
    "    args=args,\n",
    "    train_dataset=block.train.dset,\n",
    "    eval_dataset=block.test.dset,\n",
    "    data_collator=block.collator,\n",
    "    compute_metrics=metric,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d1223e-3bdd-4985-8661-d2f8ba1ffc98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28b349fc9d654336924b1a0d89b4b4c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/scipy/sparse/_index.py:145: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "o = learn.predict(block.test.dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867383e9-2d2c-495e-bd84-d08248ae42e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P@1</th>\n",
       "      <th>P@3</th>\n",
       "      <th>P@5</th>\n",
       "      <th>P@10</th>\n",
       "      <th>N@1</th>\n",
       "      <th>N@3</th>\n",
       "      <th>N@5</th>\n",
       "      <th>N@10</th>\n",
       "      <th>PSP@1</th>\n",
       "      <th>PSP@3</th>\n",
       "      <th>PSP@5</th>\n",
       "      <th>PSP@10</th>\n",
       "      <th>PSN@1</th>\n",
       "      <th>PSN@3</th>\n",
       "      <th>PSN@5</th>\n",
       "      <th>PSN@10</th>\n",
       "      <th>R@10</th>\n",
       "      <th>R@100</th>\n",
       "      <th>R@200</th>\n",
       "      <th>loss</th>\n",
       "      <th>runtime</th>\n",
       "      <th>samples_per_second</th>\n",
       "      <th>steps_per_second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.2622</td>\n",
       "      <td>11.2798</td>\n",
       "      <td>8.5273</td>\n",
       "      <td>5.5284</td>\n",
       "      <td>17.2622</td>\n",
       "      <td>17.0362</td>\n",
       "      <td>17.7345</td>\n",
       "      <td>19.0837</td>\n",
       "      <td>16.3327</td>\n",
       "      <td>16.7056</td>\n",
       "      <td>17.7868</td>\n",
       "      <td>20.5618</td>\n",
       "      <td>16.3327</td>\n",
       "      <td>17.3546</td>\n",
       "      <td>18.4396</td>\n",
       "      <td>20.0053</td>\n",
       "      <td>22.9164</td>\n",
       "      <td>37.1221</td>\n",
       "      <td>41.469</td>\n",
       "      <td>0.0335</td>\n",
       "      <td>252.57</td>\n",
       "      <td>702.835</td>\n",
       "      <td>0.439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       P@1      P@3     P@5    P@10      N@1      N@3      N@5     N@10  \\\n",
       "0  17.2622  11.2798  8.5273  5.5284  17.2622  17.0362  17.7345  19.0837   \n",
       "\n",
       "     PSP@1    PSP@3    PSP@5   PSP@10    PSN@1    PSN@3    PSN@5   PSN@10  \\\n",
       "0  16.3327  16.7056  17.7868  20.5618  16.3327  17.3546  18.4396  20.0053   \n",
       "\n",
       "      R@10    R@100   R@200    loss  runtime  samples_per_second  \\\n",
       "0  22.9164  37.1221  41.469  0.0335   252.57             702.835   \n",
       "\n",
       "   steps_per_second  \n",
       "0             0.439  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_metric(o.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c703f320-abe4-47f5-8733-54dc82ce3258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P@1</th>\n",
       "      <th>P@3</th>\n",
       "      <th>P@5</th>\n",
       "      <th>P@10</th>\n",
       "      <th>N@1</th>\n",
       "      <th>N@3</th>\n",
       "      <th>N@5</th>\n",
       "      <th>N@10</th>\n",
       "      <th>PSP@1</th>\n",
       "      <th>PSP@3</th>\n",
       "      <th>PSP@5</th>\n",
       "      <th>PSP@10</th>\n",
       "      <th>PSN@1</th>\n",
       "      <th>PSN@3</th>\n",
       "      <th>PSN@5</th>\n",
       "      <th>PSN@10</th>\n",
       "      <th>R@10</th>\n",
       "      <th>R@100</th>\n",
       "      <th>R@200</th>\n",
       "      <th>loss</th>\n",
       "      <th>runtime</th>\n",
       "      <th>samples_per_second</th>\n",
       "      <th>steps_per_second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.1849</td>\n",
       "      <td>25.1252</td>\n",
       "      <td>18.8724</td>\n",
       "      <td>11.9554</td>\n",
       "      <td>39.1849</td>\n",
       "      <td>38.8025</td>\n",
       "      <td>40.2272</td>\n",
       "      <td>42.7062</td>\n",
       "      <td>27.787</td>\n",
       "      <td>30.1188</td>\n",
       "      <td>32.8063</td>\n",
       "      <td>38.2856</td>\n",
       "      <td>27.787</td>\n",
       "      <td>31.084</td>\n",
       "      <td>33.3704</td>\n",
       "      <td>36.2891</td>\n",
       "      <td>49.0164</td>\n",
       "      <td>66.6496</td>\n",
       "      <td>70.3424</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>702.0258</td>\n",
       "      <td>252.861</td>\n",
       "      <td>0.158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       P@1      P@3      P@5     P@10      N@1      N@3      N@5     N@10  \\\n",
       "0  39.1849  25.1252  18.8724  11.9554  39.1849  38.8025  40.2272  42.7062   \n",
       "\n",
       "    PSP@1    PSP@3    PSP@5   PSP@10   PSN@1   PSN@3    PSN@5   PSN@10  \\\n",
       "0  27.787  30.1188  32.8063  38.2856  27.787  31.084  33.3704  36.2891   \n",
       "\n",
       "      R@10    R@100    R@200    loss   runtime  samples_per_second  \\\n",
       "0  49.0164  66.6496  70.3424  0.0198  702.0258             252.861   \n",
       "\n",
       "   steps_per_second  \n",
       "0             0.158  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_metric(o.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8017ebde-d4e5-426e-9639-de82fd3f18f7",
   "metadata": {},
   "source": [
    "## `Distillation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d5cc4f-77cf-41e1-9296-40220a9d9ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "model = DTL001(DistilBertConfig(), m_student=m_student, m_teacher=m_teacher, embed_sim_loss_weight=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14257a1-e39d-4fb9-b6fa-db09f58f0628",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "learn = XCLearner(\n",
    "    model=model, \n",
    "    args=args,\n",
    "    train_dataset=block.train.dset,\n",
    "    eval_dataset=block.test.dset,\n",
    "    data_collator=block.collator,\n",
    "    compute_metrics=metric,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5368b5-a8bd-499f-bcca-d57f37d0f279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb268b60-65c3-4760-a6d0-e531d2cd916d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='130200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [     7/130200 04:15 < 1848:25:13, 0.02 it/s, Epoch 0.01/300]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>P@1</th>\n",
       "      <th>P@10</th>\n",
       "      <th>P@3</th>\n",
       "      <th>P@5</th>\n",
       "      <th>N@1</th>\n",
       "      <th>N@10</th>\n",
       "      <th>N@3</th>\n",
       "      <th>N@5</th>\n",
       "      <th>Psp@1</th>\n",
       "      <th>Psp@10</th>\n",
       "      <th>Psp@3</th>\n",
       "      <th>Psp@5</th>\n",
       "      <th>Psn@1</th>\n",
       "      <th>Psn@10</th>\n",
       "      <th>Psn@3</th>\n",
       "      <th>Psn@5</th>\n",
       "      <th>R@200</th>\n",
       "      <th>R@10</th>\n",
       "      <th>R@100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.885800</td>\n",
       "      <td>1.822938</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.076667</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.138012</td>\n",
       "      <td>0.116614</td>\n",
       "      <td>0.124257</td>\n",
       "      <td>0.140339</td>\n",
       "      <td>0.171597</td>\n",
       "      <td>0.119260</td>\n",
       "      <td>0.141005</td>\n",
       "      <td>0.140339</td>\n",
       "      <td>0.153391</td>\n",
       "      <td>0.127400</td>\n",
       "      <td>0.139141</td>\n",
       "      <td>0.375940</td>\n",
       "      <td>0.167429</td>\n",
       "      <td>0.323345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.885800</td>\n",
       "      <td>1.819432</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.046000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.141294</td>\n",
       "      <td>0.117651</td>\n",
       "      <td>0.122745</td>\n",
       "      <td>0.140339</td>\n",
       "      <td>0.177766</td>\n",
       "      <td>0.123546</td>\n",
       "      <td>0.141005</td>\n",
       "      <td>0.140339</td>\n",
       "      <td>0.155641</td>\n",
       "      <td>0.127750</td>\n",
       "      <td>0.137061</td>\n",
       "      <td>0.379607</td>\n",
       "      <td>0.180762</td>\n",
       "      <td>0.321643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4ce3358209b412b9a685926f45ded0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/scipy/sparse/_index.py:145: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n",
      "Removed shared tensor {'m_student.distilbert.transformer.layer.4.attention.q_lin.bias', 'm_student.distilbert.transformer.layer.0.ffn.lin1.weight', 'm_student.distilbert.transformer.layer.0.sa_layer_norm.bias', 'm_teacher.distilbert.embeddings.position_embeddings.weight', 'm_teacher.distilbert.transformer.layer.1.sa_layer_norm.bias', 'm_teacher.distilbert.transformer.layer.5.attention.out_lin.bias', 'm_student.distilbert.transformer.layer.3.sa_layer_norm.bias', 'm_student.distilbert.transformer.layer.3.ffn.lin1.bias', 'm_teacher.distilbert.transformer.layer.2.attention.v_lin.weight', 'm_teacher.distilbert.transformer.layer.3.attention.v_lin.bias', 'm_teacher.distilbert.transformer.layer.1.attention.q_lin.bias', 'm_student.distilbert.transformer.layer.4.output_layer_norm.weight', 'm_student.distilbert.transformer.layer.0.ffn.lin1.bias', 'm_student.distilbert.transformer.layer.0.attention.v_lin.bias', 'm_student.distilbert.transformer.layer.1.sa_layer_norm.bias', 'm_student.distilbert.transformer.layer.1.attention.q_lin.bias', 'm_teacher.distilbert.transformer.layer.4.attention.v_lin.weight', 'm_teacher.distilbert.transformer.layer.3.output_layer_norm.weight', 'm_student.distilbert.transformer.layer.3.attention.q_lin.bias', 'm_student.distilbert.transformer.layer.3.attention.out_lin.weight', 'm_teacher.distilbert.transformer.layer.0.sa_layer_norm.bias', 'm_teacher.distilbert.transformer.layer.5.ffn.lin2.bias', 'm_teacher.distilbert.transformer.layer.4.sa_layer_norm.bias', 'm_student.distilbert.transformer.layer.2.ffn.lin1.weight', 'm_student.distilbert.transformer.layer.5.output_layer_norm.weight', 'm_teacher.distilbert.transformer.layer.3.output_layer_norm.bias', 'm_teacher.distilbert.transformer.layer.2.attention.v_lin.bias', 'm_student.distilbert.transformer.layer.0.output_layer_norm.bias', 'm_teacher.distilbert.transformer.layer.2.ffn.lin2.bias', 'm_teacher.distilbert.transformer.layer.3.attention.out_lin.weight', 'm_student.distilbert.transformer.layer.4.ffn.lin2.bias', 'm_teacher.distilbert.transformer.layer.0.output_layer_norm.bias', 'm_student.distilbert.transformer.layer.5.attention.v_lin.weight', 'm_student.distilbert.transformer.layer.5.ffn.lin1.bias', 'm_teacher.distilbert.transformer.layer.4.attention.out_lin.bias', 'm_teacher.distilbert.transformer.layer.4.output_layer_norm.bias', 'm_teacher.distilbert.transformer.layer.5.sa_layer_norm.bias', 'm_student.distilbert.transformer.layer.2.attention.k_lin.weight', 'm_teacher.distilbert.transformer.layer.2.sa_layer_norm.bias', 'm_teacher.distilbert.transformer.layer.4.ffn.lin1.bias', 'm_student.distilbert.transformer.layer.4.attention.out_lin.bias', 'm_teacher.distilbert.transformer.layer.0.output_layer_norm.weight', 'm_student.distilbert.transformer.layer.2.output_layer_norm.bias', 'm_teacher.distilbert.transformer.layer.5.ffn.lin1.bias', 'm_teacher.distilbert.transformer.layer.1.attention.k_lin.weight', 'm_student.distilbert.transformer.layer.0.ffn.lin2.bias', 'm_student.distilbert.transformer.layer.2.output_layer_norm.weight', 'm_teacher.distilbert.transformer.layer.1.attention.v_lin.weight', 'm_teacher.distilbert.transformer.layer.4.ffn.lin1.weight', 'm_teacher.distilbert.transformer.layer.2.attention.out_lin.bias', 'm_student.distilbert.transformer.layer.3.ffn.lin1.weight', 'm_student.distilbert.transformer.layer.0.sa_layer_norm.weight', 'm_teacher.distilbert.transformer.layer.1.output_layer_norm.weight', 'm_teacher.distilbert.transformer.layer.0.ffn.lin1.weight', 'm_teacher.distilbert.transformer.layer.5.attention.k_lin.bias', 'm_student.distilbert.transformer.layer.5.attention.q_lin.weight', 'm_teacher.distilbert.transformer.layer.0.sa_layer_norm.weight', 'm_teacher.distilbert.transformer.layer.2.ffn.lin1.bias', 'm_teacher.distilbert.transformer.layer.2.attention.k_lin.bias', 'm_teacher.distilbert.transformer.layer.0.attention.k_lin.bias', 'm_teacher.distilbert.transformer.layer.3.sa_layer_norm.weight', 'm_student.distilbert.transformer.layer.3.ffn.lin2.weight', 'm_teacher.distilbert.transformer.layer.5.attention.out_lin.weight', 'm_teacher.distilbert.transformer.layer.5.ffn.lin1.weight', 'm_teacher.distilbert.transformer.layer.1.attention.v_lin.bias', 'm_teacher.distilbert.transformer.layer.4.sa_layer_norm.weight', 'm_teacher.distilbert.embeddings.word_embeddings.weight', 'm_student.distilbert.transformer.layer.1.attention.v_lin.bias', 'm_teacher.distilbert.transformer.layer.2.attention.k_lin.weight', 'm_student.distilbert.transformer.layer.1.attention.k_lin.weight', 'm_student.distilbert.transformer.layer.2.attention.q_lin.weight', 'm_teacher.distilbert.transformer.layer.4.output_layer_norm.weight', 'm_teacher.distilbert.transformer.layer.2.attention.q_lin.weight', 'm_teacher.distilbert.embeddings.LayerNorm.weight', 'm_teacher.distilbert.transformer.layer.3.attention.v_lin.weight', 'm_teacher.distilbert.transformer.layer.2.output_layer_norm.bias', 'm_student.distilbert.transformer.layer.3.attention.k_lin.bias', 'm_teacher.distilbert.transformer.layer.3.ffn.lin1.weight', 'm_student.distilbert.transformer.layer.0.attention.q_lin.weight', 'm_student.distilbert.transformer.layer.1.output_layer_norm.bias', 'm_student.distilbert.transformer.layer.5.ffn.lin2.weight', 'm_teacher.distilbert.embeddings.LayerNorm.bias', 'm_student.distilbert.transformer.layer.4.attention.q_lin.weight', 'm_student.distilbert.transformer.layer.0.attention.v_lin.weight', 'm_student.distilbert.transformer.layer.1.ffn.lin1.bias', 'm_student.distilbert.transformer.layer.2.attention.v_lin.bias', 'm_student.distilbert.transformer.layer.4.ffn.lin2.weight', 'm_student.distilbert.transformer.layer.4.attention.k_lin.bias', 'm_teacher.distilbert.transformer.layer.4.attention.out_lin.weight', 'm_student.distilbert.transformer.layer.5.ffn.lin1.weight', 'm_student.distilbert.transformer.layer.3.attention.q_lin.weight', 'm_teacher.distilbert.transformer.layer.0.attention.q_lin.weight', 'm_teacher.distilbert.transformer.layer.3.attention.k_lin.weight', 'm_teacher.distilbert.transformer.layer.1.attention.k_lin.bias', 'm_student.distilbert.embeddings.LayerNorm.weight', 'm_student.distilbert.transformer.layer.2.attention.v_lin.weight', 'm_student.distilbert.transformer.layer.1.attention.q_lin.weight', 'm_student.distilbert.transformer.layer.4.attention.v_lin.weight', 'm_teacher.distilbert.transformer.layer.4.attention.v_lin.bias', 'm_student.distilbert.embeddings.LayerNorm.bias', 'm_teacher.distilbert.transformer.layer.1.attention.out_lin.weight', 'm_student.distilbert.transformer.layer.3.attention.v_lin.weight', 'm_teacher.distilbert.transformer.layer.5.attention.v_lin.weight', 'm_teacher.distilbert.transformer.layer.3.attention.out_lin.bias', 'm_teacher.distilbert.transformer.layer.2.output_layer_norm.weight', 'm_teacher.distilbert.transformer.layer.4.attention.q_lin.bias', 'm_teacher.distilbert.transformer.layer.0.attention.q_lin.bias', 'm_teacher.distilbert.transformer.layer.1.ffn.lin1.bias', 'm_teacher.distilbert.transformer.layer.0.ffn.lin1.bias', 'm_student.distilbert.transformer.layer.4.attention.out_lin.weight', 'm_student.distilbert.transformer.layer.5.attention.k_lin.weight', 'm_student.distilbert.transformer.layer.1.ffn.lin1.weight', 'm_teacher.distilbert.transformer.layer.1.output_layer_norm.bias', 'm_teacher.distilbert.transformer.layer.3.ffn.lin2.bias', 'm_student.distilbert.transformer.layer.3.sa_layer_norm.weight', 'm_teacher.distilbert.transformer.layer.5.ffn.lin2.weight', 'm_student.distilbert.transformer.layer.0.attention.k_lin.bias', 'm_student.distilbert.transformer.layer.5.output_layer_norm.bias', 'm_teacher.distilbert.transformer.layer.0.attention.v_lin.bias', 'm_teacher.distilbert.transformer.layer.0.attention.out_lin.weight', 'm_teacher.distilbert.transformer.layer.5.output_layer_norm.bias', 'm_student.distilbert.transformer.layer.5.sa_layer_norm.bias', 'm_teacher.distilbert.transformer.layer.5.attention.v_lin.bias', 'm_student.distilbert.transformer.layer.3.output_layer_norm.weight', 'm_teacher.distilbert.transformer.layer.3.attention.q_lin.weight', 'm_student.distilbert.transformer.layer.0.attention.out_lin.weight', 'm_student.distilbert.transformer.layer.4.sa_layer_norm.weight', 'm_teacher.distilbert.transformer.layer.0.ffn.lin2.bias', 'm_teacher.distilbert.transformer.layer.3.ffn.lin1.bias', 'm_student.distilbert.transformer.layer.5.attention.out_lin.bias', 'm_student.distilbert.transformer.layer.2.ffn.lin2.weight', 'm_student.distilbert.transformer.layer.2.ffn.lin2.bias', 'm_student.distilbert.transformer.layer.4.attention.v_lin.bias', 'm_student.distilbert.transformer.layer.4.sa_layer_norm.bias', 'm_teacher.distilbert.transformer.layer.1.attention.out_lin.bias', 'm_teacher.distilbert.transformer.layer.5.attention.q_lin.weight', 'm_teacher.distilbert.transformer.layer.4.attention.k_lin.bias', 'm_student.distilbert.transformer.layer.1.sa_layer_norm.weight', 'm_student.distilbert.transformer.layer.1.attention.out_lin.weight', 'm_teacher.distilbert.transformer.layer.1.ffn.lin2.bias', 'm_teacher.distilbert.transformer.layer.4.ffn.lin2.weight', 'm_teacher.distilbert.transformer.layer.1.sa_layer_norm.weight', 'm_teacher.distilbert.transformer.layer.1.attention.q_lin.weight', 'm_student.distilbert.transformer.layer.4.attention.k_lin.weight', 'm_student.distilbert.transformer.layer.1.attention.out_lin.bias', 'm_student.distilbert.transformer.layer.1.attention.v_lin.weight', 'm_teacher.distilbert.transformer.layer.2.sa_layer_norm.weight', 'm_teacher.distilbert.transformer.layer.1.ffn.lin1.weight', 'm_student.distilbert.transformer.layer.5.attention.v_lin.bias', 'm_teacher.distilbert.transformer.layer.2.ffn.lin2.weight', 'm_student.distilbert.transformer.layer.3.attention.out_lin.bias', 'm_student.distilbert.transformer.layer.2.attention.out_lin.weight', 'm_teacher.distilbert.transformer.layer.5.attention.q_lin.bias', 'm_student.distilbert.transformer.layer.4.ffn.lin1.weight', 'm_student.distilbert.transformer.layer.2.sa_layer_norm.weight', 'm_student.distilbert.transformer.layer.0.attention.k_lin.weight', 'm_teacher.distilbert.transformer.layer.0.attention.k_lin.weight', 'm_teacher.distilbert.transformer.layer.4.attention.k_lin.weight', 'm_student.distilbert.transformer.layer.5.attention.k_lin.bias', 'm_student.distilbert.transformer.layer.1.ffn.lin2.weight', 'm_teacher.distilbert.transformer.layer.3.attention.k_lin.bias', 'm_student.distilbert.transformer.layer.2.ffn.lin1.bias', 'm_student.distilbert.transformer.layer.0.attention.q_lin.bias', 'm_student.distilbert.transformer.layer.2.sa_layer_norm.bias', 'm_student.distilbert.transformer.layer.4.output_layer_norm.bias', 'm_teacher.distilbert.transformer.layer.2.ffn.lin1.weight', 'm_teacher.distilbert.transformer.layer.5.sa_layer_norm.weight', 'm_student.distilbert.transformer.layer.0.output_layer_norm.weight', 'm_teacher.distilbert.transformer.layer.3.ffn.lin2.weight', 'm_student.distilbert.transformer.layer.5.ffn.lin2.bias', 'm_teacher.distilbert.transformer.layer.5.attention.k_lin.weight', 'm_student.distilbert.transformer.layer.1.ffn.lin2.bias', 'm_teacher.distilbert.transformer.layer.4.attention.q_lin.weight', 'm_student.distilbert.transformer.layer.1.attention.k_lin.bias', 'm_student.distilbert.transformer.layer.3.attention.k_lin.weight', 'm_student.distilbert.transformer.layer.5.sa_layer_norm.weight', 'm_teacher.distilbert.transformer.layer.0.ffn.lin2.weight', 'm_student.distilbert.transformer.layer.2.attention.q_lin.bias', 'm_student.distilbert.transformer.layer.2.attention.out_lin.bias', 'm_teacher.distilbert.transformer.layer.2.attention.q_lin.bias', 'm_teacher.distilbert.transformer.layer.0.attention.v_lin.weight', 'm_student.distilbert.transformer.layer.3.output_layer_norm.bias', 'm_student.distilbert.transformer.layer.0.ffn.lin2.weight', 'm_student.distilbert.transformer.layer.5.attention.q_lin.bias', 'm_student.distilbert.transformer.layer.0.attention.out_lin.bias', 'm_teacher.distilbert.transformer.layer.3.attention.q_lin.bias', 'm_student.distilbert.embeddings.position_embeddings.weight', 'm_teacher.distilbert.transformer.layer.3.sa_layer_norm.bias', 'm_student.distilbert.transformer.layer.2.attention.k_lin.bias', 'm_teacher.distilbert.transformer.layer.0.attention.out_lin.bias', 'm_teacher.distilbert.transformer.layer.4.ffn.lin2.bias', 'm_student.distilbert.transformer.layer.3.ffn.lin2.bias', 'm_student.distilbert.transformer.layer.1.output_layer_norm.weight', 'm_student.distilbert.embeddings.word_embeddings.weight', 'm_student.distilbert.transformer.layer.4.ffn.lin1.bias', 'm_teacher.distilbert.transformer.layer.2.attention.out_lin.weight', 'm_teacher.distilbert.transformer.layer.1.ffn.lin2.weight', 'm_teacher.distilbert.transformer.layer.5.output_layer_norm.weight', 'm_student.distilbert.transformer.layer.3.attention.v_lin.bias', 'm_student.distilbert.transformer.layer.5.attention.out_lin.weight'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d76d82073e0f45c7aabff69338443cc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/scipy/sparse/_index.py:145: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "272474da416f4b24bcaa689ba3b01cd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/trainer.py:1624\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1622\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1623\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1624\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1625\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1629\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/scai/phd/aiz218323/Projects/xcai/xcai/learner.py:1403\u001b[0m, in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1400\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m steps_skipped) \u001b[38;5;241m/\u001b[39m steps_in_epoch\n\u001b[1;32m   1401\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 1403\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1404\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1405\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_substep_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/trainer.py:2412\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2410\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2411\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_evaluate:\n\u001b[0;32m-> 2412\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2413\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[1;32m   2415\u001b[0m     \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/scai/phd/aiz218323/Projects/xcai/xcai/learner.py:325\u001b[0m, in \u001b[0;36mXCLearner.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix, **gen_kwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m     gen_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maug_num_beams\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39maugmentation_num_beams\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather_function, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gen_kwargs  \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mgather, gen_kwargs\n\u001b[0;32m--> 325\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/trainer_seq2seq.py:166\u001b[0m, in \u001b[0;36mSeq2SeqTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix, **gen_kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mgather\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gen_kwargs \u001b[38;5;241m=\u001b[39m gen_kwargs\n\u001b[0;32m--> 166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/trainer.py:3229\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3226\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3228\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3229\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3230\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3231\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3232\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   3233\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   3234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3237\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3239\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m/scratch/scai/phd/aiz218323/Projects/xcai/xcai/learner.py:671\u001b[0m, in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, predict_with_generation, predict_with_representation, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m    668\u001b[0m eval_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(dataloader, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    670\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_perform_representation(unwrap_model(model)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m prediction_loss_only: \n\u001b[0;32m--> 671\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_lbl_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_perform_augmentation(unwrap_model(model)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m prediction_loss_only: \n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_aug_index(eval_dataset)\n",
      "File \u001b[0;32m/scratch/scai/phd/aiz218323/Projects/xcai/xcai/learner.py:434\u001b[0m, in \u001b[0;36m_build_lbl_index\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    431\u001b[0m     dataloader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_test_dataloader(dset)\n\u001b[1;32m    432\u001b[0m     rep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_representation(dataloader, representation_attribute\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mlabel_representation_attribute, \n\u001b[1;32m    433\u001b[0m                                   to_cpu\u001b[38;5;241m=\u001b[39m\u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midxs, IndexSearch))\n\u001b[0;32m--> 434\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43midxs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFailed to build `self.idxs`\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/scratch/scai/phd/aiz218323/Projects/xcai/xcai/representation/search.py:36\u001b[0m, in \u001b[0;36mIndexSearch.build\u001b[0;34m(self, data, info)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m hnswlib\u001b[38;5;241m.\u001b[39mIndex(space\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspace, dim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39minit_index(max_elements\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], ef_construction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mefc, M\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm)\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_items\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_threads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo \u001b[38;5;241m=\u001b[39m data,info\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mset_ef(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mefs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learn.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dce55ac-3985-4a8e-820d-75b5d7f7e2bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec6ba20-656c-4a0f-a99b-c566ead31e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dset = block.test.sample(n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3196d61e-ca7e-4ff3-b471-b723f02bcb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "metric = PrecRecl(block.n_lbl, valid_dset.data_lbl_filterer, prop=block.train.dset.data.data_lbl,\n",
    "                  pk=10, rk=200, rep_pk=[1, 3, 5, 10], rep_rk=[10, 100, 200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b824c3a2-8188-4d86-ab28-f7ab6bfeb7b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d311ce82d4a04934b5360fe0d384f7fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/scipy/sparse/_index.py:145: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "o = learn.predict(valid_dset.dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2c3feb-0829-416d-bf4e-9c8386ab718b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8a1926-b32a-45d4-ac85-f15bd8467bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "if __name__ == '__main__':\n",
    "    mp.freeze_support()\n",
    "    learn.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
