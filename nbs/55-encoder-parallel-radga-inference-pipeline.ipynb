{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c676b088",
   "metadata": {},
   "source": [
    "# RADGA Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2152dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp 55-encoder-parallel-radga-inference-pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba43b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45e7ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os,sys,torch,pickle,torch.multiprocessing as mp, pickle\n",
    "from xcai.basics import *\n",
    "from xcai.models.radga import RAD001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92fc136",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['WANDB_MODE'] = 'disabled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9ac7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '12,13'\n",
    "os.environ['WANDB_PROJECT']='xc-nlg_55-encoder-parallel-radga-inference-pipeline'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1fff24",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b04137",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from packaging import version\n",
    "import torch, re, math, numpy as np, os, time, datasets\n",
    "from typing import Any, Tuple, Optional, Sequence, Union, Dict, List, NamedTuple\n",
    "from transformers import AutoTokenizer, BatchEncoding, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler\n",
    "\n",
    "from torch.nn.parallel import DataParallel\n",
    "from torch.nn.parallel._functions import Scatter\n",
    "from torch.nn.parallel.scatter_gather import _is_namedtuple\n",
    "\n",
    "from xcai.core import *\n",
    "from xcai.data import *\n",
    "from xcai.representation.search import *\n",
    "from xcai.generation.trie import *\n",
    "from xcai.generation.generate import *\n",
    "from xcai.clustering.cluster import *\n",
    "\n",
    "from fastcore.utils import *\n",
    "from fastcore.meta import *\n",
    "from fastcore.dispatch import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45c953e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.trainer_pt_utils import (\n",
    "    find_batch_size, \n",
    "    nested_concat, nested_numpify, \n",
    "    IterableDatasetShard, \n",
    "    get_dataloader_sampler, \n",
    "    get_model_param_count,\n",
    "    LengthGroupedSampler\n",
    ")\n",
    "from transformers.trainer_utils import has_length, denumpify_detensorize, speed_metrics, TrainOutput, HPSearchBackend, seed_worker\n",
    "from transformers.trainer_callback import TrainerState\n",
    "from transformers.trainer import _is_peft_model\n",
    "from transformers.modeling_utils import unwrap_model\n",
    "from transformers.utils import is_sagemaker_mp_enabled, is_accelerate_available, is_torch_tpu_available, logging, is_datasets_available\n",
    "from transformers.debug_utils import DebugOption, DebugUnderflowOverflow\n",
    "\n",
    "from transformers.integrations import hp_params\n",
    "from transformers.integrations.tpu import tpu_spmd_dataloader\n",
    "from transformers.integrations.deepspeed import deepspeed_init, deepspeed_load_checkpoint, is_deepspeed_available\n",
    "\n",
    "if is_accelerate_available():\n",
    "    from accelerate import Accelerator, skip_first_batches\n",
    "    from accelerate import __version__ as accelerate_version\n",
    "    from accelerate.utils import (\n",
    "        DistributedDataParallelKwargs,\n",
    "        DistributedType,\n",
    "        GradientAccumulationPlugin,\n",
    "        load_fsdp_model,\n",
    "        load_fsdp_optimizer,\n",
    "        save_fsdp_model,\n",
    "        save_fsdp_optimizer,\n",
    "    )\n",
    "\n",
    "    DATA_SAMPLERS = [RandomSampler]\n",
    "    if version.parse(accelerate_version) > version.parse(\"0.23.0\"):\n",
    "        from accelerate.data_loader import SeedableRandomSampler\n",
    "\n",
    "        DATA_SAMPLERS += [SeedableRandomSampler]\n",
    "\n",
    "    if is_deepspeed_available():\n",
    "        from accelerate.utils import DeepSpeedSchedulerWrapper\n",
    "\n",
    "if is_accelerate_available(\"0.28.0\"):\n",
    "    from accelerate.utils import DataLoaderConfiguration\n",
    "\n",
    "TRAINING_ARGS_NAME = \"training_args.bin\"\n",
    "TRAINER_STATE_NAME = \"trainer_state.json\"\n",
    "OPTIMIZER_NAME = \"optimizer.pt\"\n",
    "OPTIMIZER_NAME_BIN = \"optimizer.bin\"\n",
    "SCHEDULER_NAME = \"scheduler.pt\"\n",
    "SCALER_NAME = \"scaler.pt\"\n",
    "FSDP_MODEL_NAME = \"pytorch_model_fsdp\"\n",
    "\n",
    "logger = logging.get_logger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca20f4b",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149ed7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/aiscuser/scratch/datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27153edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_dir = f'{data_dir}/processed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca7c9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{pkl_dir}/wikiseealso_data-metas_distilbert-base-uncased_rm_radga-final.pkl', 'rb') as file: \n",
    "    block = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418a8345",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{pkl_dir}/wikiseealso_data_distilbert-base-uncased_xcnlg_ngame.pkl', 'rb') as file: \n",
    "    test_block = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9c1f13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc327820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f'{pkl_dir}/wikititles_data-metas_distilbert-base-uncased_rm_radga-final.pkl', 'rb') as file: \n",
    "#     block = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502919a4",
   "metadata": {},
   "source": [
    "## MetaXCDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5706631",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def _verify_inputs(cls:MetaXCDataset):\n",
    "    cls.n_data,cls.n_meta = cls.data_meta.shape[0],cls.data_meta.shape[1]\n",
    "    \n",
    "    if cls.lbl_meta is not None:\n",
    "        cls.n_lbl = cls.lbl_meta.shape[0]\n",
    "        if cls.lbl_meta.shape[1] != cls.n_meta:\n",
    "            raise ValueError(f'`lbl_meta`({cls.lbl_meta.shape[1]}) should have same number of columns as `data_meta`({cls.n_meta}).')\n",
    "\n",
    "    if cls.meta_info is not None:\n",
    "        n_meta = cls._verify_info(cls.meta_info)\n",
    "        if n_meta != cls.n_meta:\n",
    "            raise ValueError(f'`meta_info`({n_meta}) should have same number of entries as number of columns of `data_meta`({cls.n_meta})')\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1079e37e",
   "metadata": {},
   "source": [
    "## Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31495a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xcai.transform import PadFeatTfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42eefdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RadgaLearningArguments(XCLearningArguments):\n",
    "\n",
    "    @delegates(XCLearningArguments.__init__)\n",
    "    def __init__(self, \n",
    "                 data_aug_meta_name:Optional[str]=None,\n",
    "                 augmentation_num_beams:Optional[int]=3,\n",
    "                 predict_with_augmentation:Optional[bool]=False,\n",
    "                 use_augmentation_index_representation:Optional[bool]=False,\n",
    "                 metadata_representation_attribute:Optional[str]='data_repr',\n",
    "                 data_augmentation_attribute:Optional[str]='data_repr',\n",
    "                 **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        store_attr('data_aug_meta_name,augmentation_num_beams,predict_with_augmentation')\n",
    "        store_attr('use_augmentation_index_representation,metadata_representation_attribute,data_augmentation_attribute')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5221eb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RadgaLearner(XCLearner):\n",
    "    \n",
    "    def __init__(self, trie:Optional[Trie]=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.tbs = TrieBeamSearch(trie, self.args.generation_eos_token, n_bm=self.args.generation_num_beams, \n",
    "                                  len_penalty=self.args.generation_length_penalty, max_info=self.args.generation_max_info, **kwargs)\n",
    "\n",
    "        self.idxs = (\n",
    "            BruteForceSearch(n_bm=self.args.representation_num_beams)\n",
    "            if self.args.representation_search_type == 'BRUTEFORCE' else\n",
    "            IndexSearch(space=self.args.index_space, efc=self.args.index_efc, m=self.args.index_m, \n",
    "                        efs=self.args.index_efs, n_bm=self.args.representation_num_beams, \n",
    "                        n_threads=self.args.index_num_threads) \n",
    "        )\n",
    "        self.aug_idxs, self.aug_info = None, None \n",
    "        self.aug_pad = PadFeatTfm(pad_tok=self.model.config.pad_token_id, prefix=\"meta\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64388339",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def _perform_augmentation(self:RadgaLearner, model:nn.Module, predict_with_augmentation:Optional[bool]=None):\n",
    "    model = unwrap_model(model)\n",
    "    predict_with_augmentation = self.args.predict_with_augmentation if predict_with_augmentation is None else predict_with_augmentation\n",
    "    return getattr(model,'use_augmentation') if hasattr(model,'use_augmentation') else predict_with_augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de0d635",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def get_meta_representation(self:XCLearner, dataloader: DataLoader, to_cpu:Optional[bool]=True):\n",
    "    data_host, all_data = None, None\n",
    "    \n",
    "    if hasattr(self.model, 'disable_noise') and callable(getattr(self.model, 'disable_noise')):\n",
    "        use_noise = self.model.disable_noise()\n",
    "    \n",
    "    for step, inputs in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "        inputs = inputs.to(self.model.device)\n",
    "        with torch.no_grad(): data = getattr(self.model.get_meta_representation(**inputs), self.args.metadata_representation_attribute)\n",
    "        data_host = self._gather_host_output(data, data_host)\n",
    "        if self.args.representation_accumulation_steps is not None and (step + 1) % self.args.representation_accumulation_steps == 0:\n",
    "            all_data, data_host = self._gather_all_output(data_host, all_data, to_cpu=to_cpu), None\n",
    "            \n",
    "    if hasattr(self.model, 'disable_noise') and callable(getattr(self.model, 'disable_noise')):\n",
    "        self.model.set_noise(use_noise)\n",
    "            \n",
    "    return self._gather_all_output(data_host, all_data, to_cpu=to_cpu)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa1f72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def get_representation(self:XCLearner, dataloader: DataLoader, to_cpu:Optional[bool]=True):\n",
    "    data_host, all_data = None, None\n",
    "    \n",
    "    if hasattr(self.model, 'disable_noise') and callable(getattr(self.model, 'disable_noise')):\n",
    "        use_noise = self.model.disable_noise()\n",
    "    \n",
    "    for step, inputs in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "        inputs = inputs.to(self.model.device)\n",
    "        with torch.no_grad(): data = getattr(self.model(**inputs), self.args.representation_attribute)\n",
    "        data_host = self._gather_host_output(data, data_host)\n",
    "        if self.args.representation_accumulation_steps is not None and (step + 1) % self.args.representation_accumulation_steps == 0:\n",
    "            all_data, data_host = self._gather_all_output(data_host, all_data, to_cpu=to_cpu), None\n",
    "            \n",
    "    if hasattr(self.model, 'disable_noise') and callable(getattr(self.model, 'disable_noise')):\n",
    "        self.model.set_noise(use_noise)\n",
    "            \n",
    "    return self._gather_all_output(data_host, all_data, to_cpu=to_cpu)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8aeaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def _build_aug_index(self:RadgaLearner, dataset:Optional[Dataset]=None):\n",
    "    dataset = dataset if self.eval_dataset is None else self.eval_dataset\n",
    "    dataset = dataset if self.train_dataset is None else self.train_dataset\n",
    "    \n",
    "    aug_meta_name = f'{self.args.data_aug_meta_name}_meta' if self.args.data_aug_meta_name is not None else None\n",
    "    if (\n",
    "        dataset is not None and dataset.meta is not None and aug_meta_name is not None and \n",
    "        aug_meta_name in dataset.meta\n",
    "    ):\n",
    "        self.aug_idxs = IndexSearch(space=self.args.index_space, efc=self.args.index_efc, m=self.args.index_m, \n",
    "                                    efs=self.args.index_efs, n_bm=self.args.representation_num_beams, \n",
    "                                    n_threads=self.args.index_num_threads)\n",
    "        \n",
    "        self.aug_info = getattr(dataset.meta[aug_meta_name], 'meta_info')\n",
    "        \n",
    "        aug_dset = MainXCDataset(self.aug_info)\n",
    "        aug_dl = self.get_test_dataloader(aug_dset)\n",
    "        aug_repr = self.get_meta_representation(aug_dl, to_cpu=isinstance(self.aug_idxs, IndexSearch))\n",
    "        self.aug_idxs.build(aug_repr)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b042f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def _build_lbl_index(self:XCLearner, dataset:Optional[Dataset]=None):\n",
    "    dataset = dataset if self.eval_dataset is None else self.eval_dataset\n",
    "    dataset = dataset if self.train_dataset is None else self.train_dataset\n",
    "    \n",
    "    if dataset is not None:\n",
    "        lbl_dset = dataset.lbl_dset\n",
    "        \n",
    "        meta_name = f'{self.args.data_aug_meta_name}_meta' if self.args.data_aug_meta_name is not None else None\n",
    "        if meta_name is not None and dataset.meta is not None and meta_name in dataset.meta:\n",
    "            prefix,lbl_meta,meta_info  = dataset.meta[meta_name].prefix,dataset.meta[meta_name].lbl_meta,dataset.meta[meta_name].meta_info\n",
    "            meta_kwargs = {meta_name: MetaXCDataset(prefix, lbl_meta, lbl_meta, meta_info, n_data_meta_samples=self.args.augmentation_num_beams)}\n",
    "            lbl_dset = XCDataset(lbl_dset, **meta_kwargs)\n",
    "        \n",
    "        lbl_dl = self.get_test_dataloader(lbl_dset)\n",
    "        lbl_repr = self.get_representation(lbl_dl, to_cpu=isinstance(self.idxs, IndexSearch))\n",
    "        self.idxs.build(lbl_repr)\n",
    "    else: raise ValueError('Failed to build `self.idxs`')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d024fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def evaluate(self:RadgaLearner, eval_dataset:Optional[Dataset]=None, ignore_keys:Optional[List[str]]=None, \n",
    "             metric_key_prefix:str=\"eval\", **gen_kwargs):\n",
    "    gen_kwargs = gen_kwargs.copy()\n",
    "    if gen_kwargs.get(\"length_penalty\") is None and self.args.generation_length_penalty is not None:\n",
    "        gen_kwargs[\"length_penalty\"] = self.args.generation_length_penalty\n",
    "    if gen_kwargs.get(\"gen_num_beams\") is None and self.args.generation_num_beams is not None:\n",
    "        gen_kwargs[\"gen_num_beams\"] = self.args.generation_num_beams\n",
    "    if gen_kwargs.get(\"repr_num_beams\") is None and self.args.representation_num_beams is not None:\n",
    "        gen_kwargs[\"repr_num_beams\"] = self.args.representation_num_beams\n",
    "    if gen_kwargs.get(\"aug_num_beams\") is None and self.args.augmentation_num_beams is not None:\n",
    "        gen_kwargs[\"aug_num_beams\"] = self.args.augmentation_num_beams\n",
    "        \n",
    "    self.gather_function, self._gen_kwargs  = self.accelerator.gather, gen_kwargs\n",
    "        \n",
    "    if self._perform_representation(unwrap_model(self.model)) and not self.args.prediction_loss_only: \n",
    "        self._build_lbl_index(eval_dataset)\n",
    "        \n",
    "    if self._perform_augmentation(unwrap_model(self.model)) and not self.args.prediction_loss_only: \n",
    "        self._build_aug_index(eval_dataset)\n",
    "\n",
    "    return super().evaluate(eval_dataset, ignore_keys=ignore_keys, metric_key_prefix=metric_key_prefix)\n",
    "\n",
    "@patch\n",
    "def predict(self:RadgaLearner, test_dataset: Dataset, ignore_keys:Optional[List[str]]=None, \n",
    "            metric_key_prefix:str=\"test\", **gen_kwargs):\n",
    "    gen_kwargs = gen_kwargs.copy()\n",
    "    if gen_kwargs.get(\"length_penalty\") is None and self.args.generation_length_penalty is not None:\n",
    "        gen_kwargs[\"length_penalty\"] = self.args.generation_length_penalty\n",
    "    if gen_kwargs.get(\"gen_num_beams\") is None and self.args.generation_num_beams is not None:\n",
    "        gen_kwargs[\"gen_num_beams\"] = self.args.generation_num_beams\n",
    "    if gen_kwargs.get(\"repr_num_beams\") is None and self.args.representation_num_beams is not None:\n",
    "        gen_kwargs[\"repr_num_beams\"] = self.args.representation_num_beams\n",
    "    if gen_kwargs.get(\"aug_num_beams\") is None and self.args.augmentation_num_beams is not None:\n",
    "        gen_kwargs[\"aug_num_beams\"] = self.args.augmentation_num_beams\n",
    "\n",
    "    self.gather_function, self._gen_kwargs = self.accelerator.gather, gen_kwargs\n",
    "    self._memory_tracker.start()\n",
    "    \n",
    "    if self._perform_representation(unwrap_model(self.model)) and not self.args.prediction_loss_only: \n",
    "        self._build_lbl_index(test_dataset)\n",
    "        \n",
    "    if self._perform_augmentation(unwrap_model(self.model)) and not self.args.prediction_loss_only: \n",
    "        self._build_aug_index(test_dataset)\n",
    "\n",
    "    test_dataloader = self.get_test_dataloader(test_dataset)\n",
    "    start_time = time.time()\n",
    "\n",
    "    output = self.evaluation_loop(test_dataloader, description=\"Prediction\", ignore_keys=ignore_keys, metric_key_prefix=metric_key_prefix)\n",
    "    total_batch_size = self.args.eval_batch_size * self.args.world_size\n",
    "    if f\"{metric_key_prefix}_jit_compilation_time\" in output.metrics:\n",
    "        start_time += output.metrics[f\"{metric_key_prefix}_jit_compilation_time\"]\n",
    "    output.metrics.update(\n",
    "        speed_metrics(metric_key_prefix,start_time,num_samples=output.num_samples,num_steps=math.ceil(output.num_samples / total_batch_size),)\n",
    "    )\n",
    "    self.control = self.callback_handler.on_predict(self.args, self.state, self.control, output.metrics)\n",
    "    self._memory_tracker.stop_and_update_metrics(output.metrics)\n",
    "    return XCPredictionOutput(pred_idx=output.pred_idx, pred_ptr=output.pred_ptr, pred_score=output.pred_score, \n",
    "                          gen_output=output.gen_output, repr_output=output.repr_output, metrics=output.metrics, \n",
    "                          num_samples=output.num_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3ed857",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def augmentation_output(\n",
    "    self:RadgaLearner,\n",
    "    model:nn.Module,\n",
    "    inputs:Dict[str, Union[torch.Tensor, Any]],\n",
    "    **kwargs\n",
    "):\n",
    "    if self.aug_idxs is None: raise ValueError('Augmentation `aug_idx` is not initialized.')\n",
    "        \n",
    "    inputs = self._prepare_inputs(inputs)\n",
    "    n_bm = kwargs.pop(\"aug_num_beams\") if \"aug_num_beams\" in kwargs and kwargs[\"aug_num_beams\"] is not None else self.args.augmentation_num_beams\n",
    "    \n",
    "    with torch.no_grad(): o = getattr(model(**inputs), self.args.data_augmentation_attribute)\n",
    "    o = self.aug_idxs.proc(o, n_bm=n_bm)\n",
    "    \n",
    "    aug_info = self.aug_pad({\n",
    "        'meta_input_ids':[self.aug_info['input_ids'][i] for i in o['info2data_idx']], \n",
    "        'meta_attention_mask':[self.aug_info['input_ids'][i] for i in o['info2data_idx']]\n",
    "    })\n",
    "    \n",
    "    if self.args.use_augmentation_index_representation:\n",
    "        meta_repr = torch.tensor(self.aug_idxs.index.get_items(o['info2data_idx']))\n",
    "        return {\n",
    "            f'{self.args.data_aug_meta_name}2data_meta_repr': meta_repr,\n",
    "            f'{self.args.data_aug_meta_name}2data_attention_mask': aug_info['meta_attention_mask'],\n",
    "            f'{self.args.data_aug_meta_name}2data_data2ptr': o['info2data_data2ptr'],\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            f'{self.args.data_aug_meta_name}2data_idx':o['info2data_idx'], \n",
    "            f'{self.args.data_aug_meta_name}2data_input_ids': aug_info['meta_input_ids'], \n",
    "            f'{self.args.data_aug_meta_name}2data_attention_mask': aug_info['meta_attention_mask'],\n",
    "            f'{self.args.data_aug_meta_name}2data_data2ptr': o['info2data_data2ptr']\n",
    "        }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66b8110",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def prediction_step(\n",
    "    self:RadgaLearner,\n",
    "    model: nn.Module,\n",
    "    inputs: Dict[str, Union[torch.Tensor, Any]],\n",
    "    prediction_loss_only: bool,\n",
    "    predict_with_generation: bool,\n",
    "    predict_with_representation: bool,\n",
    "    predict_with_augmentation:Optional[bool]=None,\n",
    "    ignore_keys: Optional[List[str]] = None,\n",
    "    **kwargs,\n",
    ") -> Tuple[Optional[float], Optional[torch.Tensor], Optional[torch.Tensor]]:\n",
    "    with torch.no_grad():\n",
    "        with self.compute_loss_context_manager(): outputs = model(**inputs)\n",
    "        loss = (outputs[\"loss\"] if isinstance(outputs, dict) else outputs[0]).mean().detach()\n",
    "    prediction_loss_only = self.args.prediction_loss_only if prediction_loss_only is None else prediction_loss_only\n",
    "    if prediction_loss_only: return loss, {}\n",
    "    \n",
    "    if self._perform_augmentation(model, predict_with_augmentation): \n",
    "        aug_inputs = self.augmentation_output(model, inputs, **kwargs)\n",
    "        inputs.update(aug_inputs)\n",
    "        \n",
    "    output, gen_o, repr_o = None, None, None\n",
    "    if self._perform_generation(model, predict_with_generation): gen_o = self.generation_output(model, inputs, **kwargs)\n",
    "    if self._perform_representation(model, predict_with_representation): repr_o = self.representation_output(model, inputs, **kwargs)\n",
    "    \n",
    "    if gen_o is not None and repr_o is not None:\n",
    "        output = {f'{k}_gen':v for k,v in gen_o.items()}\n",
    "        output.update({f'{k}_repr':v for k,v in repr_o.items()})\n",
    "        output.update(self.concatenate_output(gen_o, repr_o))\n",
    "    else:\n",
    "        output = gen_o if repr_o is None else repr_o\n",
    "        \n",
    "    labels = {'targ_idx':inputs[self.args.target_indices_key], 'targ_ptr':inputs[self.args.target_pointer_key]} if self.args.target_indices_key in inputs else None\n",
    "    if labels is not None: output.update(labels)\n",
    "    \n",
    "    return loss, output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdef79f0",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bbfd31",
   "metadata": {},
   "source": [
    "## `RAD002`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f985de2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xcai.models.radga import Encoder, RAD001, EncoderOutput, RADOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e456ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parameters:\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_meta_aug_prefix(prefix:str, **kwargs):\n",
    "        inputs = {}\n",
    "        args = [arg for arg in kwargs if prefix is not None and re.match(f'^{prefix}.*_(input_ids|attention_mask|data2ptr|meta_repr)$', arg)]\n",
    "        for arg in args:\n",
    "            meta,param = arg.split('_', maxsplit=1)\n",
    "            inputs.setdefault(meta, {})[param] = kwargs[arg]\n",
    "        return inputs\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_feat_meta_aug_prefix(feat:str, prefix:str, **kwargs):\n",
    "        keys = ['attention_mask', 'input_ids', 'meta_repr']\n",
    "        \n",
    "        inputs = {f'{prefix}_{k}': kwargs[f'{prefix}_{k}'] for k in keys if f'{prefix}_{k}' in kwargs}\n",
    "        if prefix is not None and f'{prefix}_{feat}2ptr' in kwargs:\n",
    "            inputs.update({f'{prefix}_data2ptr': kwargs[f'{prefix}_{feat}2ptr']})\n",
    "        return inputs\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_meta_pred_prefix(prefix:str, **kwargs):\n",
    "        inputs = {}\n",
    "        args = [arg for arg in kwargs if prefix is not None and re.match(f'^[p]?{prefix}.*', arg)]\n",
    "        for arg in args:\n",
    "            meta,param = arg.split('_', maxsplit=1)\n",
    "            if arg[0] == 'p': \n",
    "                inputs.setdefault(meta[1:], {})[f'p{param}'] = kwargs[arg]\n",
    "            else: \n",
    "                inputs.setdefault(meta, {})[param] = kwargs[arg]\n",
    "        return inputs\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_meta_loss_weights(lw:Union[float,List], n_meta:int):\n",
    "        if isinstance(lw, float):\n",
    "            lw = lw/n_meta if n_meta else None\n",
    "            return [lw] * n_meta\n",
    "        else:\n",
    "            if len(lw) != n_meta: raise ValueError(f'length of `lw` should be equal to number of metadata.')\n",
    "            return lw\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82424b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAD002Encoder(Encoder):\n",
    "    \n",
    "    def __init__(self, config, **kwargs):\n",
    "        super().__init__(config, **kwargs)\n",
    "        \n",
    "    def fuse_meta_into_embeddings(self, embed:torch.Tensor, attention_mask:torch.Tensor, prefix:str, **kwargs):\n",
    "        meta_kwargs = Parameters.from_meta_aug_prefix(prefix, **kwargs)\n",
    "        meta_repr, weights, performed_fusion = {}, [], False\n",
    "        \n",
    "        for m_key, m_args in meta_kwargs.items():\n",
    "            idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
    "            meta_repr[m_key] = torch.empty(0, self.config.dim).to(embed)\n",
    "            if len(idx):\n",
    "                performed_fusion = True\n",
    "                if 'meta_repr' in m_args:\n",
    "                    m_repr,m_repr_mask = m_args['meta_repr'],torch.any(m_args['attention_mask'], dim=1).long().view(-1,1)\n",
    "                    m_repr,m_repr_mask = self.resize(m_repr, m_repr_mask, m_args['data2ptr'][idx])\n",
    "                    m_repr_mask = m_repr_mask.bool()\n",
    "                else:\n",
    "                    m_input_ids, m_attention_mask = self.resize(m_args['input_ids'], m_args['attention_mask'], \n",
    "                                                                m_args['data2ptr'][idx])\n",
    "\n",
    "                    if self.use_noise:\n",
    "                        n_input_ids, n_attention_mask = self.get_noise(m_args['input_ids'], m_args['attention_mask'], \n",
    "                                                                       m_args['data2ptr'][idx])\n",
    "                        m_input_ids, m_attention_mask = self.add_noise(m_input_ids, m_attention_mask, \n",
    "                                                                       n_input_ids, n_attention_mask)\n",
    "\n",
    "                    m_embed = self.encode(m_input_ids, m_attention_mask)[0]\n",
    "\n",
    "                    m_repr = self.meta_unnormalized(m_embed, m_attention_mask)\n",
    "                    m_repr_mask = torch.any(m_attention_mask, dim=1)\n",
    "                    \n",
    "                m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.view(len(idx), -1)\n",
    "                \n",
    "                meta_repr[m_key] = m_repr[:, :-1][m_repr_mask[:, :-1]] if self.use_noise else m_repr[m_repr_mask]\n",
    "                meta_repr[m_key] = F.normalize(meta_repr[m_key], dim=1)\n",
    "                \n",
    "                fused_embed, w = self.cross_head(embed[idx], attention_mask[idx], m_repr, m_repr_mask, output_attentions=True)\n",
    "                embed[idx] += fused_embed\n",
    "                weights.append(w)\n",
    "        \n",
    "        if performed_fusion: embed = self.linear_layer(embed)        \n",
    "        return embed, weights, meta_repr\n",
    "    \n",
    "    def forward(\n",
    "        self, \n",
    "        data_input_ids: torch.Tensor, \n",
    "        data_attention_mask: torch.Tensor,\n",
    "        data_aug_meta_prefix: Optional[str]=None,\n",
    "        data_gen_idx:Optional[torch.Tensor]=None,\n",
    "        data_type:Optional[str]=None,\n",
    "        data_unnormalized:Optional[bool]=False,\n",
    "        **kwargs\n",
    "    ):\n",
    "        data_o = self.encode(data_input_ids, data_attention_mask)\n",
    "        \n",
    "        if data_type is not None and data_type == \"meta\":\n",
    "            data_repr = self.meta_unnormalized(data_o[0], data_attention_mask) if data_unnormalized else self.meta(data_o[0], data_attention_mask)\n",
    "        else: \n",
    "            data_repr = self.dr(data_o[0], data_attention_mask)\n",
    "        \n",
    "        data_fused_repr = data_fused_logits = fusion_weights = meta_repr = None\n",
    "        if data_aug_meta_prefix is not None:\n",
    "            data_fused_embed, fusion_weights, meta_repr = self.fuse_meta_into_embeddings(data_o[0], \n",
    "                                                                                         data_attention_mask, \n",
    "                                                                                         data_aug_meta_prefix, \n",
    "                                                                                         **kwargs)\n",
    "            data_fused_repr = self.dr(data_fused_embed, data_attention_mask)\n",
    "            data_fused_logits = self.gen(data_fused_embed if data_gen_idx is None else data_fused_embed[data_gen_idx])\n",
    "        \n",
    "        return EncoderOutput(\n",
    "            rep=data_repr,\n",
    "            fused_rep=data_fused_repr,\n",
    "            logits=data_fused_logits,\n",
    "            \n",
    "            meta_repr=meta_repr,\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3996e29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAD002(RAD001):\n",
    "    \n",
    "    def __init__(self, config, **kwargs):\n",
    "        super().__init__(config, **kwargs)\n",
    "        \n",
    "        self.encoder = RAD002Encoder(config, use_noise=kwargs['use_noise'], resize_length=kwargs['resize_length'])\n",
    "        self.post_init()\n",
    "        self.remap_post_init()\n",
    "        self.init_retrieval_head()\n",
    "        \n",
    "    def disable_noise(self):\n",
    "        use_noise = self.encoder.module.use_noise if isinstance(self.encoder, XCDataParallel) else self.encoder.use_noise\n",
    "        if isinstance(self.encoder, XCDataParallel): self.encoder.module.use_noise = False\n",
    "        else: self.encoder.use_noise = False\n",
    "        return use_noise\n",
    "    \n",
    "    def set_noise(self, use_noise):\n",
    "        if isinstance(self.encoder, XCDataParallel): self.encoder.module.use_noise = use_noise\n",
    "        else: self.encoder.use_noise = use_noise\n",
    "            \n",
    "    def get_noise(self):\n",
    "        return self.encoder.module.use_noise if isinstance(self.encoder, XCDataParallel) else self.encoder.use_noise\n",
    "        \n",
    "        \n",
    "    def get_meta_representation(\n",
    "        self,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        if self.use_encoder_parallel: \n",
    "            encoder = XCDataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "            \n",
    "        data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
    "                         data_unnormalized=True, data_type=\"meta\")\n",
    "        return RADOutput(\n",
    "            logits=data_o.logits,\n",
    "            data_repr=data_o.rep,\n",
    "            data_fused_repr=data_o.fused_rep,\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        lbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        lbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        lbl2data_input_ids:Optional[torch.Tensor]=None,\n",
    "        lbl2data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        plbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        plbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "        **kwargs\n",
    "    ):  \n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        \n",
    "        if self.use_encoder_parallel: \n",
    "            encoder = XCDataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "        \n",
    "        data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
    "        data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
    "                         data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
    "        \n",
    "        \n",
    "        loss = None; lbl2data_o = EncoderOutput()\n",
    "        if lbl2data_input_ids is not None:\n",
    "            lbl2data_gen_idx = self.get_last_item_mask(lbl2data_data2ptr, len(lbl2data_idx))\n",
    "            lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
    "            \n",
    "            lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
    "                                 data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, data_gen_idx=lbl2data_gen_idx,\n",
    "                                 **lbl2data_meta_kwargs)\n",
    "            \n",
    "            loss = self.compute_loss(data_o.logits, data_o.fused_rep, lbl2data_o.logits, lbl2data_o.fused_rep, \n",
    "                                     data_input_ids,lbl2data_input_ids,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                     plbl2data_data2ptr,plbl2data_idx)\n",
    "            \n",
    "            loss += self.compute_meta_loss(data_o.fused_rep, lbl2data_o.fused_rep, **kwargs)\n",
    "            \n",
    "            if self.use_fusion_loss:\n",
    "                loss += self.compute_fusion_loss(data_o.fused_rep, data_o.meta_repr, self.data_aug_meta_prefix, **kwargs)\n",
    "                loss += self.compute_fusion_loss(lbl2data_o.fused_rep, lbl2data_o.meta_repr, self.lbl2data_aug_meta_prefix, **kwargs)\n",
    "            \n",
    "        if not return_dict:\n",
    "            o = (data_o.logits,data_o.rep,data_o.fused_rep,lbl2data_o.logits,lbl2data_o.rep,lbl2data_o.fused_rep)\n",
    "            return ((loss,) + o) if loss is not None else o\n",
    "        \n",
    "        \n",
    "        return RADOutput(\n",
    "            loss=loss,\n",
    "            \n",
    "            logits=data_o.logits,\n",
    "            data_repr=data_o.rep,\n",
    "            data_fused_repr=data_o.fused_rep,\n",
    "            \n",
    "            lbl2data_repr=lbl2data_o.rep,\n",
    "            lbl2data_fused_repr=lbl2data_o.fused_rep,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567993f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f352d493",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = RadgaLearningArguments(\n",
    "    output_dir='/home/aiscuser/outputs/48-encoder-parallel-radga-with-cross-attention-loss-component-for-wikiseealso-1-0',\n",
    "    per_device_train_batch_size=200,\n",
    "    per_device_eval_batch_size=100,\n",
    "    representation_num_beams=200,\n",
    "    representation_accumulation_steps=1,\n",
    "    predict_with_representation=True,\n",
    "    generation_num_beams=10,\n",
    "    generation_length_penalty=1.5,\n",
    "    predict_with_generation=True,\n",
    "    representation_search_type='INDEX',\n",
    "    output_concatenation_weight=1.0,\n",
    "    metric_for_best_model='P@1_REPR',\n",
    "    target_indices_key='plbl2data_idx',\n",
    "    target_pointer_key='plbl2data_data2ptr',\n",
    "    \n",
    "    \n",
    "    augmentation_num_beams=3,\n",
    "    data_aug_meta_name='hlk',\n",
    "    \n",
    "    representation_attribute='data_fused_repr',\n",
    "    data_augmentation_attribute='data_repr',\n",
    "    metadata_representation_attribute='data_repr',\n",
    "    \n",
    "    use_augmentation_index_representation=True,\n",
    "    \n",
    "    predict_with_augmentation=False,\n",
    "    \n",
    "    use_encoder_parallel=True,\n",
    "    fp16=True,\n",
    "    label_names=['cat2data_idx', 'cat2data_input_ids', 'cat2data_attention_mask',\n",
    "                 'cat2lbl2data_idx', 'cat2lbl2data_input_ids', 'cat2lbl2data_attention_mask',\n",
    "                 'hlk2data_idx', 'hlk2data_input_ids', 'hlk2data_attention_mask',\n",
    "                 'hlk2lbl2data_idx', 'hlk2lbl2data_input_ids', 'hlk2lbl2data_attention_mask',],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300bc357",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = f\"/home/aiscuser/scratch/Projects/xc_nlg/outputs/{os.path.basename(args.output_dir)}\"\n",
    "mname = f'{output_dir}/{os.path.basename(get_best_model(output_dir))}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62236810",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750743a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bsz = max(args.per_device_train_batch_size, args.per_device_eval_batch_size)*torch.cuda.device_count()\n",
    "\n",
    "model = RAD002.from_pretrained(mname, num_batch_labels=5000, ignore_token=0, batch_size=bsz,\n",
    "                               margin=0.3, num_negatives=5, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='hlk2data', lbl2data_aug_meta_prefix='hlk2lbl', \n",
    "                               resize_length=5000,\n",
    "                               \n",
    "                               gen_loss_weight=0.001, meta_loss_weight=0.3, pred_meta_prefix='cat', \n",
    "                               \n",
    "                               fusion_loss_weight=0.05, tie_word_embeddings=False,\n",
    "                               \n",
    "                               use_fusion_loss=False, use_noise=False, use_encoder_parallel=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98c725f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0d2984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "985c7a4610884e1395cc508310c71fa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/312330 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trie = XCTrie.from_block(block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba836e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f97e2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = PrecRecl(block.n_lbl, block.train.data_lbl_filterer, prop=block.train.dset.data.data_lbl,\n",
    "                  pk=10, rk=200, rep_pk=[1, 3, 5, 10], rep_rk=[10, 100, 200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ded2ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = RadgaLearner(\n",
    "    model=model, \n",
    "    args=args,\n",
    "    trie=trie,\n",
    "    train_dataset=block.train.dset,\n",
    "    eval_dataset=block.test.dset,\n",
    "    data_collator=block.collator,\n",
    "    compute_metrics=metric,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ca6487",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9bdd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.use_generation = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960fe390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-11 12:37:18,228] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a37c8f61d55f4c37a4051c1c0a202b50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1562 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node-0:273706:273706 [0] NCCL INFO Bootstrap : Using eth0:10.13.51.163<0>\n",
      "node-0:273706:273706 [0] NCCL INFO NET/Plugin : Plugin load (librccl-net.so) returned 2 : librccl-net.so: cannot open shared object file: No such file or directory\n",
      "node-0:273706:273706 [0] NCCL INFO NET/Plugin : No plugin found, using internal implementation\n",
      "node-0:273706:273706 [0] NCCL INFO Kernel version: 5.15.0-1042-azure\n",
      "RCCL version 2.17.1+hip5.7 HEAD:cbbb3d8+\n",
      "\n",
      "node-0:273706:279073 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/misc/ibvwrap.cc:222 NCCL WARN Call to ibv_open_device failed\n",
      "\n",
      "node-0:273706:279073 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/transport/net_ib.cc:199 NCCL WARN NET/IB : Unable to open device mlx5_0\n",
      "\n",
      "node-0:273706:279073 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/misc/ibvwrap.cc:222 NCCL WARN Call to ibv_open_device failed\n",
      "\n",
      "node-0:273706:279073 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/transport/net_ib.cc:199 NCCL WARN NET/IB : Unable to open device mlx5_1\n",
      "\n",
      "node-0:273706:279073 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/misc/ibvwrap.cc:222 NCCL WARN Call to ibv_open_device failed\n",
      "\n",
      "node-0:273706:279073 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/transport/net_ib.cc:199 NCCL WARN NET/IB : Unable to open device mlx5_2\n",
      "\n",
      "node-0:273706:279073 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/misc/ibvwrap.cc:222 NCCL WARN Call to ibv_open_device failed\n",
      "\n",
      "node-0:273706:279073 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/transport/net_ib.cc:199 NCCL WARN NET/IB : Unable to open device mlx5_3\n",
      "\n",
      "node-0:273706:279073 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/misc/ibvwrap.cc:222 NCCL WARN Call to ibv_open_device failed\n",
      "\n",
      "node-0:273706:279073 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/transport/net_ib.cc:199 NCCL WARN NET/IB : Unable to open device mlx5_4\n",
      "\n",
      "node-0:273706:279073 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/misc/ibvwrap.cc:222 NCCL WARN Call to ibv_open_device failed\n",
      "\n",
      "node-0:273706:279073 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/transport/net_ib.cc:199 NCCL WARN NET/IB : Unable to open device mlx5_5\n",
      "\n",
      "node-0:273706:279073 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/misc/ibvwrap.cc:222 NCCL WARN Call to ibv_open_device failed\n",
      "\n",
      "node-0:273706:279073 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/transport/net_ib.cc:199 NCCL WARN NET/IB : Unable to open device mlx5_6\n",
      "\n",
      "node-0:273706:279073 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/misc/ibvwrap.cc:222 NCCL WARN Call to ibv_open_device failed\n",
      "\n",
      "node-0:273706:279073 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/transport/net_ib.cc:199 NCCL WARN NET/IB : Unable to open device mlx5_7\n",
      "node-0:273706:279073 [0] NCCL INFO NET/IB : No device found.\n",
      "node-0:273706:279073 [0] NCCL INFO NET/Socket : Using [0]eth0:10.13.51.163<0>\n",
      "node-0:273706:279073 [0] NCCL INFO Using network Socket\n",
      "node-0:273706:279074 [1] NCCL INFO Using network Socket\n",
      "node-0:273706:279073 [0] NCCL INFO Topology detection : could not read /sys/devices/LNXSYSTM:00/LNXSYBUS:00/ACPI0004:00/VMBUS:00/47505500-000d-0000-3130-303237343043/pci000d:00/000d:00:00.0/../max_link_speed, ignoring\n",
      "node-0:273706:279074 [1] NCCL INFO Topology detection : could not read /sys/devices/LNXSYSTM:00/LNXSYBUS:00/ACPI0004:00/VMBUS:00/47505500-000d-0000-3130-303237343043/pci000d:00/000d:00:00.0/../max_link_speed, ignoring\n",
      "node-0:273706:279073 [0] NCCL INFO Topology detection : could not read /sys/devices/LNXSYSTM:00/LNXSYBUS:00/ACPI0004:00/VMBUS:00/47505500-000d-0000-3130-303237343043/pci000d:00/000d:00:00.0/../max_link_width, ignoring\n",
      "node-0:273706:279074 [1] NCCL INFO Topology detection : could not read /sys/devices/LNXSYSTM:00/LNXSYBUS:00/ACPI0004:00/VMBUS:00/47505500-000d-0000-3130-303237343043/pci000d:00/000d:00:00.0/../max_link_width, ignoring\n",
      "node-0:273706:279073 [0] NCCL INFO rocm_smi_lib: version 5.0.0.0\n",
      "node-0:273706:279074 [1] NCCL INFO rocm_smi_lib: version 5.0.0.0\n",
      "node-0:273706:279073 [0] NCCL INFO Topology detection : could not read /sys/devices/LNXSYSTM:00/LNXSYBUS:00/ACPI0004:00/VMBUS:00/47505500-000e-0000-3130-303237343043/pci000e:00/000e:00:00.0/../max_link_speed, ignoring\n",
      "node-0:273706:279074 [1] NCCL INFO Topology detection : could not read /sys/devices/LNXSYSTM:00/LNXSYBUS:00/ACPI0004:00/VMBUS:00/47505500-000e-0000-3130-303237343043/pci000e:00/000e:00:00.0/../max_link_speed, ignoring\n",
      "node-0:273706:279073 [0] NCCL INFO Topology detection : could not read /sys/devices/LNXSYSTM:00/LNXSYBUS:00/ACPI0004:00/VMBUS:00/47505500-000e-0000-3130-303237343043/pci000e:00/000e:00:00.0/../max_link_width, ignoring\n",
      "node-0:273706:279074 [1] NCCL INFO Topology detection : could not read /sys/devices/LNXSYSTM:00/LNXSYBUS:00/ACPI0004:00/VMBUS:00/47505500-000e-0000-3130-303237343043/pci000e:00/000e:00:00.0/../max_link_width, ignoring\n",
      "node-0:273706:279073 [0] NCCL INFO === System : maxBw 144.0 totalBw 144.0 ===\n",
      "node-0:273706:279073 [0] NCCL INFO CPU/2 (1/2/4)\n",
      "node-0:273706:279073 [0] NCCL INFO + PCI[5000.0] - NIC/0\n",
      "node-0:273706:279073 [0] NCCL INFO + PCI[24.0] - GPU/D00000 (0)\n",
      "node-0:273706:279073 [0] NCCL INFO               + XGMI[144.0] - GPU/E00000\n",
      "node-0:273706:279073 [0] NCCL INFO + PCI[24.0] - GPU/E00000 (1)\n",
      "node-0:273706:279073 [0] NCCL INFO               + XGMI[144.0] - GPU/D00000\n",
      "node-0:273706:279073 [0] NCCL INFO ==========================================\n",
      "node-0:273706:279073 [0] NCCL INFO GPU/D00000 :GPU/D00000 (0/5000.000000/LOC) GPU/E00000 (1/144.000000/XGMI) CPU/2 (1/24.000000/PHB) \n",
      "node-0:273706:279073 [0] NCCL INFO GPU/E00000 :GPU/D00000 (1/144.000000/XGMI) GPU/E00000 (0/5000.000000/LOC) CPU/2 (1/24.000000/PHB) \n",
      "node-0:273706:279073 [0] NCCL INFO Setting affinity for GPU 12 to ff,ffff0000,00000000\n",
      "node-0:273706:279074 [1] NCCL INFO === System : maxBw 144.0 totalBw 144.0 ===\n",
      "node-0:273706:279074 [1] NCCL INFO CPU/2 (1/2/4)\n",
      "node-0:273706:279074 [1] NCCL INFO + PCI[5000.0] - NIC/0\n",
      "node-0:273706:279074 [1] NCCL INFO + PCI[24.0] - GPU/D00000 (0)\n",
      "node-0:273706:279074 [1] NCCL INFO               + XGMI[144.0] - GPU/E00000\n",
      "node-0:273706:279074 [1] NCCL INFO + PCI[24.0] - GPU/E00000 (1)\n",
      "node-0:273706:279074 [1] NCCL INFO               + XGMI[144.0] - GPU/D00000\n",
      "node-0:273706:279074 [1] NCCL INFO ==========================================\n",
      "node-0:273706:279074 [1] NCCL INFO GPU/D00000 :GPU/D00000 (0/5000.000000/LOC) GPU/E00000 (1/144.000000/XGMI) CPU/2 (1/24.000000/PHB) \n",
      "node-0:273706:279074 [1] NCCL INFO GPU/E00000 :GPU/D00000 (1/144.000000/XGMI) GPU/E00000 (0/5000.000000/LOC) CPU/2 (1/24.000000/PHB) \n",
      "node-0:273706:279074 [1] NCCL INFO Setting affinity for GPU 13 to ff,ffff0000,00000000\n",
      "node-0:273706:279073 [0] NCCL INFO Pattern 4, crossNic 0, nChannels 6, bw 24.000000/24.000000, type XGMI/PIX, sameChannels 1\n",
      "node-0:273706:279073 [0] NCCL INFO  0 : GPU/0 GPU/1\n",
      "node-0:273706:279073 [0] NCCL INFO  1 : GPU/0 GPU/1\n",
      "node-0:273706:279073 [0] NCCL INFO  2 : GPU/0 GPU/1\n",
      "node-0:273706:279073 [0] NCCL INFO  3 : GPU/0 GPU/1\n",
      "node-0:273706:279073 [0] NCCL INFO  4 : GPU/0 GPU/1\n",
      "node-0:273706:279073 [0] NCCL INFO  5 : GPU/0 GPU/1\n",
      "node-0:273706:279073 [0] NCCL INFO Pattern 1, crossNic 0, nChannels 6, bw 48.000000/48.000000, type XGMI/PIX, sameChannels 0\n",
      "node-0:273706:279073 [0] NCCL INFO  0 : GPU/0 GPU/1\n",
      "node-0:273706:279073 [0] NCCL INFO  1 : GPU/0 GPU/1\n",
      "node-0:273706:279073 [0] NCCL INFO  2 : GPU/0 GPU/1\n",
      "node-0:273706:279073 [0] NCCL INFO  3 : GPU/1 GPU/0\n",
      "node-0:273706:279073 [0] NCCL INFO  4 : GPU/1 GPU/0\n",
      "node-0:273706:279073 [0] NCCL INFO  5 : GPU/1 GPU/0\n",
      "node-0:273706:279073 [0] NCCL INFO Pattern 3, crossNic 0, nChannels 6, bw 48.000000/48.000000, type XGMI/PIX, sameChannels 0\n",
      "node-0:273706:279073 [0] NCCL INFO  0 : GPU/0 GPU/1\n",
      "node-0:273706:279073 [0] NCCL INFO  1 : GPU/0 GPU/1\n",
      "node-0:273706:279073 [0] NCCL INFO  2 : GPU/0 GPU/1\n",
      "node-0:273706:279073 [0] NCCL INFO  3 : GPU/1 GPU/0\n",
      "node-0:273706:279073 [0] NCCL INFO  4 : GPU/1 GPU/0\n",
      "node-0:273706:279073 [0] NCCL INFO  5 : GPU/1 GPU/0\n",
      "node-0:273706:279074 [1] NCCL INFO Pattern 4, crossNic 0, nChannels 6, bw 24.000000/24.000000, type XGMI/PIX, sameChannels 1\n",
      "node-0:273706:279074 [1] NCCL INFO  0 : GPU/0 GPU/1\n",
      "node-0:273706:279074 [1] NCCL INFO  1 : GPU/0 GPU/1\n",
      "node-0:273706:279074 [1] NCCL INFO  2 : GPU/0 GPU/1\n",
      "node-0:273706:279074 [1] NCCL INFO  3 : GPU/0 GPU/1\n",
      "node-0:273706:279074 [1] NCCL INFO  4 : GPU/0 GPU/1\n",
      "node-0:273706:279074 [1] NCCL INFO  5 : GPU/0 GPU/1\n",
      "node-0:273706:279074 [1] NCCL INFO Pattern 1, crossNic 0, nChannels 6, bw 48.000000/48.000000, type XGMI/PIX, sameChannels 0\n",
      "node-0:273706:279074 [1] NCCL INFO  0 : GPU/0 GPU/1\n",
      "node-0:273706:279074 [1] NCCL INFO  1 : GPU/0 GPU/1\n",
      "node-0:273706:279074 [1] NCCL INFO  2 : GPU/0 GPU/1\n",
      "node-0:273706:279074 [1] NCCL INFO  3 : GPU/1 GPU/0\n",
      "node-0:273706:279074 [1] NCCL INFO  4 : GPU/1 GPU/0\n",
      "node-0:273706:279074 [1] NCCL INFO  5 : GPU/1 GPU/0\n",
      "node-0:273706:279074 [1] NCCL INFO Pattern 3, crossNic 0, nChannels 6, bw 48.000000/48.000000, type XGMI/PIX, sameChannels 0\n",
      "node-0:273706:279074 [1] NCCL INFO  0 : GPU/0 GPU/1\n",
      "node-0:273706:279074 [1] NCCL INFO  1 : GPU/0 GPU/1\n",
      "node-0:273706:279074 [1] NCCL INFO  2 : GPU/0 GPU/1\n",
      "node-0:273706:279074 [1] NCCL INFO  3 : GPU/1 GPU/0\n",
      "node-0:273706:279074 [1] NCCL INFO  4 : GPU/1 GPU/0\n",
      "node-0:273706:279074 [1] NCCL INFO  5 : GPU/1 GPU/0\n",
      "node-0:273706:279073 [0] NCCL INFO Tree 0 : -1 -> 0 -> 1/-1/-1\n",
      "node-0:273706:279073 [0] NCCL INFO Tree 6 : -1 -> 0 -> 1/-1/-1\n",
      "node-0:273706:279073 [0] NCCL INFO Tree 1 : -1 -> 0 -> 1/-1/-1\n",
      "node-0:273706:279073 [0] NCCL INFO Tree 7 : -1 -> 0 -> 1/-1/-1\n",
      "node-0:273706:279073 [0] NCCL INFO Tree 2 : -1 -> 0 -> 1/-1/-1\n",
      "node-0:273706:279073 [0] NCCL INFO Tree 8 : -1 -> 0 -> 1/-1/-1\n",
      "node-0:273706:279074 [1] NCCL INFO Tree 0 : 0 -> 1 -> -1/-1/-1\n",
      "node-0:273706:279073 [0] NCCL INFO Tree 3 : 1 -> 0 -> -1/-1/-1\n",
      "node-0:273706:279074 [1] NCCL INFO Tree 6 : 0 -> 1 -> -1/-1/-1\n",
      "node-0:273706:279073 [0] NCCL INFO Tree 9 : 1 -> 0 -> -1/-1/-1\n",
      "node-0:273706:279074 [1] NCCL INFO Tree 1 : 0 -> 1 -> -1/-1/-1\n",
      "node-0:273706:279073 [0] NCCL INFO Tree 4 : 1 -> 0 -> -1/-1/-1\n",
      "node-0:273706:279074 [1] NCCL INFO Tree 7 : 0 -> 1 -> -1/-1/-1\n",
      "node-0:273706:279073 [0] NCCL INFO Tree 10 : 1 -> 0 -> -1/-1/-1\n",
      "node-0:273706:279074 [1] NCCL INFO Tree 2 : 0 -> 1 -> -1/-1/-1\n",
      "node-0:273706:279073 [0] NCCL INFO Tree 5 : 1 -> 0 -> -1/-1/-1\n",
      "node-0:273706:279074 [1] NCCL INFO Tree 8 : 0 -> 1 -> -1/-1/-1\n",
      "node-0:273706:279073 [0] NCCL INFO Tree 11 : 1 -> 0 -> -1/-1/-1\n",
      "node-0:273706:279074 [1] NCCL INFO Tree 3 : -1 -> 1 -> 0/-1/-1\n",
      "node-0:273706:279074 [1] NCCL INFO Tree 9 : -1 -> 1 -> 0/-1/-1\n",
      "node-0:273706:279074 [1] NCCL INFO Tree 4 : -1 -> 1 -> 0/-1/-1\n",
      "node-0:273706:279074 [1] NCCL INFO Tree 10 : -1 -> 1 -> 0/-1/-1\n",
      "node-0:273706:279074 [1] NCCL INFO Tree 5 : -1 -> 1 -> 0/-1/-1\n",
      "node-0:273706:279074 [1] NCCL INFO Tree 11 : -1 -> 1 -> 0/-1/-1\n",
      "node-0:273706:279073 [0] NCCL INFO Channel 00/24 :    0   1\n",
      "node-0:273706:279073 [0] NCCL INFO Channel 01/24 :    0   1\n",
      "node-0:273706:279073 [0] NCCL INFO Channel 02/24 :    0   1\n",
      "node-0:273706:279073 [0] NCCL INFO Channel 03/24 :    0   1\n",
      "node-0:273706:279073 [0] NCCL INFO Channel 04/24 :    0   1\n",
      "node-0:273706:279073 [0] NCCL INFO Channel 05/24 :    0   1\n",
      "node-0:273706:279074 [1] NCCL INFO Ring 0 : 0 -> 1 -> 0 comm 0x1b6d19e0 nRanks 02 busId e00000\n",
      "node-0:273706:279073 [0] NCCL INFO Channel 06/24 :    0   1\n",
      "node-0:273706:279074 [1] NCCL INFO Ring 1 : 0 -> 1 -> 0 comm 0x1b6d19e0 nRanks 02 busId e00000\n",
      "node-0:273706:279073 [0] NCCL INFO Channel 07/24 :    0   1\n",
      "node-0:273706:279073 [0] NCCL INFO Channel 08/24 :    0   1\n",
      "node-0:273706:279074 [1] NCCL INFO Ring 2 : 0 -> 1 -> 0 comm 0x1b6d19e0 nRanks 02 busId e00000\n",
      "node-0:273706:279073 [0] NCCL INFO Channel 09/24 :    0   1\n",
      "node-0:273706:279074 [1] NCCL INFO Ring 3 : 0 -> 1 -> 0 comm 0x1b6d19e0 nRanks 02 busId e00000\n",
      "node-0:273706:279073 [0] NCCL INFO Channel 10/24 :    0   1\n",
      "node-0:273706:279073 [0] NCCL INFO Channel 11/24 :    0   1\n",
      "node-0:273706:279074 [1] NCCL INFO Ring 4 : 0 -> 1 -> 0 comm 0x1b6d19e0 nRanks 02 busId e00000\n",
      "node-0:273706:279073 [0] NCCL INFO Channel 12/24 :    0   1\n",
      "node-0:273706:279074 [1] NCCL INFO Ring 5 : 0 -> 1 -> 0 comm 0x1b6d19e0 nRanks 02 busId e00000\n",
      "node-0:273706:279074 [1] NCCL INFO Ring 6 : 0 -> 1 -> 0 comm 0x1b6d19e0 nRanks 02 busId e00000\n",
      "node-0:273706:279074 [1] NCCL INFO Ring 7 : 0 -> 1 -> 0 comm 0x1b6d19e0 nRanks 02 busId e00000\n",
      "node-0:273706:279074 [1] NCCL INFO Ring 8 : 0 -> 1 -> 0 comm 0x1b6d19e0 nRanks 02 busId e00000\n",
      "node-0:273706:279074 [1] NCCL INFO Ring 9 : 0 -> 1 -> 0 comm 0x1b6d19e0 nRanks 02 busId e00000\n",
      "node-0:273706:279074 [1] NCCL INFO Ring 10 : 0 -> 1 -> 0 comm 0x1b6d19e0 nRanks 02 busId e00000\n",
      "node-0:273706:279074 [1] NCCL INFO Ring 11 : 0 -> 1 -> 0 comm 0x1b6d19e0 nRanks 02 busId e00000\n",
      "node-0:273706:279074 [1] NCCL INFO Ring 12 : 0 -> 1 -> 0 comm 0x1b6d19e0 nRanks 02 busId e00000\n",
      "node-0:273706:279073 [0] NCCL INFO Channel 13/24 :    0   1\n",
      "node-0:273706:279074 [1] NCCL INFO Ring 13 : 0 -> 1 -> 0 comm 0x1b6d19e0 nRanks 02 busId e00000\n",
      "node-0:273706:279074 [1] NCCL INFO Ring 14 : 0 -> 1 -> 0 comm 0x1b6d19e0 nRanks 02 busId e00000\n",
      "node-0:273706:279073 [0] NCCL INFO Channel 14/24 :    0   1\n",
      "node-0:273706:279073 [0] NCCL INFO Channel 15/24 :    0   1\n",
      "node-0:273706:279074 [1] NCCL INFO Ring 15 : 0 -> 1 -> 0 comm 0x1b6d19e0 nRanks 02 busId e00000\n",
      "node-0:273706:279073 [0] NCCL INFO Channel 16/24 :    0   1\n",
      "node-0:273706:279074 [1] NCCL INFO Ring 16 : 0 -> 1 -> 0 comm 0x1b6d19e0 nRanks 02 busId e00000\n",
      "node-0:273706:279073 [0] NCCL INFO Channel 17/24 :    0   1\n",
      "node-0:273706:279074 [1] NCCL INFO Ring 17 : 0 -> 1 -> 0 comm 0x1b6d19e0 nRanks 02 busId e00000\n",
      "node-0:273706:279073 [0] NCCL INFO Channel 18/24 :    0   1\n",
      "node-0:273706:279073 [0] NCCL INFO Channel 19/24 :    0   1\n",
      "node-0:273706:279074 [1] NCCL INFO Ring 18 : 0 -> 1 -> 0 comm 0x1b6d19e0 nRanks 02 busId e00000\n",
      "node-0:273706:279073 [0] NCCL INFO Channel 20/24 :    0   1\n",
      "node-0:273706:279074 [1] NCCL INFO Ring 19 : 0 -> 1 -> 0 comm 0x1b6d19e0 nRanks 02 busId e00000\n",
      "node-0:273706:279073 [0] NCCL INFO Channel 21/24 :    0   1\n",
      "node-0:273706:279074 [1] NCCL INFO Ring 20 : 0 -> 1 -> 0 comm 0x1b6d19e0 nRanks 02 busId e00000\n",
      "node-0:273706:279073 [0] NCCL INFO Channel 22/24 :    0   1\n",
      "node-0:273706:279074 [1] NCCL INFO Ring 21 : 0 -> 1 -> 0 comm 0x1b6d19e0 nRanks 02 busId e00000\n",
      "node-0:273706:279073 [0] NCCL INFO Channel 23/24 :    0   1\n",
      "node-0:273706:279074 [1] NCCL INFO Ring 22 : 0 -> 1 -> 0 comm 0x1b6d19e0 nRanks 02 busId e00000\n",
      "node-0:273706:279074 [1] NCCL INFO Ring 23 : 0 -> 1 -> 0 comm 0x1b6d19e0 nRanks 02 busId e00000\n",
      "node-0:273706:279073 [0] NCCL INFO Ring 0 : 1 -> 0 -> 1 comm 0x1b6ce640 nRanks 02 busId d00000\n",
      "node-0:273706:279074 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] 0/-1/-1->1->-1 [4] 0/-1/-1->1->-1 [5] 0/-1/-1->1->-1 [6] -1/-1/-1->1->0 [7] -1/-1/-1->1->0 [8] -1/-1/-1->1->0 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] -1/-1/-1->1->0 [13] -1/-1/-1->1->0 [14] -1/-1/-1->1->0 [15] 0/-1/-1->1->-1 [16] 0/-1/-1->1->-1 [17] 0/-1/-1->1->-1 [18] -1/-1/-1->1->0 [19] -1/-1/-1->1->0 [20] -1/-1/-1->1->0 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1 comm 0x1b6d19e0 nRanks 02 busId e00000\n",
      "node-0:273706:279073 [0] NCCL INFO Ring 1 : 1 -> 0 -> 1 comm 0x1b6ce640 nRanks 02 busId d00000\n",
      "node-0:273706:279073 [0] NCCL INFO Ring 2 : 1 -> 0 -> 1 comm 0x1b6ce640 nRanks 02 busId d00000\n",
      "node-0:273706:279074 [1] NCCL INFO P2P Chunksize set to 524288\n",
      "node-0:273706:279073 [0] NCCL INFO Ring 3 : 1 -> 0 -> 1 comm 0x1b6ce640 nRanks 02 busId d00000\n",
      "node-0:273706:279073 [0] NCCL INFO Ring 4 : 1 -> 0 -> 1 comm 0x1b6ce640 nRanks 02 busId d00000\n",
      "node-0:273706:279073 [0] NCCL INFO Ring 5 : 1 -> 0 -> 1 comm 0x1b6ce640 nRanks 02 busId d00000\n",
      "node-0:273706:279073 [0] NCCL INFO Ring 6 : 1 -> 0 -> 1 comm 0x1b6ce640 nRanks 02 busId d00000\n",
      "node-0:273706:279073 [0] NCCL INFO Ring 7 : 1 -> 0 -> 1 comm 0x1b6ce640 nRanks 02 busId d00000\n",
      "node-0:273706:279073 [0] NCCL INFO Ring 8 : 1 -> 0 -> 1 comm 0x1b6ce640 nRanks 02 busId d00000\n",
      "node-0:273706:279073 [0] NCCL INFO Ring 9 : 1 -> 0 -> 1 comm 0x1b6ce640 nRanks 02 busId d00000\n",
      "node-0:273706:279073 [0] NCCL INFO Ring 10 : 1 -> 0 -> 1 comm 0x1b6ce640 nRanks 02 busId d00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node-0:273706:279073 [0] NCCL INFO Ring 11 : 1 -> 0 -> 1 comm 0x1b6ce640 nRanks 02 busId d00000\n",
      "node-0:273706:279073 [0] NCCL INFO Ring 12 : 1 -> 0 -> 1 comm 0x1b6ce640 nRanks 02 busId d00000\n",
      "node-0:273706:279073 [0] NCCL INFO Ring 13 : 1 -> 0 -> 1 comm 0x1b6ce640 nRanks 02 busId d00000\n",
      "node-0:273706:279073 [0] NCCL INFO Ring 14 : 1 -> 0 -> 1 comm 0x1b6ce640 nRanks 02 busId d00000\n",
      "node-0:273706:279073 [0] NCCL INFO Ring 15 : 1 -> 0 -> 1 comm 0x1b6ce640 nRanks 02 busId d00000\n",
      "node-0:273706:279073 [0] NCCL INFO Ring 16 : 1 -> 0 -> 1 comm 0x1b6ce640 nRanks 02 busId d00000\n",
      "node-0:273706:279073 [0] NCCL INFO Ring 17 : 1 -> 0 -> 1 comm 0x1b6ce640 nRanks 02 busId d00000\n",
      "node-0:273706:279073 [0] NCCL INFO Ring 18 : 1 -> 0 -> 1 comm 0x1b6ce640 nRanks 02 busId d00000\n",
      "node-0:273706:279073 [0] NCCL INFO Ring 19 : 1 -> 0 -> 1 comm 0x1b6ce640 nRanks 02 busId d00000\n",
      "node-0:273706:279073 [0] NCCL INFO Ring 20 : 1 -> 0 -> 1 comm 0x1b6ce640 nRanks 02 busId d00000\n",
      "node-0:273706:279073 [0] NCCL INFO Ring 21 : 1 -> 0 -> 1 comm 0x1b6ce640 nRanks 02 busId d00000\n",
      "node-0:273706:279073 [0] NCCL INFO Ring 22 : 1 -> 0 -> 1 comm 0x1b6ce640 nRanks 02 busId d00000\n",
      "node-0:273706:279073 [0] NCCL INFO Ring 23 : 1 -> 0 -> 1 comm 0x1b6ce640 nRanks 02 busId d00000\n",
      "node-0:273706:279073 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] -1/-1/-1->0->1 [4] -1/-1/-1->0->1 [5] -1/-1/-1->0->1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1 [8] 1/-1/-1->0->-1 [9] -1/-1/-1->0->1 [10] -1/-1/-1->0->1 [11] -1/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] -1/-1/-1->0->1 [16] -1/-1/-1->0->1 [17] -1/-1/-1->0->1 [18] 1/-1/-1->0->-1 [19] 1/-1/-1->0->-1 [20] 1/-1/-1->0->-1 [21] -1/-1/-1->0->1 [22] -1/-1/-1->0->1 [23] -1/-1/-1->0->1 comm 0x1b6ce640 nRanks 02 busId d00000\n",
      "node-0:273706:279073 [0] NCCL INFO P2P Chunksize set to 524288\n",
      "node-0:273706:279074 [1] NCCL INFO Channel 00/0 : 1[e00000] -> 0[d00000] via P2P/direct pointer comm 0x1b6d19e0 nRanks 02\n",
      "node-0:273706:279073 [0] NCCL INFO Channel 00/0 : 0[d00000] -> 1[e00000] via P2P/direct pointer comm 0x1b6ce640 nRanks 02\n",
      "node-0:273706:279074 [1] NCCL INFO Channel 01/0 : 1[e00000] -> 0[d00000] via P2P/direct pointer comm 0x1b6d19e0 nRanks 02\n",
      "node-0:273706:279073 [0] NCCL INFO Channel 01/0 : 0[d00000] -> 1[e00000] via P2P/direct pointer comm 0x1b6ce640 nRanks 02\n",
      "node-0:273706:279074 [1] NCCL INFO Channel 02/0 : 1[e00000] -> 0[d00000] via P2P/direct pointer comm 0x1b6d19e0 nRanks 02\n",
      "node-0:273706:279073 [0] NCCL INFO Channel 02/0 : 0[d00000] -> 1[e00000] via P2P/direct pointer comm 0x1b6ce640 nRanks 02\n",
      "node-0:273706:279074 [1] NCCL INFO Channel 03/0 : 1[e00000] -> 0[d00000] via P2P/direct pointer comm 0x1b6d19e0 nRanks 02\n",
      "node-0:273706:279074 [1] NCCL INFO Channel 04/0 : 1[e00000] -> 0[d00000] via P2P/direct pointer comm 0x1b6d19e0 nRanks 02\n",
      "node-0:273706:279073 [0] NCCL INFO Channel 03/0 : 0[d00000] -> 1[e00000] via P2P/direct pointer comm 0x1b6ce640 nRanks 02\n",
      "node-0:273706:279074 [1] NCCL INFO Channel 05/0 : 1[e00000] -> 0[d00000] via P2P/direct pointer comm 0x1b6d19e0 nRanks 02\n",
      "node-0:273706:279073 [0] NCCL INFO Channel 04/0 : 0[d00000] -> 1[e00000] via P2P/direct pointer comm 0x1b6ce640 nRanks 02\n",
      "node-0:273706:279074 [1] NCCL INFO Channel 06/0 : 1[e00000] -> 0[d00000] via P2P/direct pointer comm 0x1b6d19e0 nRanks 02\n",
      "node-0:273706:279073 [0] NCCL INFO Channel 05/0 : 0[d00000] -> 1[e00000] via P2P/direct pointer comm 0x1b6ce640 nRanks 02\n",
      "node-0:273706:279073 [0] NCCL INFO Channel 06/0 : 0[d00000] -> 1[e00000] via P2P/direct pointer comm 0x1b6ce640 nRanks 02\n",
      "node-0:273706:279074 [1] NCCL INFO Channel 07/0 : 1[e00000] -> 0[d00000] via P2P/direct pointer comm 0x1b6d19e0 nRanks 02\n",
      "node-0:273706:279073 [0] NCCL INFO Channel 07/0 : 0[d00000] -> 1[e00000] via P2P/direct pointer comm 0x1b6ce640 nRanks 02\n",
      "node-0:273706:279074 [1] NCCL INFO Channel 08/0 : 1[e00000] -> 0[d00000] via P2P/direct pointer comm 0x1b6d19e0 nRanks 02\n",
      "node-0:273706:279073 [0] NCCL INFO Channel 08/0 : 0[d00000] -> 1[e00000] via P2P/direct pointer comm 0x1b6ce640 nRanks 02\n",
      "node-0:273706:279074 [1] NCCL INFO Channel 09/0 : 1[e00000] -> 0[d00000] via P2P/direct pointer comm 0x1b6d19e0 nRanks 02\n",
      "node-0:273706:279073 [0] NCCL INFO Channel 09/0 : 0[d00000] -> 1[e00000] via P2P/direct pointer comm 0x1b6ce640 nRanks 02\n",
      "node-0:273706:279074 [1] NCCL INFO Channel 10/0 : 1[e00000] -> 0[d00000] via P2P/direct pointer comm 0x1b6d19e0 nRanks 02\n",
      "node-0:273706:279073 [0] NCCL INFO Channel 10/0 : 0[d00000] -> 1[e00000] via P2P/direct pointer comm 0x1b6ce640 nRanks 02\n",
      "node-0:273706:279074 [1] NCCL INFO Channel 11/0 : 1[e00000] -> 0[d00000] via P2P/direct pointer comm 0x1b6d19e0 nRanks 02\n",
      "node-0:273706:279073 [0] NCCL INFO Channel 11/0 : 0[d00000] -> 1[e00000] via P2P/direct pointer comm 0x1b6ce640 nRanks 02\n",
      "node-0:273706:279074 [1] NCCL INFO Channel 12/0 : 1[e00000] -> 0[d00000] via P2P/direct pointer comm 0x1b6d19e0 nRanks 02\n",
      "node-0:273706:279073 [0] NCCL INFO Channel 12/0 : 0[d00000] -> 1[e00000] via P2P/direct pointer comm 0x1b6ce640 nRanks 02\n",
      "node-0:273706:279074 [1] NCCL INFO Channel 13/0 : 1[e00000] -> 0[d00000] via P2P/direct pointer comm 0x1b6d19e0 nRanks 02\n",
      "node-0:273706:279073 [0] NCCL INFO Channel 13/0 : 0[d00000] -> 1[e00000] via P2P/direct pointer comm 0x1b6ce640 nRanks 02\n",
      "node-0:273706:279074 [1] NCCL INFO Channel 14/0 : 1[e00000] -> 0[d00000] via P2P/direct pointer comm 0x1b6d19e0 nRanks 02\n",
      "node-0:273706:279073 [0] NCCL INFO Channel 14/0 : 0[d00000] -> 1[e00000] via P2P/direct pointer comm 0x1b6ce640 nRanks 02\n",
      "node-0:273706:279074 [1] NCCL INFO Channel 15/0 : 1[e00000] -> 0[d00000] via P2P/direct pointer comm 0x1b6d19e0 nRanks 02\n",
      "node-0:273706:279073 [0] NCCL INFO Channel 15/0 : 0[d00000] -> 1[e00000] via P2P/direct pointer comm 0x1b6ce640 nRanks 02\n",
      "node-0:273706:279074 [1] NCCL INFO Channel 16/0 : 1[e00000] -> 0[d00000] via P2P/direct pointer comm 0x1b6d19e0 nRanks 02\n",
      "node-0:273706:279073 [0] NCCL INFO Channel 16/0 : 0[d00000] -> 1[e00000] via P2P/direct pointer comm 0x1b6ce640 nRanks 02\n",
      "node-0:273706:279074 [1] NCCL INFO Channel 17/0 : 1[e00000] -> 0[d00000] via P2P/direct pointer comm 0x1b6d19e0 nRanks 02\n",
      "node-0:273706:279073 [0] NCCL INFO Channel 17/0 : 0[d00000] -> 1[e00000] via P2P/direct pointer comm 0x1b6ce640 nRanks 02\n",
      "node-0:273706:279074 [1] NCCL INFO Channel 18/0 : 1[e00000] -> 0[d00000] via P2P/direct pointer comm 0x1b6d19e0 nRanks 02\n",
      "node-0:273706:279073 [0] NCCL INFO Channel 18/0 : 0[d00000] -> 1[e00000] via P2P/direct pointer comm 0x1b6ce640 nRanks 02\n",
      "node-0:273706:279074 [1] NCCL INFO Channel 19/0 : 1[e00000] -> 0[d00000] via P2P/direct pointer comm 0x1b6d19e0 nRanks 02\n",
      "node-0:273706:279073 [0] NCCL INFO Channel 19/0 : 0[d00000] -> 1[e00000] via P2P/direct pointer comm 0x1b6ce640 nRanks 02\n",
      "node-0:273706:279074 [1] NCCL INFO Channel 20/0 : 1[e00000] -> 0[d00000] via P2P/direct pointer comm 0x1b6d19e0 nRanks 02\n",
      "node-0:273706:279073 [0] NCCL INFO Channel 20/0 : 0[d00000] -> 1[e00000] via P2P/direct pointer comm 0x1b6ce640 nRanks 02\n",
      "node-0:273706:279074 [1] NCCL INFO Channel 21/0 : 1[e00000] -> 0[d00000] via P2P/direct pointer comm 0x1b6d19e0 nRanks 02\n",
      "node-0:273706:279073 [0] NCCL INFO Channel 21/0 : 0[d00000] -> 1[e00000] via P2P/direct pointer comm 0x1b6ce640 nRanks 02\n",
      "node-0:273706:279074 [1] NCCL INFO Channel 22/0 : 1[e00000] -> 0[d00000] via P2P/direct pointer comm 0x1b6d19e0 nRanks 02\n",
      "node-0:273706:279073 [0] NCCL INFO Channel 22/0 : 0[d00000] -> 1[e00000] via P2P/direct pointer comm 0x1b6ce640 nRanks 02\n",
      "node-0:273706:279074 [1] NCCL INFO Channel 23/0 : 1[e00000] -> 0[d00000] via P2P/direct pointer comm 0x1b6d19e0 nRanks 02\n",
      "node-0:273706:279073 [0] NCCL INFO Channel 23/0 : 0[d00000] -> 1[e00000] via P2P/direct pointer comm 0x1b6ce640 nRanks 02\n",
      "node-0:273706:279073 [0] NCCL INFO Connected all rings comm 0x1b6ce640 nRanks 02 busId d00000\n",
      "node-0:273706:279073 [0] NCCL INFO Connected all trees\n",
      "node-0:273706:279073 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 256 | 256\n",
      "node-0:273706:279073 [0] NCCL INFO 24 coll channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer\n",
      "node-0:273706:279074 [1] NCCL INFO Connected all rings comm 0x1b6d19e0 nRanks 02 busId e00000\n",
      "node-0:273706:279074 [1] NCCL INFO Connected all trees\n",
      "node-0:273706:2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiscuser/scratch/Projects/xcai/xcai/losses.py:21: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:54.)\n",
      "  return torch.sparse_csr_tensor(data_ptr, data_idx, scores, device=data_ptr.device)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/ptca/lib/python3.9/site-packages/scipy/sparse/_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "o = learn.predict(block.train.dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eef4ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P@1</th>\n",
       "      <th>P@3</th>\n",
       "      <th>P@5</th>\n",
       "      <th>P@10</th>\n",
       "      <th>N@1</th>\n",
       "      <th>N@3</th>\n",
       "      <th>N@5</th>\n",
       "      <th>N@10</th>\n",
       "      <th>PSP@1</th>\n",
       "      <th>PSP@3</th>\n",
       "      <th>PSP@5</th>\n",
       "      <th>PSP@10</th>\n",
       "      <th>PSN@1</th>\n",
       "      <th>PSN@3</th>\n",
       "      <th>PSN@5</th>\n",
       "      <th>PSN@10</th>\n",
       "      <th>R@10</th>\n",
       "      <th>R@100</th>\n",
       "      <th>R@200</th>\n",
       "      <th>loss</th>\n",
       "      <th>runtime</th>\n",
       "      <th>samples_per_second</th>\n",
       "      <th>steps_per_second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77.9066</td>\n",
       "      <td>41.1329</td>\n",
       "      <td>28.0339</td>\n",
       "      <td>15.6834</td>\n",
       "      <td>77.9066</td>\n",
       "      <td>79.2724</td>\n",
       "      <td>80.8556</td>\n",
       "      <td>82.5391</td>\n",
       "      <td>69.5293</td>\n",
       "      <td>71.1523</td>\n",
       "      <td>74.2569</td>\n",
       "      <td>80.0041</td>\n",
       "      <td>69.5293</td>\n",
       "      <td>75.694</td>\n",
       "      <td>78.3396</td>\n",
       "      <td>80.6496</td>\n",
       "      <td>88.1427</td>\n",
       "      <td>92.5086</td>\n",
       "      <td>92.5086</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>3882.6119</td>\n",
       "      <td>178.331</td>\n",
       "      <td>0.892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       P@1      P@3      P@5     P@10      N@1      N@3      N@5     N@10  \\\n",
       "0  77.9066  41.1329  28.0339  15.6834  77.9066  79.2724  80.8556  82.5391   \n",
       "\n",
       "     PSP@1    PSP@3    PSP@5   PSP@10    PSN@1   PSN@3    PSN@5   PSN@10  \\\n",
       "0  69.5293  71.1523  74.2569  80.0041  69.5293  75.694  78.3396  80.6496   \n",
       "\n",
       "      R@10    R@100    R@200    loss    runtime  samples_per_second  \\\n",
       "0  88.1427  92.5086  92.5086  0.0094  3882.6119             178.331   \n",
       "\n",
       "   steps_per_second  \n",
       "0             0.892  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_metric(o.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0b7a86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e38f05a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dcf682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9eb9afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P@1</th>\n",
       "      <th>P@3</th>\n",
       "      <th>P@5</th>\n",
       "      <th>P@10</th>\n",
       "      <th>N@1</th>\n",
       "      <th>N@3</th>\n",
       "      <th>N@5</th>\n",
       "      <th>N@10</th>\n",
       "      <th>PSP@1</th>\n",
       "      <th>PSP@3</th>\n",
       "      <th>PSP@5</th>\n",
       "      <th>PSP@10</th>\n",
       "      <th>PSN@1</th>\n",
       "      <th>PSN@3</th>\n",
       "      <th>PSN@5</th>\n",
       "      <th>PSN@10</th>\n",
       "      <th>R@10</th>\n",
       "      <th>R@100</th>\n",
       "      <th>R@200</th>\n",
       "      <th>loss</th>\n",
       "      <th>runtime</th>\n",
       "      <th>samples_per_second</th>\n",
       "      <th>steps_per_second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.6845</td>\n",
       "      <td>21.9946</td>\n",
       "      <td>15.8711</td>\n",
       "      <td>9.7873</td>\n",
       "      <td>36.6845</td>\n",
       "      <td>30.3162</td>\n",
       "      <td>29.881</td>\n",
       "      <td>30.9404</td>\n",
       "      <td>28.4921</td>\n",
       "      <td>26.0447</td>\n",
       "      <td>25.7811</td>\n",
       "      <td>27.6033</td>\n",
       "      <td>28.4921</td>\n",
       "      <td>28.7257</td>\n",
       "      <td>30.5264</td>\n",
       "      <td>33.2445</td>\n",
       "      <td>32.211</td>\n",
       "      <td>42.3966</td>\n",
       "      <td>42.3966</td>\n",
       "      <td>0.0482</td>\n",
       "      <td>3912.2858</td>\n",
       "      <td>200.329</td>\n",
       "      <td>1.002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       P@1      P@3      P@5    P@10      N@1      N@3     N@5     N@10  \\\n",
       "0  36.6845  21.9946  15.8711  9.7873  36.6845  30.3162  29.881  30.9404   \n",
       "\n",
       "     PSP@1    PSP@3    PSP@5   PSP@10    PSN@1    PSN@3    PSN@5   PSN@10  \\\n",
       "0  28.4921  26.0447  25.7811  27.6033  28.4921  28.7257  30.5264  33.2445   \n",
       "\n",
       "     R@10    R@100    R@200    loss    runtime  samples_per_second  \\\n",
       "0  32.211  42.3966  42.3966  0.0482  3912.2858             200.329   \n",
       "\n",
       "   steps_per_second  \n",
       "0             1.002  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_metric(o.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5a6aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P@1</th>\n",
       "      <th>P@3</th>\n",
       "      <th>P@5</th>\n",
       "      <th>P@10</th>\n",
       "      <th>N@1</th>\n",
       "      <th>N@3</th>\n",
       "      <th>N@5</th>\n",
       "      <th>N@10</th>\n",
       "      <th>PSP@1</th>\n",
       "      <th>PSP@3</th>\n",
       "      <th>PSP@5</th>\n",
       "      <th>PSP@10</th>\n",
       "      <th>PSN@1</th>\n",
       "      <th>PSN@3</th>\n",
       "      <th>PSN@5</th>\n",
       "      <th>PSN@10</th>\n",
       "      <th>R@10</th>\n",
       "      <th>R@100</th>\n",
       "      <th>R@200</th>\n",
       "      <th>loss</th>\n",
       "      <th>runtime</th>\n",
       "      <th>samples_per_second</th>\n",
       "      <th>steps_per_second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.9428</td>\n",
       "      <td>20.2432</td>\n",
       "      <td>15.5844</td>\n",
       "      <td>10.1736</td>\n",
       "      <td>29.9428</td>\n",
       "      <td>30.3275</td>\n",
       "      <td>31.7684</td>\n",
       "      <td>34.1689</td>\n",
       "      <td>24.7682</td>\n",
       "      <td>26.8411</td>\n",
       "      <td>29.3415</td>\n",
       "      <td>34.5346</td>\n",
       "      <td>24.7682</td>\n",
       "      <td>27.3513</td>\n",
       "      <td>29.3419</td>\n",
       "      <td>31.9797</td>\n",
       "      <td>40.3797</td>\n",
       "      <td>54.7225</td>\n",
       "      <td>54.7225</td>\n",
       "      <td>0.0492</td>\n",
       "      <td>962.8372</td>\n",
       "      <td>184.367</td>\n",
       "      <td>0.922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       P@1      P@3      P@5     P@10      N@1      N@3      N@5     N@10  \\\n",
       "0  29.9428  20.2432  15.5844  10.1736  29.9428  30.3275  31.7684  34.1689   \n",
       "\n",
       "     PSP@1    PSP@3    PSP@5   PSP@10    PSN@1    PSN@3    PSN@5   PSN@10  \\\n",
       "0  24.7682  26.8411  29.3415  34.5346  24.7682  27.3513  29.3419  31.9797   \n",
       "\n",
       "      R@10    R@100    R@200    loss   runtime  samples_per_second  \\\n",
       "0  40.3797  54.7225  54.7225  0.0492  962.8372             184.367   \n",
       "\n",
       "   steps_per_second  \n",
       "0             0.922  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_metric(o.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30631670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P@1</th>\n",
       "      <th>P@3</th>\n",
       "      <th>P@5</th>\n",
       "      <th>P@10</th>\n",
       "      <th>N@1</th>\n",
       "      <th>N@3</th>\n",
       "      <th>N@5</th>\n",
       "      <th>N@10</th>\n",
       "      <th>PSP@1</th>\n",
       "      <th>PSP@3</th>\n",
       "      <th>PSP@5</th>\n",
       "      <th>PSP@10</th>\n",
       "      <th>PSN@1</th>\n",
       "      <th>PSN@3</th>\n",
       "      <th>PSN@5</th>\n",
       "      <th>PSN@10</th>\n",
       "      <th>R@10</th>\n",
       "      <th>R@100</th>\n",
       "      <th>R@200</th>\n",
       "      <th>loss</th>\n",
       "      <th>runtime</th>\n",
       "      <th>samples_per_second</th>\n",
       "      <th>steps_per_second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.7412</td>\n",
       "      <td>19.2727</td>\n",
       "      <td>14.8497</td>\n",
       "      <td>9.725</td>\n",
       "      <td>28.7412</td>\n",
       "      <td>29.182</td>\n",
       "      <td>30.6493</td>\n",
       "      <td>33.0577</td>\n",
       "      <td>23.6155</td>\n",
       "      <td>25.3211</td>\n",
       "      <td>27.6706</td>\n",
       "      <td>32.679</td>\n",
       "      <td>23.6155</td>\n",
       "      <td>26.0438</td>\n",
       "      <td>27.989</td>\n",
       "      <td>30.5923</td>\n",
       "      <td>39.391</td>\n",
       "      <td>53.9873</td>\n",
       "      <td>53.9873</td>\n",
       "      <td>0.0489</td>\n",
       "      <td>977.6731</td>\n",
       "      <td>181.569</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       P@1      P@3      P@5   P@10      N@1     N@3      N@5     N@10  \\\n",
       "0  28.7412  19.2727  14.8497  9.725  28.7412  29.182  30.6493  33.0577   \n",
       "\n",
       "     PSP@1    PSP@3    PSP@5  PSP@10    PSN@1    PSN@3   PSN@5   PSN@10  \\\n",
       "0  23.6155  25.3211  27.6706  32.679  23.6155  26.0438  27.989  30.5923   \n",
       "\n",
       "     R@10    R@100    R@200    loss   runtime  samples_per_second  \\\n",
       "0  39.391  53.9873  53.9873  0.0489  977.6731             181.569   \n",
       "\n",
       "   steps_per_second  \n",
       "0             0.908  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_metric(o.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee0af48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4af82a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578559b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5354bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7ee5b03d0e5433aa009d8331881d0f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1562 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a567611b3e9437d9b5e69e0df7a3459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12292 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/ptca/lib/python3.9/site-packages/scipy/sparse/_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "o = learn.predict(test_block.test.dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18423ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P@1</th>\n",
       "      <th>P@3</th>\n",
       "      <th>P@5</th>\n",
       "      <th>P@10</th>\n",
       "      <th>N@1</th>\n",
       "      <th>N@3</th>\n",
       "      <th>N@5</th>\n",
       "      <th>N@10</th>\n",
       "      <th>PSP@1</th>\n",
       "      <th>PSP@3</th>\n",
       "      <th>PSP@5</th>\n",
       "      <th>PSP@10</th>\n",
       "      <th>PSN@1</th>\n",
       "      <th>PSN@3</th>\n",
       "      <th>PSN@5</th>\n",
       "      <th>PSN@10</th>\n",
       "      <th>R@10</th>\n",
       "      <th>R@100</th>\n",
       "      <th>R@200</th>\n",
       "      <th>loss</th>\n",
       "      <th>runtime</th>\n",
       "      <th>samples_per_second</th>\n",
       "      <th>steps_per_second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.688</td>\n",
       "      <td>17.4213</td>\n",
       "      <td>13.4276</td>\n",
       "      <td>8.7873</td>\n",
       "      <td>25.688</td>\n",
       "      <td>26.108</td>\n",
       "      <td>27.3521</td>\n",
       "      <td>29.4336</td>\n",
       "      <td>21.5048</td>\n",
       "      <td>23.2458</td>\n",
       "      <td>25.352</td>\n",
       "      <td>29.8492</td>\n",
       "      <td>21.5048</td>\n",
       "      <td>23.7806</td>\n",
       "      <td>25.4808</td>\n",
       "      <td>27.7529</td>\n",
       "      <td>34.8096</td>\n",
       "      <td>47.4142</td>\n",
       "      <td>47.4142</td>\n",
       "      <td>0.0502</td>\n",
       "      <td>775.4204</td>\n",
       "      <td>228.927</td>\n",
       "      <td>1.145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      P@1      P@3      P@5    P@10     N@1     N@3      N@5     N@10  \\\n",
       "0  25.688  17.4213  13.4276  8.7873  25.688  26.108  27.3521  29.4336   \n",
       "\n",
       "     PSP@1    PSP@3   PSP@5   PSP@10    PSN@1    PSN@3    PSN@5   PSN@10  \\\n",
       "0  21.5048  23.2458  25.352  29.8492  21.5048  23.7806  25.4808  27.7529   \n",
       "\n",
       "      R@10    R@100    R@200    loss   runtime  samples_per_second  \\\n",
       "0  34.8096  47.4142  47.4142  0.0502  775.4204             228.927   \n",
       "\n",
       "   steps_per_second  \n",
       "0             1.145  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_metric(o.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b38392",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692d67c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e59faa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
