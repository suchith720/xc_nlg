{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e3a0f4c-1cfb-4a14-b8f2-fdea31c390ec",
   "metadata": {},
   "source": [
    "# RAGDA LORA training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddda97e8-16ac-42c7-9ad4-f981e21c0aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp 92-radga-dr-ep-for-wikiseealso-lora-1-0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f35d8be-1323-400a-b78e-d0a4d2697801",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d685e35e-9a13-4186-b7f4-b831b10086bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "comet_ml is installed but `COMET_API_KEY` is not set.\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import os,torch, torch.multiprocessing as mp, pickle\n",
    "from xcai.basics import *\n",
    "from xcai.models.radga_lora import RAD001\n",
    "from xclib.utils.sparse import retain_topk\n",
    "\n",
    "from transformers import DistilBertConfig,DistilBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55428488-a5d0-4a56-93bb-247ab9299cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c924c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['WANDB_MODE'] = 'disabled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53768670-9905-46b0-9a6d-b6e91d50b918",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n",
    "os.environ['WANDB_PROJECT']='xc-nlg_66-radga-dr-ep-for-wikiseealso-2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc96ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/scai/phd/aiz218323/Projects/XC_NLG/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f7ff60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "pkl_dir = '/home/scai/phd/aiz218323/scratch/datasets/'\n",
    "pkl_file = f'{pkl_dir}/processed/wikiseealso_data-linker_distilbert-base-uncased_rm_oak-linker.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a19cd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "with open(pkl_file, 'rb') as file: block = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9908ab26-18af-4946-ad1f-c4f6bf6d4e4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddd0bc8-ee21-41b6-bf9f-675bfa2574d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "data_meta = retain_topk(block.train.dset.meta.lnk_meta.data_meta, k=5)\n",
    "block.train.dset.meta.lnk_meta.data_meta = data_meta\n",
    "block.train.dset.meta.lnk_meta.curr_data_meta = data_meta\n",
    "\n",
    "data_meta = retain_topk(block.test.dset.meta.lnk_meta.data_meta, k=3)\n",
    "block.test.dset.meta.lnk_meta.data_meta = data_meta\n",
    "block.test.dset.meta.lnk_meta.curr_data_meta = data_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192a19fc-9fa7-4532-9eda-9a738f8d2acb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2554487b",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8521c4ff-94e8-43a2-84eb-553610cb7de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "args = XCLearningArguments(\n",
    "    output_dir='/home/scai/phd/aiz218323/scratch/outputs/92-radga-dr-ep-for-wikiseealso-lora-1-0',\n",
    "    logging_first_step=True,\n",
    "    per_device_train_batch_size=10, #800,\n",
    "    per_device_eval_batch_size=800,\n",
    "    representation_num_beams=200,\n",
    "    representation_accumulation_steps=10,\n",
    "    save_strategy=\"steps\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=10, #5000,\n",
    "    save_steps=10, #5000,\n",
    "    save_total_limit=5,\n",
    "    num_train_epochs=300,\n",
    "    predict_with_representation=True,\n",
    "    adam_epsilon=1e-6,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    learning_rate=2e-4,\n",
    "    generation_num_beams=10,\n",
    "    generation_length_penalty=1.5,\n",
    "    predict_with_generation=True,\n",
    "    representation_search_type='BRUTEFORCE',\n",
    "    \n",
    "    output_representation_attribute='data_fused_repr',\n",
    "    label_representation_attribute='data_repr',\n",
    "    metadata_representation_attribute='data_repr',\n",
    "    data_augmentation_attribute='data_repr',\n",
    "    representation_attribute='data_fused_repr',\n",
    "    clustering_representation_attribute='data_fused_repr',\n",
    "    \n",
    "    group_by_cluster=True,\n",
    "    num_clustering_warmup_epochs=10,\n",
    "    num_cluster_update_epochs=5,\n",
    "    num_cluster_size_update_epochs=25,\n",
    "    use_data_metadata_for_clustering=True,\n",
    "    clustering_type='EXPO',\n",
    "    minimum_cluster_size=2,\n",
    "    maximum_cluster_size=1600,\n",
    "\n",
    "    metric_for_best_model='P@1',\n",
    "    load_best_model_at_end=True,\n",
    "    target_indices_key='plbl2data_idx',\n",
    "    target_pointer_key='plbl2data_data2ptr',\n",
    "    \n",
    "    use_distributional_representation=False,\n",
    "    use_encoder_parallel=True,\n",
    "    max_grad_norm=None, \n",
    "    fp16=True,\n",
    "    \n",
    "    label_names=['lnk2data_idx', 'lnk2data_input_ids', 'lnk2data_attention_mask'],\n",
    "    \n",
    "    prune_metadata=False,\n",
    "    num_metadata_prune_warmup_epochs=10,\n",
    "    num_metadata_prune_epochs=5,\n",
    "    metadata_prune_batch_size=2048,\n",
    "    prune_metadata_names=['cat_meta'],\n",
    "    use_data_metadata_for_pruning=True,\n",
    "\n",
    "    predict_with_augmentation=False,\n",
    "    use_augmentation_index_representation=True,\n",
    "    \n",
    "    data_aug_meta_name='lnk',\n",
    "    augmentation_num_beams=3,\n",
    "    data_aug_prefix='lnk',\n",
    "    use_label_metadata=False,\n",
    "    \n",
    "    data_meta_batch_size=2048,\n",
    "    augment_metadata=False,\n",
    "    num_metadata_augment_warmup_epochs=10,\n",
    "    num_metadata_augment_epochs=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbc728f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "metric = PrecRecl(block.n_lbl, block.test.data_lbl_filterer, prop=block.train.dset.data.data_lbl,\n",
    "                  pk=10, rk=200, rep_pk=[1, 3, 5, 10], rep_rk=[10, 100, 200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29041ca-d9ac-4607-a053-263390cb6bca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12171f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "bsz = max(args.per_device_train_batch_size, args.per_device_eval_batch_size)*torch.cuda.device_count()\n",
    "\n",
    "base_model = DistilBertModel.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4')\n",
    "\n",
    "model = RAD001(DistilBertConfig(), resize_length=5000, base_model=base_model, lora_r=8, lora_alpha=32,\n",
    "               \n",
    "               batch_size=100, num_batch_labels=5000, margin=0.3, num_negatives=10, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "               data_aug_meta_prefix='lnk2data', lbl2data_aug_meta_prefix=None, data_pred_meta_prefix=None, lbl2data_pred_meta_prefix=None,\n",
    "               \n",
    "               use_query_loss=True,\n",
    "               \n",
    "               calib_margin=0.05, calib_num_negatives=10, calib_tau=0.1, calib_apply_softmax=False, calib_loss_weight=0.1,\n",
    "               use_calib_loss=True,\n",
    "               \n",
    "               meta_loss_weight=0.0, fusion_loss_weight=0.0, use_fusion_loss=False,\n",
    "               use_encoder_parallel=False)\n",
    "\n",
    "model.init_retrieval_head()\n",
    "model.init_cross_head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50683d2-49ad-4abe-b19e-1f3c0884c9b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6e2864-12bb-4aec-afad-b3e2de623672",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = PrecRecl(block.n_lbl, test_dset.data.data_lbl_filterer, prop=block.train.dset.data.data_lbl,\n",
    "                  pk=10, rk=200, rep_pk=[1, 3, 5, 10], rep_rk=[10, 100, 200])\n",
    "test_dset = block.test.dset.sample(n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d48f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "learn = XCLearner(\n",
    "    model=model, \n",
    "    args=args,\n",
    "    train_dataset=block.train.dset,\n",
    "    eval_dataset=test_dset, #block.test.dset,\n",
    "    data_collator=block.collator,\n",
    "    compute_metrics=metric,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3f3767-1cab-4969-8cb5-17050f710637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func():\n",
    "    import pdb; pdb.set_trace()\n",
    "    return learn.train()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99e7d3f-c4c3-44c9-b5da-f137aa58e064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_16160/199652302.py(3)func()\n",
      "      1 def func():\n",
      "      2     import pdb; pdb.set_trace()\n",
      "----> 3     return learn.train()\n",
      "      4 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='10396500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [      29/10396500 31:19 < 201048:46:48, 0.01 it/s, Epoch 0.00/300]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>P@1</th>\n",
       "      <th>P@10</th>\n",
       "      <th>P@3</th>\n",
       "      <th>P@5</th>\n",
       "      <th>N@1</th>\n",
       "      <th>N@10</th>\n",
       "      <th>N@3</th>\n",
       "      <th>N@5</th>\n",
       "      <th>Psp@1</th>\n",
       "      <th>Psp@10</th>\n",
       "      <th>Psp@3</th>\n",
       "      <th>Psp@5</th>\n",
       "      <th>Psn@1</th>\n",
       "      <th>Psn@10</th>\n",
       "      <th>Psn@3</th>\n",
       "      <th>Psn@5</th>\n",
       "      <th>R@200</th>\n",
       "      <th>R@10</th>\n",
       "      <th>R@100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.036700</td>\n",
       "      <td>0.046844</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.048000</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.157398</td>\n",
       "      <td>0.128247</td>\n",
       "      <td>0.146054</td>\n",
       "      <td>0.062985</td>\n",
       "      <td>0.135187</td>\n",
       "      <td>0.098130</td>\n",
       "      <td>0.119156</td>\n",
       "      <td>0.062985</td>\n",
       "      <td>0.118691</td>\n",
       "      <td>0.088369</td>\n",
       "      <td>0.105291</td>\n",
       "      <td>0.433421</td>\n",
       "      <td>0.211980</td>\n",
       "      <td>0.383770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.036700</td>\n",
       "      <td>0.040589</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.049000</td>\n",
       "      <td>0.096667</td>\n",
       "      <td>0.076000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.161122</td>\n",
       "      <td>0.132705</td>\n",
       "      <td>0.146201</td>\n",
       "      <td>0.055039</td>\n",
       "      <td>0.137724</td>\n",
       "      <td>0.101172</td>\n",
       "      <td>0.116275</td>\n",
       "      <td>0.055039</td>\n",
       "      <td>0.117239</td>\n",
       "      <td>0.087297</td>\n",
       "      <td>0.102091</td>\n",
       "      <td>0.409948</td>\n",
       "      <td>0.223702</td>\n",
       "      <td>0.370837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b279ca2cc0f48a3a32a9025d79ae926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/scipy/sparse/_index.py:145: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n",
      "Checkpoint destination directory /home/scai/phd/aiz218323/scratch/outputs/92-radga-dr-ep-for-wikiseealso-lora-1-0/checkpoint-10 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09de5ac8b31f47968a90a023a9340967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/scipy/sparse/_index.py:145: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Program interrupted. (Use 'cont' to resume).\n",
      "--Return--\n",
      "None\n",
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/autograd/__init__.py(266)backward()\n",
      "    264     # some Python versions print out the first line of a multi-line function\n",
      "    265     # calls in the traceback and some print out the last line\n",
      "--> 266     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    267         tensors,\n",
      "    268         grad_tensors_,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "None\n",
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/_tensor.py(522)backward()\n",
      "    520                 inputs=inputs,\n",
      "    521             )\n",
      "--> 522         torch.autograd.backward(\n",
      "    523             self, gradient, retain_graph, create_graph, inputs=inputs\n",
      "    524         )\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "None\n",
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/accelerate/accelerator.py(1999)backward()\n",
      "   1997             return\n",
      "   1998         elif self.scaler is not None:\n",
      "-> 1999             self.scaler.scale(loss).backward(**kwargs)\n",
      "   2000         else:\n",
      "   2001             loss.backward(**kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/comet_ml/monkey_patching.py(294)wrapper()\n",
      "    292 \n",
      "    293         # Call after callbacks once we have the return value\n",
      "--> 294         if should_run:\n",
      "    295             for callback in after_callbacks:\n",
      "    296                 callback_allows_exception = getattr(\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/comet_ml/monkey_patching.py(316)wrapper()\n",
      "    314                     )\n",
      "    315 \n",
      "--> 316         if exception_raised is not None:\n",
      "    317             raise exception_raised\n",
      "    318 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "None\n",
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/comet_ml/monkey_patching.py(319)wrapper()\n",
      "    317             raise exception_raised\n",
      "    318 \n",
      "--> 319         return return_value\n",
      "    320 \n",
      "    321     # Simulate functools.wraps behavior but make it working with mocks\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/trainer.py(2913)training_step()\n",
      "   2911             self.accelerator.backward(loss)\n",
      "   2912 \n",
      "-> 2913         return loss.detach() / self.args.gradient_accumulation_steps\n",
      "   2914 \n",
      "   2915     def compute_loss(self, model, inputs, return_outputs=False):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.model.forward\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method convert_outputs_to_fp32.<locals>.forward of RAD001(\n",
      "  (encoder): Encoder(\n",
      "    (distilbert): PeftModel(\n",
      "      (base_model): LoraModel(\n",
      "        (model): DistilBertModel(\n",
      "          (embeddings): Embeddings(\n",
      "            (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "            (position_embeddings): Embedding(512, 768)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (transformer): Transformer(\n",
      "            (layer): ModuleList(\n",
      "              (0-5): 6 x TransformerBlock(\n",
      "                (attention): MultiHeadSelfAttention(\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  (q_lin): lora.Linear(\n",
      "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (lbl2data): Dropout(p=0.05, inplace=False)\n",
      "                      (lnk2data): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (lbl2data): Linear(in_features=768, out_features=8, bias=False)\n",
      "                      (lnk2data): Linear(in_features=768, out_features=8, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (lbl2data): Linear(in_features=8, out_features=768, bias=False)\n",
      "                      (lnk2data): Linear(in_features=8, out_features=768, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                    (lora_magnitude_vector): ModuleDict()\n",
      "                  )\n",
      "                  (k_lin): lora.Linear(\n",
      "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (lbl2data): Dropout(p=0.05, inplace=False)\n",
      "                      (lnk2data): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (lbl2data): Linear(in_features=768, out_features=8, bias=False)\n",
      "                      (lnk2data): Linear(in_features=768, out_features=8, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (lbl2data): Linear(in_features=8, out_features=768, bias=False)\n",
      "                      (lnk2data): Linear(in_features=8, out_features=768, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                    (lora_magnitude_vector): ModuleDict()\n",
      "                  )\n",
      "                  (v_lin): lora.Linear(\n",
      "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (lbl2data): Dropout(p=0.05, inplace=False)\n",
      "                      (lnk2data): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (lbl2data): Linear(in_features=768, out_features=8, bias=False)\n",
      "                      (lnk2data): Linear(in_features=768, out_features=8, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (lbl2data): Linear(in_features=8, out_features=768, bias=False)\n",
      "                      (lnk2data): Linear(in_features=8, out_features=768, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                    (lora_magnitude_vector): ModuleDict()\n",
      "                  )\n",
      "                  (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "                )\n",
      "                (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (ffn): FFN(\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (activation): GELUActivation()\n",
      "                )\n",
      "                (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (dr_head): RepresentationHead(\n",
      "      (transform): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (projector): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): GELUActivation()\n",
      "    )\n",
      "    (dr_fused_head): RepresentationHead(\n",
      "      (transform): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (projector): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): GELUActivation()\n",
      "    )\n",
      "    (meta_head): RepresentationHead(\n",
      "      (transform): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (projector): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): GELUActivation()\n",
      "    )\n",
      "    (cross_head): CrossAttention(\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (q): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (k): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (v): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (o): Linear(in_features=768, out_features=768, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (rep_loss_fn): MultiTriplet()\n",
      "  (cab_loss_fn): Calibration()\n",
      ")>\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  b self.model.forward\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breakpoint 3 at /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/accelerate/utils/operations.py:821\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  b self.model.encoder.forward\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breakpoint 4 at /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga_lora.py:352\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/accelerate/utils/operations.py(822)forward()\n",
      "    820 \n",
      "3   821     def forward(*args, **kwargs):\n",
      "--> 822         return model_forward(*args, **kwargs)\n",
      "    823 \n",
      "    824     # To act like a decorator so that it can be popped when doing `extract_model_from_parallel`\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/accelerate/utils/operations.py(809)__call__()\n",
      "    807         update_wrapper(self, model_forward)\n",
      "    808 \n",
      "--> 809     def __call__(self, *args, **kwargs):\n",
      "    810         return convert_to_fp32(self.model_forward(*args, **kwargs))\n",
      "    811 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/accelerate/utils/operations.py(810)__call__()\n",
      "    808 \n",
      "    809     def __call__(self, *args, **kwargs):\n",
      "--> 810         return convert_to_fp32(self.model_forward(*args, **kwargs))\n",
      "    811 \n",
      "    812     def __getstate__(self):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/amp/autocast_mode.py(13)decorate_autocast()\n",
      "     11 \n",
      "     12 def autocast_decorator(autocast_instance, func):\n",
      "---> 13     @functools.wraps(func)\n",
      "     14     def decorate_autocast(*args, **kwargs):\n",
      "     15         with autocast_instance:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/amp/autocast_mode.py(15)decorate_autocast()\n",
      "     13     @functools.wraps(func)\n",
      "     14     def decorate_autocast(*args, **kwargs):\n",
      "---> 15         with autocast_instance:\n",
      "     16             return func(*args, **kwargs)\n",
      "     17 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/amp/autocast_mode.py(16)decorate_autocast()\n",
      "     14     def decorate_autocast(*args, **kwargs):\n",
      "     15         with autocast_instance:\n",
      "---> 16             return func(*args, **kwargs)\n",
      "     17 \n",
      "     18     decorate_autocast.__script_unsupported = \"@autocast() decorator is not supported in script mode\"  # type: ignore[attr-defined]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/accelerate/utils/operations.py(821)forward()\n",
      "    819     model_forward = ConvertOutputsToFp32(model_forward)\n",
      "    820 \n",
      "3-> 821     def forward(*args, **kwargs):\n",
      "    822         return model_forward(*args, **kwargs)\n",
      "    823 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/accelerate/utils/operations.py(822)forward()\n",
      "    820 \n",
      "3   821     def forward(*args, **kwargs):\n",
      "--> 822         return model_forward(*args, **kwargs)\n",
      "    823 \n",
      "    824     # To act like a decorator so that it can be popped when doing `extract_model_from_parallel`\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/accelerate/utils/operations.py(809)__call__()\n",
      "    807         update_wrapper(self, model_forward)\n",
      "    808 \n",
      "--> 809     def __call__(self, *args, **kwargs):\n",
      "    810         return convert_to_fp32(self.model_forward(*args, **kwargs))\n",
      "    811 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/accelerate/utils/operations.py(822)forward()\n",
      "    820 \n",
      "3   821     def forward(*args, **kwargs):\n",
      "--> 822         return model_forward(*args, **kwargs)\n",
      "    823 \n",
      "    824     # To act like a decorator so that it can be popped when doing `extract_model_from_parallel`\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga_lora.py(361)forward()\n",
      "    359         **kwargs\n",
      "    360     ):\n",
      "--> 361         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "    362 \n",
      "    363         if data_type is not None and data_type == \"meta\":\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  xx = [n for n,p in self.named_parameters() if p.requires_grad]\n",
      "ipdb>  len(xx)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.distilbert.active_adapters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lbl2data']\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga_lora.py(363)forward()\n",
      "    361         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "    362 \n",
      "--> 363         if data_type is not None and data_type == \"meta\":\n",
      "    364             data_repr = self.meta_unnormalized(data_o[0], data_attention_mask) if data_unnormalized else self.meta(data_o[0], data_attention_mask)\n",
      "    365         else:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga_lora.py(366)forward()\n",
      "    364             data_repr = self.meta_unnormalized(data_o[0], data_attention_mask) if data_unnormalized else self.meta(data_o[0], data_attention_mask)\n",
      "    365         else:\n",
      "--> 366             data_repr = self.dr(data_o[0], data_attention_mask)\n",
      "    367 \n",
      "    368         data_fused_repr = meta_repr = None\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga_lora.py(368)forward()\n",
      "    366             data_repr = self.dr(data_o[0], data_attention_mask)\n",
      "    367 \n",
      "--> 368         data_fused_repr = meta_repr = None\n",
      "    369         if data_aug_meta_prefix is not None:\n",
      "    370             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga_lora.py(369)forward()\n",
      "    367 \n",
      "    368         data_fused_repr = meta_repr = None\n",
      "--> 369         if data_aug_meta_prefix is not None:\n",
      "    370             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "    371             if len(meta_kwargs):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga_lora.py(370)forward()\n",
      "    368         data_fused_repr = meta_repr = None\n",
      "    369         if data_aug_meta_prefix is not None:\n",
      "--> 370             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "    371             if len(meta_kwargs):\n",
      "    372                 if self.training: self._mark_only_adapters_as_trainable()\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga_lora.py(371)forward()\n",
      "    369         if data_aug_meta_prefix is not None:\n",
      "    370             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "--> 371             if len(meta_kwargs):\n",
      "    372                 if self.training: self._mark_only_adapters_as_trainable()\n",
      "    373                 data_fused_embed, meta_repr = self.fuse_meta_into_embeddings(data_o[0], \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga_lora.py(372)forward()\n",
      "    370             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "    371             if len(meta_kwargs):\n",
      "--> 372                 if self.training: self._mark_only_adapters_as_trainable()\n",
      "    373                 data_fused_embed, meta_repr = self.fuse_meta_into_embeddings(data_o[0], \n",
      "    374                                                                              data_attention_mask,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga_lora.py(373)forward()\n",
      "    371             if len(meta_kwargs):\n",
      "    372                 if self.training: self._mark_only_adapters_as_trainable()\n",
      "--> 373                 data_fused_embed, meta_repr = self.fuse_meta_into_embeddings(data_o[0], \n",
      "    374                                                                              data_attention_mask,\n",
      "    375                                                                              meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  xx = [n for n,p in self.named_parameters() if p.requires_grad]\n",
      "ipdb>  len(xx)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga_lora.py(374)forward()\n",
      "    372                 if self.training: self._mark_only_adapters_as_trainable()\n",
      "    373                 data_fused_embed, meta_repr = self.fuse_meta_into_embeddings(data_o[0], \n",
      "--> 374                                                                              data_attention_mask,\n",
      "    375                                                                              meta_kwargs)\n",
      "    376                 data_fused_repr = self.dr_fused(data_fused_embed, data_attention_mask)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga_lora.py(375)forward()\n",
      "    373                 data_fused_embed, meta_repr = self.fuse_meta_into_embeddings(data_o[0], \n",
      "    374                                                                              data_attention_mask,\n",
      "--> 375                                                                              meta_kwargs)\n",
      "    376                 data_fused_repr = self.dr_fused(data_fused_embed, data_attention_mask)\n",
      "    377 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga_lora.py(373)forward()\n",
      "    371             if len(meta_kwargs):\n",
      "    372                 if self.training: self._mark_only_adapters_as_trainable()\n",
      "--> 373                 data_fused_embed, meta_repr = self.fuse_meta_into_embeddings(data_o[0], \n",
      "    374                                                                              data_attention_mask,\n",
      "    375                                                                              meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga_lora.py(376)forward()\n",
      "    374                                                                              data_attention_mask,\n",
      "    375                                                                              meta_kwargs)\n",
      "--> 376                 data_fused_repr = self.dr_fused(data_fused_embed, data_attention_mask)\n",
      "    377 \n",
      "    378                 self.distilbert.set_adapter('lbl2data')\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga_lora.py(378)forward()\n",
      "    376                 data_fused_repr = self.dr_fused(data_fused_embed, data_attention_mask)\n",
      "    377 \n",
      "--> 378                 self.distilbert.set_adapter('lbl2data')\n",
      "    379                 if self.training: self._mark_entire_encoder_as_trainable()\n",
      "    380 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.distilbert.active_adapters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lnk2data']\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  xx = [n for n,p in self.named_parameters() if p.requires_grad]\n",
      "ipdb>  len(xx)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  aa = [o for o in xx if 'lnk2data' in o]\n",
      "ipdb>  len(aa)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  aa = [o for o in xx if 'lbl2data' in o]\n",
      "ipdb>  len(aa)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga_lora.py(379)forward()\n",
      "    377 \n",
      "    378                 self.distilbert.set_adapter('lbl2data')\n",
      "--> 379                 if self.training: self._mark_entire_encoder_as_trainable()\n",
      "    380 \n",
      "    381         return EncoderOutput(\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.distilbert.active_adapters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lbl2data']\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga_lora.py(381)forward()\n",
      "    379                 if self.training: self._mark_entire_encoder_as_trainable()\n",
      "    380 \n",
      "--> 381         return EncoderOutput(\n",
      "    382             rep=data_repr,\n",
      "    383             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  xx = [n for n,p in self.named_parameters() if p.requires_grad]\n",
      "ipdb>  len(xx)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga_lora.py(382)forward()\n",
      "    380 \n",
      "    381         return EncoderOutput(\n",
      "--> 382             rep=data_repr,\n",
      "    383             fused_rep=data_fused_repr,\n",
      "    384             meta_repr=meta_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga_lora.py(383)forward()\n",
      "    381         return EncoderOutput(\n",
      "    382             rep=data_repr,\n",
      "--> 383             fused_rep=data_fused_repr,\n",
      "    384             meta_repr=meta_repr,\n",
      "    385         )\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga_lora.py(384)forward()\n",
      "    382             rep=data_repr,\n",
      "    383             fused_rep=data_fused_repr,\n",
      "--> 384             meta_repr=meta_repr,\n",
      "    385         )\n",
      "    386 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga_lora.py(381)forward()\n",
      "    379                 if self.training: self._mark_entire_encoder_as_trainable()\n",
      "    380 \n",
      "--> 381         return EncoderOutput(\n",
      "    382             rep=data_repr,\n",
      "    383             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "EncoderOutput...vBackward0>)})\n",
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga_lora.py(381)forward()\n",
      "    379                 if self.training: self._mark_entire_encoder_as_trainable()\n",
      "    380 \n",
      "--> 381         return EncoderOutput(\n",
      "    382             rep=data_repr,\n",
      "    383             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga_lora.py(565)forward()\n",
      "    563 \n",
      "    564 \n",
      "--> 565         loss = None; lbl2data_o = EncoderOutput()\n",
      "    566         if lbl2data_input_ids is not None:\n",
      "    567             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga_lora.py(566)forward()\n",
      "    564 \n",
      "    565         loss = None; lbl2data_o = EncoderOutput()\n",
      "--> 566         if lbl2data_input_ids is not None:\n",
      "    567             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "    568             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga_lora.py(567)forward()\n",
      "    565         loss = None; lbl2data_o = EncoderOutput()\n",
      "    566         if lbl2data_input_ids is not None:\n",
      "--> 567             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "    568             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "    569                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga_lora.py(568)forward()\n",
      "    566         if lbl2data_input_ids is not None:\n",
      "    567             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "--> 568             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "    569                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
      "    570 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga_lora.py(569)forward()\n",
      "    567             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "    568             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "--> 569                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
      "    570 \n",
      "    571             loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga_lora.py(568)forward()\n",
      "    566         if lbl2data_input_ids is not None:\n",
      "    567             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "--> 568             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "    569                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
      "    570 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga_lora.py(569)forward()\n",
      "    567             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "    568             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "--> 569                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
      "    570 \n",
      "    571             loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga_lora.py(568)forward()\n",
      "    566         if lbl2data_input_ids is not None:\n",
      "    567             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "--> 568             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "    569                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
      "    570 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga_lora.py(361)forward()\n",
      "    359         **kwargs\n",
      "    360     ):\n",
      "--> 361         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "    362 \n",
      "    363         if data_type is not None and data_type == \"meta\":\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  xx = [n for n,p in self.named_parameters() if p.requires_grad]\n",
      "ipdb>  len(xx)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  aa = [o for o in xx if 'lnk2data' in o]\n",
      "ipdb>  len(aa)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  aa = [o for o in xx if 'lbl2data' in o]\n",
      "ipdb>  len(aa)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga_lora.py(363)forward()\n",
      "    361         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "    362 \n",
      "--> 363         if data_type is not None and data_type == \"meta\":\n",
      "    364             data_repr = self.meta_unnormalized(data_o[0], data_attention_mask) if data_unnormalized else self.meta(data_o[0], data_attention_mask)\n",
      "    365         else:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga_lora.py(366)forward()\n",
      "    364             data_repr = self.meta_unnormalized(data_o[0], data_attention_mask) if data_unnormalized else self.meta(data_o[0], data_attention_mask)\n",
      "    365         else:\n",
      "--> 366             data_repr = self.dr(data_o[0], data_attention_mask)\n",
      "    367 \n",
      "    368         data_fused_repr = meta_repr = None\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga_lora.py(368)forward()\n",
      "    366             data_repr = self.dr(data_o[0], data_attention_mask)\n",
      "    367 \n",
      "--> 368         data_fused_repr = meta_repr = None\n",
      "    369         if data_aug_meta_prefix is not None:\n",
      "    370             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga_lora.py(369)forward()\n",
      "    367 \n",
      "    368         data_fused_repr = meta_repr = None\n",
      "--> 369         if data_aug_meta_prefix is not None:\n",
      "    370             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "    371             if len(meta_kwargs):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga_lora.py(381)forward()\n",
      "    379                 if self.training: self._mark_entire_encoder_as_trainable()\n",
      "    380 \n",
      "--> 381         return EncoderOutput(\n",
      "    382             rep=data_repr,\n",
      "    383             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga_lora.py(382)forward()\n",
      "    380 \n",
      "    381         return EncoderOutput(\n",
      "--> 382             rep=data_repr,\n",
      "    383             fused_rep=data_fused_repr,\n",
      "    384             meta_repr=meta_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga_lora.py(383)forward()\n",
      "    381         return EncoderOutput(\n",
      "    382             rep=data_repr,\n",
      "--> 383             fused_rep=data_fused_repr,\n",
      "    384             meta_repr=meta_repr,\n",
      "    385         )\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/accelerate/utils/operations.py(822)forward()\n",
      "    820 \n",
      "3   821     def forward(*args, **kwargs):\n",
      "--> 822         return model_forward(*args, **kwargs)\n",
      "    823 \n",
      "    824     # To act like a decorator so that it can be popped when doing `extract_model_from_parallel`\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  q\n"
     ]
    }
   ],
   "source": [
    "func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019c0d6e-5d7f-455f-80ca-efc749ae6c70",
   "metadata": {},
   "source": [
    "xx = [n for n,p in self.named_parameters() if p.requires_grad]\n",
    "\n",
    "aa = [o for o in xx if 'lnk2data' in o]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a53091-941d-4445-8387-5c803e23bff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='10396500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [      11/10396500 00:01 < 386:10:50, 7.48 it/s, Epoch 0.00/300]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:57]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb37e64e2b1c4f509373fdb1eb5f679a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/scipy/sparse/_index.py:145: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f037c311-c6ef-457a-b34f-e9ae105838d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cd155e-912d-4780-b60d-b7c6749b30b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "if __name__ == '__main__':\n",
    "    mp.freeze_support()\n",
    "    learn.train()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130617dd-f34b-41f8-a299-3a2654c8939a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5df2b60-c20b-4e7c-83fe-d583e55d781c",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d622383-db42-403d-8b0c-e2d44f9bfad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = XCLearningArguments(\n",
    "    output_dir='/home/scai/phd/aiz218323/scratch/outputs/80-radga-dr-ep-for-wikiseealso-1-0',\n",
    "    logging_first_step=True,\n",
    "    per_device_train_batch_size=800,\n",
    "    per_device_eval_batch_size=800,\n",
    "    representation_num_beams=200,\n",
    "    representation_accumulation_steps=10,\n",
    "    save_strategy=\"steps\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=5000,\n",
    "    save_steps=5000,\n",
    "    save_total_limit=5,\n",
    "    num_train_epochs=300,\n",
    "    predict_with_representation=True,\n",
    "    adam_epsilon=1e-6,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    learning_rate=2e-4,\n",
    "    generation_num_beams=10,\n",
    "    generation_length_penalty=1.5,\n",
    "    predict_with_generation=True,\n",
    "    representation_search_type='BRUTEFORCE',\n",
    "    \n",
    "    output_representation_attribute='data_fused_repr',\n",
    "    label_representation_attribute='data_repr',\n",
    "    metadata_representation_attribute='data_repr',\n",
    "    data_augmentation_attribute='data_repr',\n",
    "    representation_attribute='data_fused_repr',\n",
    "    clustering_representation_attribute='data_fused_repr',\n",
    "    \n",
    "    group_by_cluster=True,\n",
    "    num_clustering_warmup_epochs=10,\n",
    "    num_cluster_update_epochs=5,\n",
    "    num_cluster_size_update_epochs=25,\n",
    "    use_data_metadata_for_clustering=True,\n",
    "    clustering_type='EXPO',\n",
    "    minimum_cluster_size=2,\n",
    "    maximum_cluster_size=1600,\n",
    "\n",
    "    metric_for_best_model='P@1',\n",
    "    load_best_model_at_end=True,\n",
    "    target_indices_key='plbl2data_idx',\n",
    "    target_pointer_key='plbl2data_data2ptr',\n",
    "    \n",
    "    use_distributional_representation=False,\n",
    "    use_encoder_parallel=True,\n",
    "    max_grad_norm=None, \n",
    "    fp16=True,\n",
    "    \n",
    "    label_names=['lnk2data_idx', 'lnk2data_input_ids', 'lnk2data_attention_mask'],\n",
    "\n",
    "    prune_metadata=False,\n",
    "    num_metadata_prune_warmup_epochs=10,\n",
    "    num_metadata_prune_epochs=5,\n",
    "    metadata_prune_batch_size=2048,\n",
    "    prune_metadata_names=['cat_meta'],\n",
    "    use_data_metadata_for_pruning=True,\n",
    "\n",
    "    predict_with_augmentation=False,\n",
    "    use_augmentation_index_representation=True,\n",
    "    \n",
    "    data_aug_meta_name='lnk',\n",
    "    augmentation_num_beams=3,\n",
    "    data_aug_prefix='lnk',\n",
    "    use_label_metadata=False,\n",
    "    \n",
    "    data_meta_batch_size=2048,\n",
    "    augment_metadata=False,\n",
    "    num_metadata_augment_warmup_epochs=10,\n",
    "    num_metadata_augment_epochs=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4865c84b-0d78-47ea-ac8a-ed10a324e7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = PrecRecl(block.n_lbl, block.test.data_lbl_filterer, prop=block.train.dset.data.data_lbl,\n",
    "                  pk=10, rk=200, rep_pk=[1, 3, 5, 10], rep_rk=[10, 100, 200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69926870-0db1-4bc8-9117-a9b16983144d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RAD006 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "bsz = max(args.per_device_train_batch_size, args.per_device_eval_batch_size)*torch.cuda.device_count()\n",
    "\n",
    "model = RAD006.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', batch_size=bsz, num_batch_labels=5000, \n",
    "                               margin=0.3, num_negatives=10, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='lnk2data', lbl2data_aug_meta_prefix=None, \n",
    "                               data_pred_meta_prefix=None, lbl2data_pred_meta_prefix=None,\n",
    "\n",
    "                               resize_length=5000, use_noise=False, shuffle_noise_pct=0.5, dropout_noise_pct=0.1,\n",
    "                               \n",
    "                               use_query_loss=True,\n",
    "\n",
    "                               calib_margin=0.3, calib_num_negatives=10, calib_tau=0.1, calib_apply_softmax=False, calib_loss_weight=0.1,\n",
    "                               use_calib_loss=True,\n",
    "                               \n",
    "                               meta_loss_weight=0.0, fusion_loss_weight=0.0, use_fusion_loss=False,\n",
    "                               use_encoder_parallel=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4f1045-de24-4be9-890b-defb99f40133",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5329ca-97c0-4560-b097-cf0d5d11cf92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "learn = XCLearner(\n",
    "    model=model, \n",
    "    args=args,\n",
    "    train_dataset=block.train.dset,\n",
    "    eval_dataset=block.test.dset,\n",
    "    data_collator=block.collator,\n",
    "    compute_metrics=metric,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e153e4c-7e57-47c5-bf98-497cd877cf9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd2fe53cc997434db9c4ab57409d1b1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/434 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05e01f21210c400d9e4268d08558faf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/111 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "data_dset = learn._get_dataset(learn.train_dataset, dset_type='data', use_metadata=False)\n",
    "dataloader = learn.get_test_dataloader(data_dset)\n",
    "train_data_repr = learn.get_representation(dataloader, representation_attribute='data_repr')\n",
    "\n",
    "data_dset = learn._get_dataset(learn.eval_dataset, dset_type='data', use_metadata=True)\n",
    "dataloader = learn.get_test_dataloader(data_dset)\n",
    "test_data_repr = learn.get_representation(dataloader, representation_attribute='data_fused_repr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52eef732-fa41-4de4-8f23-700aed482767",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_repr = train_data_repr.to('cuda')\n",
    "test_data_repr = test_data_repr.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e970e9f4-6f2c-48f6-bddc-5110c7e21a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "from xcai.analysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b3eca4-e5ae-4400-8586-530e956ecade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e1b0c5848314dc48f94d2febd57eb08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/178 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from scipy import sparse\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "score, indices, topk = None, None, 3\n",
    "dl = DataLoader(test_data_repr, batch_size=1000)\n",
    "\n",
    "for x in tqdm(dl, total=len(dl)):\n",
    "    o = x@train_data_repr.T\n",
    "    sc,idx = torch.topk(o, topk, dim=1)\n",
    "\n",
    "    score = sc if score is None else torch.cat([score, sc], dim=0)\n",
    "    indices = idx if indices is None else torch.cat([indices, idx], dim=0)\n",
    "\n",
    "score, indices = score.cpu(), indices.cpu()\n",
    "indptr = torch.arange(0, (score.shape[0]+1)*topk, topk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73472b3-e93b-44da-a587-1baae385c37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_hlk = sparse.csr_matrix((score.flatten(), indices.flatten(), indptr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b7f180-d80f-4e2a-9190-ff2da8b5156b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"test_hlk.pkl\"\n",
    "with open(fname, 'wb') as file: pickle.dump(test_hlk, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c913edd-407c-4bfc-8e36-fe7f620dd4cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_input_text': 'Mathematical model',\n",
       " 'lbl2data_input_text': ['Polyhedron model',\n",
       "  'Data model',\n",
       "  'Simulation modeling']}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xcai.data import *\n",
    "test_dset = TextColumns(MainXCDataset(block.test.dset.data.data_info, test_hlk, block.train.dset.data.data_info))\n",
    "test_dset[2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e050c69-0961-4097-9416-8bb222c3a756",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cat = test_hlk@block.train.dset.meta.cat_meta.data_meta\n",
    "\n",
    "block.test.dset.meta.lnk_meta.data_meta = test_cat\n",
    "block.test.dset.meta.lnk_meta.curr_data_meta = test_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b24d163-66cb-40b8-a244-f212d25f3633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23338bdd6a164e8ea8da73fb9af4f928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/scai/phd/aiz218323/Projects/xcai/xcai/losses.py:22: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "  return torch.sparse_csr_tensor(data_ptr, data_idx, scores, device=data_ptr.device)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/scipy/sparse/_index.py:145: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.10378105938434601, 'test_P@1': 0.16729290482494438, 'test_P@10': 0.05309973805035105, 'test_P@3': 0.10881897304453633, 'test_P@5': 0.08202799763404925, 'test_N@1': 0.16729290783405304, 'test_N@10': 0.18368692696094513, 'test_N@3': 0.16428664326667786, 'test_N@5': 0.17077775299549103, 'test_PSP@1': 0.1586184204459441, 'test_PSP@10': 0.1977837675423582, 'test_PSP@3': 0.1613118277559351, 'test_PSP@5': 0.17142875641498287, 'test_PSN@1': 0.15861842036247253, 'test_PSN@10': 0.19298529624938965, 'test_PSN@3': 0.16770175099372864, 'test_PSN@5': 0.17800629138946533, 'test_R@200': 0.3965625126598376, 'test_R@10': 0.22037828039708174, 'test_R@100': 0.35519597960181626, 'test_runtime': 295.0679, 'test_samples_per_second': 601.607, 'test_steps_per_second': 0.376}\n"
     ]
    }
   ],
   "source": [
    "o = learn.predict(block.test.dset)\n",
    "print(o.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e929176-7b68-475d-a553-7f6767456e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'^(data|cat2data|lnk2data)_input_text$'\n",
    "dset = TextColumns(get_pred_dset(pred, block), pat=pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d51636d-4153-43d4-972a-52f8ece31780",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa5a7e5-67a7-4ec6-9727-34201d6ff4fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
