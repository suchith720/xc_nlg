{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e3a0f4c-1cfb-4a14-b8f2-fdea31c390ec",
   "metadata": {},
   "source": [
    "# Ramen with input augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddda97e8-16ac-42c7-9ad4-f981e21c0aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp 25-ramen-style-clover-training-with-input-augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f35d8be-1323-400a-b78e-d0a4d2697801",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d685e35e-9a13-4186-b7f4-b831b10086bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os,torch, torch.multiprocessing as mp, sys, pickle\n",
    "from xcai.basics import *\n",
    "from xcai.models.MMM0XX import DBT017\n",
    "from xcai.transform import AugmentMetaInputIdsTfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0c924c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['WANDB_MODE'] = 'disabled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53768670-9905-46b0-9a6d-b6e91d50b918",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2,3'\n",
    "os.environ['WANDB_PROJECT']='xc-nlg_25-ramen-style-clover-training-with-input-augmentation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ca2ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "data_dir = '/home/aiscuser/scratch/datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0318c2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiscuser/.local/lib/python3.9/site-packages/xclib-0.97-py3.9-linux-x86_64.egg/xclib/data/data_utils.py:263: UserWarning: Header mis-match from inferred shape!\n",
      "  warnings.warn(\"Header mis-match from inferred shape!\")\n",
      "/opt/conda/envs/ptca/lib/python3.9/site-packages/scipy/sparse/_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "block = XCBlock.from_cfg(data_dir, 'data_metas', valid_pct=0.001, tfm='rm', tokenizer='distilbert-base-uncased', \n",
    "                         smp_features=[('lbl2data|cat2lbl2data',1, 2), ('cat2data',1, 1)], \n",
    "                         n_data_meta_samples=50, n_lbl_meta_samples=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ded95c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "pkl_dir = f'{data_dir}/processed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4778be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{pkl_dir}/wikiseealso_data-metas_distilbert-base-uncased_rm_ramen-cat.pkl', 'wb') as file: \n",
    "    pickle.dump(block, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f61457",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "with open(f'{pkl_dir}/wikiseealso_data-metas_distilbert-base-uncased_rm_ramen-cat.pkl', 'rb') as file: \n",
    "    block = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5610fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='692389' class='' max='692389' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [692389/692389 01:34&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='692389' class='' max='692389' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [692389/692389 00:58&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='686' class='' max='686' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [686/686 00:00&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='686' class='' max='686' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [686/686 00:00&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='177515' class='' max='177515' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [177515/177515 00:19&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='177515' class='' max='177515' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [177515/177515 00:14&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| export\n",
    "block = AugmentMetaInputIdsTfm.apply(block, 'hlk_meta', 32, True)\n",
    "\n",
    "block.train.dset.data.data_info['input_ids'] = block.train.dset.data.data_info['input_ids_aug_hlk']\n",
    "block.train.dset.data.data_info['attention_mask'] = block.train.dset.data.data_info['attention_mask_aug_hlk']\n",
    "\n",
    "block.test.dset.data.data_info['input_ids'] = block.test.dset.data.data_info['input_ids_aug_hlk']\n",
    "block.test.dset.data.data_info['attention_mask'] = block.test.dset.data.data_info['attention_mask_aug_hlk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73b6a059-3409-4c00-a575-dcdb5775adc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/ptca/lib/python3.9/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "args = XCLearningArguments(\n",
    "    output_dir='/home/aiscuser/outputs/25-ramen-style-clover-training-with-input-augmentation',\n",
    "    logging_first_step=True,\n",
    "    per_device_train_batch_size=800,\n",
    "    per_device_eval_batch_size=800,\n",
    "    representation_num_beams=200,\n",
    "    representation_accumulation_steps=10,\n",
    "    save_strategy=\"steps\",\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps=1000,\n",
    "    save_steps=1000,\n",
    "    save_total_limit=5,\n",
    "    num_train_epochs=300,\n",
    "    predict_with_representation=True,\n",
    "    adam_epsilon=1e-6,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.1,\n",
    "    learning_rate=2e-4,\n",
    "    generation_num_beams=10,\n",
    "    generation_length_penalty=1.5,\n",
    "    predict_with_generation=True,\n",
    "    representation_search_type='INDEX',\n",
    "    group_by_cluster=True,\n",
    "    num_clustering_warmup_epochs=10,\n",
    "    num_cluster_update_epochs=5,\n",
    "    num_cluster_size_update_epochs=10,\n",
    "    clustering_type='EXPO',\n",
    "    minimum_cluster_size=1,\n",
    "    maximum_cluster_size=300,\n",
    "    output_concatenation_weight=1.0,\n",
    "    metric_for_best_model='P@1',\n",
    "    load_best_model_at_end=True,\n",
    "    target_indices_key='plbl2data_idx',\n",
    "    target_pointer_key='plbl2data_data2ptr',\n",
    "    fp16=True,\n",
    "    label_names=['cat2data_idx', 'cat2data_input_ids', 'cat2data_attention_mask',\n",
    "                 'cat2lbl2data_idx', 'cat2lbl2data_input_ids', 'cat2lbl2data_attention_mask'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfbc728f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "test_dset = block.test.dset.sample(n=2000, seed=50)\n",
    "metric = PrecRecl(block.n_lbl, test_dset.data.data_lbl_filterer, prop=block.train.dset.data.data_lbl,\n",
    "                  pk=10, rk=200, rep_pk=[1, 3, 5, 10], rep_rk=[10, 100, 200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a12171f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DBT017 were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['dr_layer_norm.bias', 'dr_layer_norm.weight', 'dr_projector.bias', 'dr_projector.weight', 'dr_transform.bias', 'dr_transform.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "bsz = max(args.per_device_train_batch_size, args.per_device_eval_batch_size)*torch.cuda.device_count()\n",
    "\n",
    "model = DBT017.from_pretrained('distilbert-base-uncased', ig_tok=0, bsz=bsz, tn_targ=1000, margin=0.3, tau=0.1, \n",
    "                               n_negatives=5, apply_softmax=True, lw=0.01, m_lw=0.3, meta_prefix='cat')\n",
    "model.init_dr_head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c46e67e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d55b83920d2e4261a144c9b595d7a169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/312330 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| export\n",
    "trie = XCTrie.from_block(block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01d48f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "learn = XCLearner(\n",
    "    model=model, \n",
    "    args=args,\n",
    "    trie=trie,\n",
    "    train_dataset=block.train.dset,\n",
    "    eval_dataset=test_dset,\n",
    "    data_collator=block.collator,\n",
    "    compute_metrics=metric,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558b61ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aba00769",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-30 21:05:03,670] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "wandb: WARNING The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node-0:1810131:1810131 [0] NCCL INFO Bootstrap : Using eth0:10.13.60.215<0>\n",
      "node-0:1810131:1810131 [0] NCCL INFO NET/Plugin : Plugin load (librccl-net.so) returned 2 : librccl-net.so: cannot open shared object file: No such file or directory\n",
      "node-0:1810131:1810131 [0] NCCL INFO NET/Plugin : No plugin found, using internal implementation\n",
      "node-0:1810131:1810131 [0] NCCL INFO Kernel version: 5.15.0-1042-azure\n",
      "RCCL version 2.17.1+hip5.7 HEAD:cbbb3d8+\n",
      "\n",
      "node-0:1810131:1820050 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/misc/ibvwrap.cc:222 NCCL WARN Call to ibv_open_device failed\n",
      "\n",
      "node-0:1810131:1820050 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/transport/net_ib.cc:199 NCCL WARN NET/IB : Unable to open device mlx5_0\n",
      "\n",
      "node-0:1810131:1820050 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/misc/ibvwrap.cc:222 NCCL WARN Call to ibv_open_device failed\n",
      "\n",
      "node-0:1810131:1820050 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/transport/net_ib.cc:199 NCCL WARN NET/IB : Unable to open device mlx5_1\n",
      "\n",
      "node-0:1810131:1820050 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/misc/ibvwrap.cc:222 NCCL WARN Call to ibv_open_device failed\n",
      "\n",
      "node-0:1810131:1820050 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/transport/net_ib.cc:199 NCCL WARN NET/IB : Unable to open device mlx5_2\n",
      "\n",
      "node-0:1810131:1820050 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/misc/ibvwrap.cc:222 NCCL WARN Call to ibv_open_device failed\n",
      "\n",
      "node-0:1810131:1820050 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/transport/net_ib.cc:199 NCCL WARN NET/IB : Unable to open device mlx5_3\n",
      "\n",
      "node-0:1810131:1820050 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/misc/ibvwrap.cc:222 NCCL WARN Call to ibv_open_device failed\n",
      "\n",
      "node-0:1810131:1820050 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/transport/net_ib.cc:199 NCCL WARN NET/IB : Unable to open device mlx5_4\n",
      "\n",
      "node-0:1810131:1820050 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/misc/ibvwrap.cc:222 NCCL WARN Call to ibv_open_device failed\n",
      "\n",
      "node-0:1810131:1820050 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/transport/net_ib.cc:199 NCCL WARN NET/IB : Unable to open device mlx5_5\n",
      "\n",
      "node-0:1810131:1820050 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/misc/ibvwrap.cc:222 NCCL WARN Call to ibv_open_device failed\n",
      "\n",
      "node-0:1810131:1820050 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/transport/net_ib.cc:199 NCCL WARN NET/IB : Unable to open device mlx5_6\n",
      "\n",
      "node-0:1810131:1820050 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/misc/ibvwrap.cc:222 NCCL WARN Call to ibv_open_device failed\n",
      "\n",
      "node-0:1810131:1820050 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/transport/net_ib.cc:199 NCCL WARN NET/IB : Unable to open device mlx5_7\n",
      "\n",
      "node-0:1810131:1820050 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/misc/ibvwrap.cc:222 NCCL WARN Call to ibv_open_device failed\n",
      "\n",
      "node-0:1810131:1820050 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/src/extlibs/rccl/build/hipify/src/transport/net_ib.cc:199 NCCL WARN NET/IB : Unable to open device mlx5_8\n",
      "node-0:1810131:1820050 [0] NCCL INFO NET/IB : No device found.\n",
      "node-0:1810131:1820050 [0] NCCL INFO NET/Socket : Using [0]eth0:10.13.60.215<0>\n",
      "node-0:1810131:1820050 [0] NCCL INFO Using network Socket\n",
      "node-0:1810131:1820051 [1] NCCL INFO Using network Socket\n",
      "node-0:1810131:1820051 [1] NCCL INFO Topology detection : could not read /sys/devices/LNXSYSTM:00/LNXSYBUS:00/ACPI0004:00/VMBUS:00/47505500-0003-0000-3130-303237343043/pci0003:00/0003:00:00.0/../max_link_speed, ignoring\n",
      "node-0:1810131:1820050 [0] NCCL INFO Topology detection : could not read /sys/devices/LNXSYSTM:00/LNXSYBUS:00/ACPI0004:00/VMBUS:00/47505500-0003-0000-3130-303237343043/pci0003:00/0003:00:00.0/../max_link_speed, ignoring\n",
      "node-0:1810131:1820051 [1] NCCL INFO Topology detection : could not read /sys/devices/LNXSYSTM:00/LNXSYBUS:00/ACPI0004:00/VMBUS:00/47505500-0003-0000-3130-303237343043/pci0003:00/0003:00:00.0/../max_link_width, ignoring\n",
      "node-0:1810131:1820050 [0] NCCL INFO Topology detection : could not read /sys/devices/LNXSYSTM:00/LNXSYBUS:00/ACPI0004:00/VMBUS:00/47505500-0003-0000-3130-303237343043/pci0003:00/0003:00:00.0/../max_link_width, ignoring\n",
      "node-0:1810131:1820051 [1] NCCL INFO rocm_smi_lib: version 5.0.0.0\n",
      "node-0:1810131:1820050 [0] NCCL INFO rocm_smi_lib: version 5.0.0.0\n",
      "node-0:1810131:1820051 [1] NCCL INFO Topology detection : could not read /sys/devices/LNXSYSTM:00/LNXSYBUS:00/ACPI0004:00/VMBUS:00/47505500-0004-0000-3130-303237343043/pci0004:00/0004:00:00.0/../max_link_speed, ignoring\n",
      "node-0:1810131:1820050 [0] NCCL INFO Topology detection : could not read /sys/devices/LNXSYSTM:00/LNXSYBUS:00/ACPI0004:00/VMBUS:00/47505500-0004-0000-3130-303237343043/pci0004:00/0004:00:00.0/../max_link_speed, ignoring\n",
      "node-0:1810131:1820051 [1] NCCL INFO Topology detection : could not read /sys/devices/LNXSYSTM:00/LNXSYBUS:00/ACPI0004:00/VMBUS:00/47505500-0004-0000-3130-303237343043/pci0004:00/0004:00:00.0/../max_link_width, ignoring\n",
      "node-0:1810131:1820050 [0] NCCL INFO Topology detection : could not read /sys/devices/LNXSYSTM:00/LNXSYBUS:00/ACPI0004:00/VMBUS:00/47505500-0004-0000-3130-303237343043/pci0004:00/0004:00:00.0/../max_link_width, ignoring\n",
      "node-0:1810131:1820051 [1] NCCL INFO === System : maxBw 144.0 totalBw 144.0 ===\n",
      "node-0:1810131:1820051 [1] NCCL INFO CPU/1 (1/2/4)\n",
      "node-0:1810131:1820051 [1] NCCL INFO + PCI[5000.0] - NIC/0\n",
      "node-0:1810131:1820051 [1] NCCL INFO + PCI[24.0] - GPU/300000 (0)\n",
      "node-0:1810131:1820051 [1] NCCL INFO               + XGMI[144.0] - GPU/400000\n",
      "node-0:1810131:1820051 [1] NCCL INFO + PCI[24.0] - GPU/400000 (1)\n",
      "node-0:1810131:1820051 [1] NCCL INFO               + XGMI[144.0] - GPU/300000\n",
      "node-0:1810131:1820051 [1] NCCL INFO ==========================================\n",
      "node-0:1810131:1820051 [1] NCCL INFO GPU/300000 :GPU/300000 (0/5000.000000/LOC) GPU/400000 (1/144.000000/XGMI) CPU/1 (1/24.000000/PHB) \n",
      "node-0:1810131:1820051 [1] NCCL INFO GPU/400000 :GPU/300000 (1/144.000000/XGMI) GPU/400000 (0/5000.000000/LOC) CPU/1 (1/24.000000/PHB) \n",
      "node-0:1810131:1820051 [1] NCCL INFO Setting affinity for GPU 3 to ffff,ff000000\n",
      "node-0:1810131:1820050 [0] NCCL INFO === System : maxBw 144.0 totalBw 144.0 ===\n",
      "node-0:1810131:1820050 [0] NCCL INFO CPU/1 (1/2/4)\n",
      "node-0:1810131:1820050 [0] NCCL INFO + PCI[5000.0] - NIC/0\n",
      "node-0:1810131:1820050 [0] NCCL INFO + PCI[24.0] - GPU/300000 (0)\n",
      "node-0:1810131:1820050 [0] NCCL INFO               + XGMI[144.0] - GPU/400000\n",
      "node-0:1810131:1820050 [0] NCCL INFO + PCI[24.0] - GPU/400000 (1)\n",
      "node-0:1810131:1820050 [0] NCCL INFO               + XGMI[144.0] - GPU/300000\n",
      "node-0:1810131:1820050 [0] NCCL INFO ==========================================\n",
      "node-0:1810131:1820050 [0] NCCL INFO GPU/300000 :GPU/300000 (0/5000.000000/LOC) GPU/400000 (1/144.000000/XGMI) CPU/1 (1/24.000000/PHB) \n",
      "node-0:1810131:1820050 [0] NCCL INFO GPU/400000 :GPU/300000 (1/144.000000/XGMI) GPU/400000 (0/5000.000000/LOC) CPU/1 (1/24.000000/PHB) \n",
      "node-0:1810131:1820050 [0] NCCL INFO Setting affinity for GPU 2 to ffff,ff000000\n",
      "node-0:1810131:1820051 [1] NCCL INFO Pattern 4, crossNic 0, nChannels 6, bw 24.000000/24.000000, type XGMI/PIX, sameChannels 1\n",
      "node-0:1810131:1820051 [1] NCCL INFO  0 : GPU/0 GPU/1\n",
      "node-0:1810131:1820051 [1] NCCL INFO  1 : GPU/0 GPU/1\n",
      "node-0:1810131:1820051 [1] NCCL INFO  2 : GPU/0 GPU/1\n",
      "node-0:1810131:1820051 [1] NCCL INFO  3 : GPU/0 GPU/1\n",
      "node-0:1810131:1820051 [1] NCCL INFO  4 : GPU/0 GPU/1\n",
      "node-0:1810131:1820051 [1] NCCL INFO  5 : GPU/0 GPU/1\n",
      "node-0:1810131:1820051 [1] NCCL INFO Pattern 1, crossNic 0, nChannels 6, bw 48.000000/48.000000, type XGMI/PIX, sameChannels 0\n",
      "node-0:1810131:1820051 [1] NCCL INFO  0 : GPU/0 GPU/1\n",
      "node-0:1810131:1820051 [1] NCCL INFO  1 : GPU/0 GPU/1\n",
      "node-0:1810131:1820051 [1] NCCL INFO  2 : GPU/0 GPU/1\n",
      "node-0:1810131:1820051 [1] NCCL INFO  3 : GPU/1 GPU/0\n",
      "node-0:1810131:1820051 [1] NCCL INFO  4 : GPU/1 GPU/0\n",
      "node-0:1810131:1820051 [1] NCCL INFO  5 : GPU/1 GPU/0\n",
      "node-0:1810131:1820051 [1] NCCL INFO Pattern 3, crossNic 0, nChannels 6, bw 48.000000/48.000000, type XGMI/PIX, sameChannels 0\n",
      "node-0:1810131:1820051 [1] NCCL INFO  0 : GPU/0 GPU/1\n",
      "node-0:1810131:1820051 [1] NCCL INFO  1 : GPU/0 GPU/1\n",
      "node-0:1810131:1820051 [1] NCCL INFO  2 : GPU/0 GPU/1\n",
      "node-0:1810131:1820051 [1] NCCL INFO  3 : GPU/1 GPU/0\n",
      "node-0:1810131:1820051 [1] NCCL INFO  4 : GPU/1 GPU/0\n",
      "node-0:1810131:1820051 [1] NCCL INFO  5 : GPU/1 GPU/0\n",
      "node-0:1810131:1820050 [0] NCCL INFO Pattern 4, crossNic 0, nChannels 6, bw 24.000000/24.000000, type XGMI/PIX, sameChannels 1\n",
      "node-0:1810131:1820050 [0] NCCL INFO  0 : GPU/0 GPU/1\n",
      "node-0:1810131:1820050 [0] NCCL INFO  1 : GPU/0 GPU/1\n",
      "node-0:1810131:1820050 [0] NCCL INFO  2 : GPU/0 GPU/1\n",
      "node-0:1810131:1820050 [0] NCCL INFO  3 : GPU/0 GPU/1\n",
      "node-0:1810131:1820050 [0] NCCL INFO  4 : GPU/0 GPU/1\n",
      "node-0:1810131:1820050 [0] NCCL INFO  5 : GPU/0 GPU/1\n",
      "node-0:1810131:1820050 [0] NCCL INFO Pattern 1, crossNic 0, nChannels 6, bw 48.000000/48.000000, type XGMI/PIX, sameChannels 0\n",
      "node-0:1810131:1820050 [0] NCCL INFO  0 : GPU/0 GPU/1\n",
      "node-0:1810131:1820050 [0] NCCL INFO  1 : GPU/0 GPU/1\n",
      "node-0:1810131:1820050 [0] NCCL INFO  2 : GPU/0 GPU/1\n",
      "node-0:1810131:1820050 [0] NCCL INFO  3 : GPU/1 GPU/0\n",
      "node-0:1810131:1820050 [0] NCCL INFO  4 : GPU/1 GPU/0\n",
      "node-0:1810131:1820050 [0] NCCL INFO  5 : GPU/1 GPU/0\n",
      "node-0:1810131:1820050 [0] NCCL INFO Pattern 3, crossNic 0, nChannels 6, bw 48.000000/48.000000, type XGMI/PIX, sameChannels 0\n",
      "node-0:1810131:1820050 [0] NCCL INFO  0 : GPU/0 GPU/1\n",
      "node-0:1810131:1820050 [0] NCCL INFO  1 : GPU/0 GPU/1\n",
      "node-0:1810131:1820050 [0] NCCL INFO  2 : GPU/0 GPU/1\n",
      "node-0:1810131:1820050 [0] NCCL INFO  3 : GPU/1 GPU/0\n",
      "node-0:1810131:1820050 [0] NCCL INFO  4 : GPU/1 GPU/0\n",
      "node-0:1810131:1820050 [0] NCCL INFO  5 : GPU/1 GPU/0\n",
      "node-0:1810131:1820051 [1] NCCL INFO Tree 0 : 0 -> 1 -> -1/-1/-1\n",
      "node-0:1810131:1820051 [1] NCCL INFO Tree 6 : 0 -> 1 -> -1/-1/-1\n",
      "node-0:1810131:1820051 [1] NCCL INFO Tree 1 : 0 -> 1 -> -1/-1/-1\n",
      "node-0:1810131:1820051 [1] NCCL INFO Tree 7 : 0 -> 1 -> -1/-1/-1\n",
      "node-0:1810131:1820050 [0] NCCL INFO Tree 0 : -1 -> 0 -> 1/-1/-1\n",
      "node-0:1810131:1820051 [1] NCCL INFO Tree 2 : 0 -> 1 -> -1/-1/-1\n",
      "node-0:1810131:1820050 [0] NCCL INFO Tree 6 : -1 -> 0 -> 1/-1/-1\n",
      "node-0:1810131:1820051 [1] NCCL INFO Tree 8 : 0 -> 1 -> -1/-1/-1\n",
      "node-0:1810131:1820050 [0] NCCL INFO Tree 1 : -1 -> 0 -> 1/-1/-1\n",
      "node-0:1810131:1820051 [1] NCCL INFO Tree 3 : -1 -> 1 -> 0/-1/-1\n",
      "node-0:1810131:1820050 [0] NCCL INFO Tree 7 : -1 -> 0 -> 1/-1/-1\n",
      "node-0:1810131:1820051 [1] NCCL INFO Tree 9 : -1 -> 1 -> 0/-1/-1\n",
      "node-0:1810131:1820050 [0] NCCL INFO Tree 2 : -1 -> 0 -> 1/-1/-1\n",
      "node-0:1810131:1820051 [1] NCCL INFO Tree 4 : -1 -> 1 -> 0/-1/-1\n",
      "node-0:1810131:1820050 [0] NCCL INFO Tree 8 : -1 -> 0 -> 1/-1/-1\n",
      "node-0:1810131:1820051 [1] NCCL INFO Tree 10 : -1 -> 1 -> 0/-1/-1\n",
      "node-0:1810131:1820050 [0] NCCL INFO Tree 3 : 1 -> 0 -> -1/-1/-1\n",
      "node-0:1810131:1820051 [1] NCCL INFO Tree 5 : -1 -> 1 -> 0/-1/-1\n",
      "node-0:1810131:1820050 [0] NCCL INFO Tree 9 : 1 -> 0 -> -1/-1/-1\n",
      "node-0:1810131:1820051 [1] NCCL INFO Tree 11 : -1 -> 1 -> 0/-1/-1\n",
      "node-0:1810131:1820050 [0] NCCL INFO Tree 4 : 1 -> 0 -> -1/-1/-1\n",
      "node-0:1810131:1820050 [0] NCCL INFO Tree 10 : 1 -> 0 -> -1/-1/-1\n",
      "node-0:1810131:1820050 [0] NCCL INFO Tree 5 : 1 -> 0 -> -1/-1/-1\n",
      "node-0:1810131:1820050 [0] NCCL INFO Tree 11 : 1 -> 0 -> -1/-1/-1\n",
      "node-0:1810131:1820050 [0] NCCL INFO Channel 00/24 :    0   1\n",
      "node-0:1810131:1820050 [0] NCCL INFO Channel 01/24 :    0   1\n",
      "node-0:1810131:1820050 [0] NCCL INFO Channel 02/24 :    0   1\n",
      "node-0:1810131:1820050 [0] NCCL INFO Channel 03/24 :    0   1\n",
      "node-0:1810131:1820050 [0] NCCL INFO Channel 04/24 :    0   1\n",
      "node-0:1810131:1820051 [1] NCCL INFO Ring 0 : 0 -> 1 -> 0 comm 0x1fd20020 nRanks 02 busId 400000\n",
      "node-0:1810131:1820050 [0] NCCL INFO Channel 05/24 :    0   1\n",
      "node-0:1810131:1820050 [0] NCCL INFO Channel 06/24 :    0   1\n",
      "node-0:1810131:1820051 [1] NCCL INFO Ring 1 : 0 -> 1 -> 0 comm 0x1fd20020 nRanks 02 busId 400000\n",
      "node-0:1810131:1820050 [0] NCCL INFO Channel 07/24 :    0   1\n",
      "node-0:1810131:1820051 [1] NCCL INFO Ring 2 : 0 -> 1 -> 0 comm 0x1fd20020 nRanks 02 busId 400000\n",
      "node-0:1810131:1820051 [1] NCCL INFO Ring 3 : 0 -> 1 -> 0 comm 0x1fd20020 nRanks 02 busId 400000\n",
      "node-0:1810131:1820051 [1] NCCL INFO Ring 4 : 0 -> 1 -> 0 comm 0x1fd20020 nRanks 02 busId 400000\n",
      "node-0:1810131:1820051 [1] NCCL INFO Ring 5 : 0 -> 1 -> 0 comm 0x1fd20020 nRanks 02 busId 400000\n",
      "node-0:1810131:1820051 [1] NCCL INFO Ring 6 : 0 -> 1 -> 0 comm 0x1fd20020 nRanks 02 busId 400000\n",
      "node-0:1810131:1820051 [1] NCCL INFO Ring 7 : 0 -> 1 -> 0 comm 0x1fd20020 nRanks 02 busId 400000\n",
      "node-0:1810131:1820051 [1] NCCL INFO Ring 8 : 0 -> 1 -> 0 comm 0x1fd20020 nRanks 02 busId 400000\n",
      "node-0:1810131:1820051 [1] NCCL INFO Ring 9 : 0 -> 1 -> 0 comm 0x1fd20020 nRanks 02 busId 400000\n",
      "node-0:1810131:1820050 [0] NCCL INFO Channel 08/24 :    0   1\n",
      "node-0:1810131:1820051 [1] NCCL INFO Ring 10 : 0 -> 1 -> 0 comm 0x1fd20020 nRanks 02 busId 400000\n",
      "node-0:1810131:1820050 [0] NCCL INFO Channel 09/24 :    0   1\n",
      "node-0:1810131:1820051 [1] NCCL INFO Ring 11 : 0 -> 1 -> 0 comm 0x1fd20020 nRanks 02 busId 400000\n",
      "node-0:1810131:1820050 [0] NCCL INFO Channel 10/24 :    0   1\n",
      "node-0:1810131:1820050 [0] NCCL INFO Channel 11/24 :    0   1\n",
      "node-0:1810131:1820051 [1] NCCL INFO Ring 12 : 0 -> 1 -> 0 comm 0x1fd20020 nRanks 02 busId 400000\n",
      "node-0:1810131:1820050 [0] NCCL INFO Channel 12/24 :    0   1\n",
      "node-0:1810131:1820051 [1] NCCL INFO Ring 13 : 0 -> 1 -> 0 comm 0x1fd20020 nRanks 02 busId 400000\n",
      "node-0:1810131:1820050 [0] NCCL INFO Channel 13/24 :    0   1\n",
      "node-0:1810131:1820051 [1] NCCL INFO Ring 14 : 0 -> 1 -> 0 comm 0x1fd20020 nRanks 02 busId 400000\n",
      "node-0:1810131:1820050 [0] NCCL INFO Channel 14/24 :    0   1\n",
      "node-0:1810131:1820050 [0] NCCL INFO Channel 15/24 :    0   1\n",
      "node-0:1810131:1820051 [1] NCCL INFO Ring 15 : 0 -> 1 -> 0 comm 0x1fd20020 nRanks 02 busId 400000\n",
      "node-0:1810131:1820050 [0] NCCL INFO Channel 16/24 :    0   1\n",
      "node-0:1810131:1820051 [1] NCCL INFO Ring 16 : 0 -> 1 -> 0 comm 0x1fd20020 nRanks 02 busId 400000\n",
      "node-0:1810131:1820050 [0] NCCL INFO Channel 17/24 :    0   1\n",
      "node-0:1810131:1820051 [1] NCCL INFO Ring 17 : 0 -> 1 -> 0 comm 0x1fd20020 nRanks 02 busId 400000\n",
      "node-0:1810131:1820050 [0] NCCL INFO Channel 18/24 :    0   1\n",
      "node-0:1810131:1820051 [1] NCCL INFO Ring 18 : 0 -> 1 -> 0 comm 0x1fd20020 nRanks 02 busId 400000\n",
      "node-0:1810131:1820050 [0] NCCL INFO Channel 19/24 :    0   1\n",
      "node-0:1810131:1820050 [0] NCCL INFO Channel 20/24 :    0   1\n",
      "node-0:1810131:1820051 [1] NCCL INFO Ring 19 : 0 -> 1 -> 0 comm 0x1fd20020 nRanks 02 busId 400000\n",
      "node-0:1810131:1820050 [0] NCCL INFO Channel 21/24 :    0   1\n",
      "node-0:1810131:1820051 [1] NCCL INFO Ring 20 : 0 -> 1 -> 0 comm 0x1fd20020 nRanks 02 busId 400000\n",
      "node-0:1810131:1820050 [0] NCCL INFO Channel 22/24 :    0   1\n",
      "node-0:1810131:1820051 [1] NCCL INFO Ring 21 : 0 -> 1 -> 0 comm 0x1fd20020 nRanks 02 busId 400000\n",
      "node-0:1810131:1820050 [0] NCCL INFO Channel 23/24 :    0   1\n",
      "node-0:1810131:1820051 [1] NCCL INFO Ring 22 : 0 -> 1 -> 0 comm 0x1fd20020 nRanks 02 busId 400000\n",
      "node-0:1810131:1820051 [1] NCCL INFO Ring 23 : 0 -> 1 -> 0 comm 0x1fd20020 nRanks 02 busId 400000\n",
      "node-0:1810131:1820050 [0] NCCL INFO Ring 0 : 1 -> 0 -> 1 comm 0x1fd1cc80 nRanks 02 busId 300000\n",
      "node-0:1810131:1820051 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] 0/-1/-1->1->-1 [4] 0/-1/-1->1->-1 [5] 0/-1/-1->1->-1 [6] -1/-1/-1->1->0 [7] -1/-1/-1->1->0 [8] -1/-1/-1->1->0 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] -1/-1/-1->1->0 [13] -1/-1/-1->1->0 [14] -1/-1/-1->1->0 [15] 0/-1/-1->1->-1 [16] 0/-1/-1->1->-1 [17] 0/-1/-1->1->-1 [18] -1/-1/-1->1->0 [19] -1/-1/-1->1->0 [20] -1/-1/-1->1->0 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1 comm 0x1fd20020 nRanks 02 busId 400000\n",
      "node-0:1810131:1820050 [0] NCCL INFO Ring 1 : 1 -> 0 -> 1 comm 0x1fd1cc80 nRanks 02 busId 300000\n",
      "node-0:1810131:1820050 [0] NCCL INFO Ring 2 : 1 -> 0 -> 1 comm 0x1fd1cc80 nRanks 02 busId 300000\n",
      "node-0:1810131:1820051 [1] NCCL INFO P2P Chunksize set to 524288\n",
      "node-0:1810131:1820050 [0] NCCL INFO Ring 3 : 1 -> 0 -> 1 comm 0x1fd1cc80 nRanks 02 busId 300000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node-0:1810131:1820050 [0] NCCL INFO Ring 4 : 1 -> 0 -> 1 comm 0x1fd1cc80 nRanks 02 busId 300000\n",
      "node-0:1810131:1820050 [0] NCCL INFO Ring 5 : 1 -> 0 -> 1 comm 0x1fd1cc80 nRanks 02 busId 300000\n",
      "node-0:1810131:1820050 [0] NCCL INFO Ring 6 : 1 -> 0 -> 1 comm 0x1fd1cc80 nRanks 02 busId 300000\n",
      "node-0:1810131:1820050 [0] NCCL INFO Ring 7 : 1 -> 0 -> 1 comm 0x1fd1cc80 nRanks 02 busId 300000\n",
      "node-0:1810131:1820050 [0] NCCL INFO Ring 8 : 1 -> 0 -> 1 comm 0x1fd1cc80 nRanks 02 busId 300000\n",
      "node-0:1810131:1820050 [0] NCCL INFO Ring 9 : 1 -> 0 -> 1 comm 0x1fd1cc80 nRanks 02 busId 300000\n",
      "node-0:1810131:1820050 [0] NCCL INFO Ring 10 : 1 -> 0 -> 1 comm 0x1fd1cc80 nRanks 02 busId 300000\n",
      "node-0:1810131:1820050 [0] NCCL INFO Ring 11 : 1 -> 0 -> 1 comm 0x1fd1cc80 nRanks 02 busId 300000\n",
      "node-0:1810131:1820050 [0] NCCL INFO Ring 12 : 1 -> 0 -> 1 comm 0x1fd1cc80 nRanks 02 busId 300000\n",
      "node-0:1810131:1820050 [0] NCCL INFO Ring 13 : 1 -> 0 -> 1 comm 0x1fd1cc80 nRanks 02 busId 300000\n",
      "node-0:1810131:1820050 [0] NCCL INFO Ring 14 : 1 -> 0 -> 1 comm 0x1fd1cc80 nRanks 02 busId 300000\n",
      "node-0:1810131:1820050 [0] NCCL INFO Ring 15 : 1 -> 0 -> 1 comm 0x1fd1cc80 nRanks 02 busId 300000\n",
      "node-0:1810131:1820050 [0] NCCL INFO Ring 16 : 1 -> 0 -> 1 comm 0x1fd1cc80 nRanks 02 busId 300000\n",
      "node-0:1810131:1820050 [0] NCCL INFO Ring 17 : 1 -> 0 -> 1 comm 0x1fd1cc80 nRanks 02 busId 300000\n",
      "node-0:1810131:1820050 [0] NCCL INFO Ring 18 : 1 -> 0 -> 1 comm 0x1fd1cc80 nRanks 02 busId 300000\n",
      "node-0:1810131:1820050 [0] NCCL INFO Ring 19 : 1 -> 0 -> 1 comm 0x1fd1cc80 nRanks 02 busId 300000\n",
      "node-0:1810131:1820050 [0] NCCL INFO Ring 20 : 1 -> 0 -> 1 comm 0x1fd1cc80 nRanks 02 busId 300000\n",
      "node-0:1810131:1820050 [0] NCCL INFO Ring 21 : 1 -> 0 -> 1 comm 0x1fd1cc80 nRanks 02 busId 300000\n",
      "node-0:1810131:1820050 [0] NCCL INFO Ring 22 : 1 -> 0 -> 1 comm 0x1fd1cc80 nRanks 02 busId 300000\n",
      "node-0:1810131:1820050 [0] NCCL INFO Ring 23 : 1 -> 0 -> 1 comm 0x1fd1cc80 nRanks 02 busId 300000\n",
      "node-0:1810131:1820050 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] -1/-1/-1->0->1 [4] -1/-1/-1->0->1 [5] -1/-1/-1->0->1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1 [8] 1/-1/-1->0->-1 [9] -1/-1/-1->0->1 [10] -1/-1/-1->0->1 [11] -1/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] -1/-1/-1->0->1 [16] -1/-1/-1->0->1 [17] -1/-1/-1->0->1 [18] 1/-1/-1->0->-1 [19] 1/-1/-1->0->-1 [20] 1/-1/-1->0->-1 [21] -1/-1/-1->0->1 [22] -1/-1/-1->0->1 [23] -1/-1/-1->0->1 comm 0x1fd1cc80 nRanks 02 busId 300000\n",
      "node-0:1810131:1820050 [0] NCCL INFO P2P Chunksize set to 524288\n",
      "node-0:1810131:1820051 [1] NCCL INFO Channel 00/0 : 1[400000] -> 0[300000] via P2P/direct pointer comm 0x1fd20020 nRanks 02\n",
      "node-0:1810131:1820050 [0] NCCL INFO Channel 00/0 : 0[300000] -> 1[400000] via P2P/direct pointer comm 0x1fd1cc80 nRanks 02\n",
      "node-0:1810131:1820051 [1] NCCL INFO Channel 01/0 : 1[400000] -> 0[300000] via P2P/direct pointer comm 0x1fd20020 nRanks 02\n",
      "node-0:1810131:1820050 [0] NCCL INFO Channel 01/0 : 0[300000] -> 1[400000] via P2P/direct pointer comm 0x1fd1cc80 nRanks 02\n",
      "node-0:1810131:1820051 [1] NCCL INFO Channel 02/0 : 1[400000] -> 0[300000] via P2P/direct pointer comm 0x1fd20020 nRanks 02\n",
      "node-0:1810131:1820050 [0] NCCL INFO Channel 02/0 : 0[300000] -> 1[400000] via P2P/direct pointer comm 0x1fd1cc80 nRanks 02\n",
      "node-0:1810131:1820051 [1] NCCL INFO Channel 03/0 : 1[400000] -> 0[300000] via P2P/direct pointer comm 0x1fd20020 nRanks 02\n",
      "node-0:1810131:1820050 [0] NCCL INFO Channel 03/0 : 0[300000] -> 1[400000] via P2P/direct pointer comm 0x1fd1cc80 nRanks 02\n",
      "node-0:1810131:1820051 [1] NCCL INFO Channel 04/0 : 1[400000] -> 0[300000] via P2P/direct pointer comm 0x1fd20020 nRanks 02\n",
      "node-0:1810131:1820050 [0] NCCL INFO Channel 04/0 : 0[300000] -> 1[400000] via P2P/direct pointer comm 0x1fd1cc80 nRanks 02\n",
      "node-0:1810131:1820051 [1] NCCL INFO Channel 05/0 : 1[400000] -> 0[300000] via P2P/direct pointer comm 0x1fd20020 nRanks 02\n",
      "node-0:1810131:1820050 [0] NCCL INFO Channel 05/0 : 0[300000] -> 1[400000] via P2P/direct pointer comm 0x1fd1cc80 nRanks 02\n",
      "node-0:1810131:1820051 [1] NCCL INFO Channel 06/0 : 1[400000] -> 0[300000] via P2P/direct pointer comm 0x1fd20020 nRanks 02\n",
      "node-0:1810131:1820050 [0] NCCL INFO Channel 06/0 : 0[300000] -> 1[400000] via P2P/direct pointer comm 0x1fd1cc80 nRanks 02\n",
      "node-0:1810131:1820051 [1] NCCL INFO Channel 07/0 : 1[400000] -> 0[300000] via P2P/direct pointer comm 0x1fd20020 nRanks 02\n",
      "node-0:1810131:1820050 [0] NCCL INFO Channel 07/0 : 0[300000] -> 1[400000] via P2P/direct pointer comm 0x1fd1cc80 nRanks 02\n",
      "node-0:1810131:1820051 [1] NCCL INFO Channel 08/0 : 1[400000] -> 0[300000] via P2P/direct pointer comm 0x1fd20020 nRanks 02\n",
      "node-0:1810131:1820050 [0] NCCL INFO Channel 08/0 : 0[300000] -> 1[400000] via P2P/direct pointer comm 0x1fd1cc80 nRanks 02\n",
      "node-0:1810131:1820051 [1] NCCL INFO Channel 09/0 : 1[400000] -> 0[300000] via P2P/direct pointer comm 0x1fd20020 nRanks 02\n",
      "node-0:1810131:1820050 [0] NCCL INFO Channel 09/0 : 0[300000] -> 1[400000] via P2P/direct pointer comm 0x1fd1cc80 nRanks 02\n",
      "node-0:1810131:1820051 [1] NCCL INFO Channel 10/0 : 1[400000] -> 0[300000] via P2P/direct pointer comm 0x1fd20020 nRanks 02\n",
      "node-0:1810131:1820050 [0] NCCL INFO Channel 10/0 : 0[300000] -> 1[400000] via P2P/direct pointer comm 0x1fd1cc80 nRanks 02\n",
      "node-0:1810131:1820051 [1] NCCL INFO Channel 11/0 : 1[400000] -> 0[300000] via P2P/direct pointer comm 0x1fd20020 nRanks 02\n",
      "node-0:1810131:1820050 [0] NCCL INFO Channel 11/0 : 0[300000] -> 1[400000] via P2P/direct pointer comm 0x1fd1cc80 nRanks 02\n",
      "node-0:1810131:1820050 [0] NCCL INFO Channel 12/0 : 0[300000] -> 1[400000] via P2P/direct pointer comm 0x1fd1cc80 nRanks 02\n",
      "node-0:1810131:1820051 [1] NCCL INFO Channel 12/0 : 1[400000] -> 0[300000] via P2P/direct pointer comm 0x1fd20020 nRanks 02\n",
      "node-0:1810131:1820050 [0] NCCL INFO Channel 13/0 : 0[300000] -> 1[400000] via P2P/direct pointer comm 0x1fd1cc80 nRanks 02\n",
      "node-0:1810131:1820051 [1] NCCL INFO Channel 13/0 : 1[400000] -> 0[300000] via P2P/direct pointer comm 0x1fd20020 nRanks 02\n",
      "node-0:1810131:1820051 [1] NCCL INFO Channel 14/0 : 1[400000] -> 0[300000] via P2P/direct pointer comm 0x1fd20020 nRanks 02\n",
      "node-0:1810131:1820050 [0] NCCL INFO Channel 14/0 : 0[300000] -> 1[400000] via P2P/direct pointer comm 0x1fd1cc80 nRanks 02\n",
      "node-0:1810131:1820051 [1] NCCL INFO Channel 15/0 : 1[400000] -> 0[300000] via P2P/direct pointer comm 0x1fd20020 nRanks 02\n",
      "node-0:1810131:1820050 [0] NCCL INFO Channel 15/0 : 0[300000] -> 1[400000] via P2P/direct pointer comm 0x1fd1cc80 nRanks 02\n",
      "node-0:1810131:1820051 [1] NCCL INFO Channel 16/0 : 1[400000] -> 0[300000] via P2P/direct pointer comm 0x1fd20020 nRanks 02\n",
      "node-0:1810131:1820050 [0] NCCL INFO Channel 16/0 : 0[300000] -> 1[400000] via P2P/direct pointer comm 0x1fd1cc80 nRanks 02\n",
      "node-0:1810131:1820051 [1] NCCL INFO Channel 17/0 : 1[400000] -> 0[300000] via P2P/direct pointer comm 0x1fd20020 nRanks 02\n",
      "node-0:1810131:1820050 [0] NCCL INFO Channel 17/0 : 0[300000] -> 1[400000] via P2P/direct pointer comm 0x1fd1cc80 nRanks 02\n",
      "node-0:1810131:1820050 [0] NCCL INFO Channel 18/0 : 0[300000] -> 1[400000] via P2P/direct pointer comm 0x1fd1cc80 nRanks 02\n",
      "node-0:1810131:1820051 [1] NCCL INFO Channel 18/0 : 1[400000] -> 0[300000] via P2P/direct pointer comm 0x1fd20020 nRanks 02\n",
      "node-0:1810131:1820050 [0] NCCL INFO Channel 19/0 : 0[300000] -> 1[400000] via P2P/direct pointer comm 0x1fd1cc80 nRanks 02\n",
      "node-0:1810131:1820051 [1] NCCL INFO Channel 19/0 : 1[400000] -> 0[300000] via P2P/direct pointer comm 0x1fd20020 nRanks 02\n",
      "node-0:1810131:1820050 [0] NCCL INFO Channel 20/0 : 0[300000] -> 1[400000] via P2P/direct pointer comm 0x1fd1cc80 nRanks 02\n",
      "node-0:1810131:1820051 [1] NCCL INFO Channel 20/0 : 1[400000] -> 0[300000] via P2P/direct pointer comm 0x1fd20020 nRanks 02\n",
      "node-0:1810131:1820051 [1] NCCL INFO Channel 21/0 : 1[400000] -> 0[300000] via P2P/direct pointer comm 0x1fd20020 nRanks 02\n",
      "node-0:1810131:1820050 [0] NCCL INFO Channel 21/0 : 0[300000] -> 1[400000] via P2P/direct pointer comm 0x1fd1cc80 nRanks 02\n",
      "node-0:1810131:1820051 [1] NCCL INFO Channel 22/0 : 1[400000] -> 0[300000] via P2P/direct pointer comm 0x1fd20020 nRanks 02\n",
      "node-0:1810131:1820050 [0] NCCL INFO Chann> /home/aiscuser/scratch/Projects/xcai/xcai/models/MMM0XX.py(932)forward()\n",
      "    930     ):\n",
      "    931         import pdb; pdb.set_trace()\n",
      "--> 932         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
      "    933         data_o, data_logits, data_repr = self.get_genrep(data_input_ids, data_attention_mask)\n",
      "    934 \n",
      "\n",
      "ipdb> kwargs.keys()\n",
      "dict_keys(['pcat2lbl_data2ptr', 'cat2lbl_data2ptr', 'pcat2data_data2ptr', 'cat2data_data2ptr', 'cat2data_idx', 'cat2data_input_ids', 'cat2data_attention_mask', 'pcat2lbl_idx', 'cat2lbl_idx', 'cat2lbl_input_ids', 'cat2lbl_attention_mask', 'pcat2data_idx', 'pcat2lbl_lbl2data2ptr', 'cat2lbl_lbl2data2ptr'])\n",
      "ipdb> n\n",
      "> /home/aiscuser/scratch/Projects/xcai/xcai/models/MMM0XX.py(933)forward()\n",
      "    931         import pdb; pdb.set_trace()\n",
      "    932         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
      "--> 933         data_o, data_logits, data_repr = self.get_genrep(data_input_ids, data_attention_mask)\n",
      "    934 \n",
      "    935         meta_outputs = {}\n",
      "\n",
      "ipdb> n\n",
      "> /home/aiscuser/scratch/Projects/xcai/xcai/models/MMM0XX.py(935)forward()\n",
      "    933         data_o, data_logits, data_repr = self.get_genrep(data_input_ids, data_attention_mask)\n",
      "    934 \n",
      "--> 935         meta_outputs = {}\n",
      "    936         loss = lm_loss = dr_loss = lbl2data_repr = None\n",
      "    937         if lbl2data_input_ids is not None:\n",
      "\n",
      "ipdb> n\n",
      "> /home/aiscuser/scratch/Projects/xcai/xcai/models/MMM0XX.py(936)forward()\n",
      "    934 \n",
      "    935         meta_outputs = {}\n",
      "--> 936         loss = lm_loss = dr_loss = lbl2data_repr = None\n",
      "    937         if lbl2data_input_ids is not None:\n",
      "    938             lbl2data_o, lbl2data_logits, lbl2data_repr = self.get_genrep(lbl2data_input_ids, lbl2data_attention_mask)\n",
      "\n",
      "ipdb> n\n",
      "> /home/aiscuser/scratch/Projects/xcai/xcai/models/MMM0XX.py(937)forward()\n",
      "    935         meta_outputs = {}\n",
      "    936         loss = lm_loss = dr_loss = lbl2data_repr = None\n",
      "--> 937         if lbl2data_input_ids is not None:\n",
      "    938             lbl2data_o, lbl2data_logits, lbl2data_repr = self.get_genrep(lbl2data_input_ids, lbl2data_attention_mask)\n",
      "    939 \n",
      "\n",
      "ipdb> n\n",
      "> /home/aiscuser/scratch/Projects/xcai/xcai/models/MMM0XX.py(938)forward()\n",
      "    936         loss = lm_loss = dr_loss = lbl2data_repr = None\n",
      "    937         if lbl2data_input_ids is not None:\n",
      "--> 938             lbl2data_o, lbl2data_logits, lbl2data_repr = self.get_genrep(lbl2data_input_ids, lbl2data_attention_mask)\n",
      "    939 \n",
      "    940             lm_loss = self.gen_lfn(data_logits, lbl2data_input_ids, lbl2data_data2ptr, **kwargs)\n",
      "\n",
      "ipdb> n\n",
      "> /home/aiscuser/scratch/Projects/xcai/xcai/models/MMM0XX.py(940)forward()\n",
      "    938             lbl2data_o, lbl2data_logits, lbl2data_repr = self.get_genrep(lbl2data_input_ids, lbl2data_attention_mask)\n",
      "    939 \n",
      "--> 940             lm_loss = self.gen_lfn(data_logits, lbl2data_input_ids, lbl2data_data2ptr, **kwargs)\n",
      "    941             dr_loss = self.rep_lfn(data_repr, lbl2data_repr, lbl2data_data2ptr, lbl2data_idx, \n",
      "    942                                    plbl2data_data2ptr, plbl2data_idx, **kwargs)\n",
      "\n",
      "ipdb> n\n",
      "> /home/aiscuser/scratch/Projects/xcai/xcai/models/MMM0XX.py(941)forward()\n",
      "    939 \n",
      "    940             lm_loss = self.gen_lfn(data_logits, lbl2data_input_ids, lbl2data_data2ptr, **kwargs)\n",
      "--> 941             dr_loss = self.rep_lfn(data_repr, lbl2data_repr, lbl2data_data2ptr, lbl2data_idx, \n",
      "    942                                    plbl2data_data2ptr, plbl2data_idx, **kwargs)\n",
      "    943             loss = dr_loss + self.lw*lm_loss\n",
      "\n",
      "ipdb> n\n",
      "> /home/aiscuser/scratch/Projects/xcai/xcai/models/MMM0XX.py(942)forward()\n",
      "    940             lm_loss = self.gen_lfn(data_logits, lbl2data_input_ids, lbl2data_data2ptr, **kwargs)\n",
      "    941             dr_loss = self.rep_lfn(data_repr, lbl2data_repr, lbl2data_data2ptr, lbl2data_idx, \n",
      "--> 942                                    plbl2data_data2ptr, plbl2data_idx, **kwargs)\n",
      "    943             loss = dr_loss + self.lw*lm_loss\n",
      "    944 \n",
      "\n",
      "ipdb> n\n",
      "> /home/aiscuser/scratch/Projects/xcai/xcai/models/MMM0XX.py(941)forward()\n",
      "    939 \n",
      "    940             lm_loss = self.gen_lfn(data_logits, lbl2data_input_ids, lbl2data_data2ptr, **kwargs)\n",
      "--> 941             dr_loss = self.rep_lfn(data_repr, lbl2data_repr, lbl2data_data2ptr, lbl2data_idx, \n",
      "    942                                    plbl2data_data2ptr, plbl2data_idx, **kwargs)\n",
      "    943             loss = dr_loss + self.lw*lm_loss\n",
      "\n",
      "ipdb> n\n",
      "> /home/aiscuser/scratch/Projects/xcai/xcai/models/MMM0XX.py(942)forward()\n",
      "    940             lm_loss = self.gen_lfn(data_logits, lbl2data_input_ids, lbl2data_data2ptr, **kwargs)\n",
      "    941             dr_loss = self.rep_lfn(data_repr, lbl2data_repr, lbl2data_data2ptr, lbl2data_idx, \n",
      "--> 942                                    plbl2data_data2ptr, plbl2data_idx, **kwargs)\n",
      "    943             loss = dr_loss + self.lw*lm_loss\n",
      "    944 \n",
      "\n",
      "ipdb> n\n",
      "> /home/aiscuser/scratch/Projects/xcai/xcai/models/MMM0XX.py(941)forward()\n",
      "    939 \n",
      "    940             lm_loss = self.gen_lfn(data_logits, lbl2data_input_ids, lbl2data_data2ptr, **kwargs)\n",
      "--> 941             dr_loss = self.rep_lfn(data_repr, lbl2data_repr, lbl2data_data2ptr, lbl2data_idx, \n",
      "    942                                    plbl2data_data2ptr, plbl2data_idx, **kwargs)\n",
      "    943             loss = dr_loss + self.lw*lm_loss\n",
      "\n",
      "ipdb> n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiscuser/scratch/Projects/xcai/xcai/losses.py:21: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:54.)\n",
      "  return torch.sparse_csr_tensor(data_ptr, data_idx, scores, device=data_ptr.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/aiscuser/scratch/Projects/xcai/xcai/models/MMM0XX.py(943)forward()\n",
      "    941             dr_loss = self.rep_lfn(data_repr, lbl2data_repr, lbl2data_data2ptr, lbl2data_idx, \n",
      "    942                                    plbl2data_data2ptr, plbl2data_idx, **kwargs)\n",
      "--> 943             loss = dr_loss + self.lw*lm_loss\n",
      "    944 \n",
      "    945             meta_inputs = self._get_meta_inputs(**kwargs)\n",
      "\n",
      "ipdb> n\n",
      "> /home/aiscuser/scratch/Projects/xcai/xcai/models/MMM0XX.py(945)forward()\n",
      "    943             loss = dr_loss + self.lw*lm_loss\n",
      "    944 \n",
      "--> 945             meta_inputs = self._get_meta_inputs(**kwargs)\n",
      "    946             if isinstance(self.m_lw, float):\n",
      "    947                 meta_lw = self.m_lw/len(meta_inputs) if len(meta_inputs) else None\n",
      "\n",
      "ipdb> n\n",
      "> /home/aiscuser/scratch/Projects/xcai/xcai/models/MMM0XX.py(946)forward()\n",
      "    944 \n",
      "    945             meta_inputs = self._get_meta_inputs(**kwargs)\n",
      "--> 946             if isinstance(self.m_lw, float):\n",
      "    947                 meta_lw = self.m_lw/len(meta_inputs) if len(meta_inputs) else None\n",
      "    948                 meta_lw = [meta_lw]*len(meta_inputs)\n",
      "\n",
      "ipdb> meta_inputs.keys()\n",
      "dict_keys(['cat2lbl', 'cat2data'])\n",
      "ipdb> n\n",
      "> /home/aiscuser/scratch/Projects/xcai/xcai/models/MMM0XX.py(947)forward()\n",
      "    945             meta_inputs = self._get_meta_inputs(**kwargs)\n",
      "    946             if isinstance(self.m_lw, float):\n",
      "--> 947                 meta_lw = self.m_lw/len(meta_inputs) if len(meta_inputs) else None\n",
      "    948                 meta_lw = [meta_lw]*len(meta_inputs)\n",
      "    949             else:\n",
      "\n",
      "ipdb> n\n",
      "> /home/aiscuser/scratch/Projects/xcai/xcai/models/MMM0XX.py(948)forward()\n",
      "    946             if isinstance(self.m_lw, float):\n",
      "    947                 meta_lw = self.m_lw/len(meta_inputs) if len(meta_inputs) else None\n",
      "--> 948                 meta_lw = [meta_lw]*len(meta_inputs)\n",
      "    949             else:\n",
      "    950                 if len(self.m_lw) != len(meta_inputs): raise ValueError(f'length of `m_lw` should be equal to number of metadata.')\n",
      "\n",
      "ipdb> meta_lw\n",
      "0.15\n",
      "ipdb> n\n",
      "> /home/aiscuser/scratch/Projects/xcai/xcai/models/MMM0XX.py(953)forward()\n",
      "    951                 meta_lw = self.m_lw\n",
      "    952 \n",
      "--> 953             for m,m_lw in zip(meta_inputs.values(), meta_lw):\n",
      "    954                 if 'lbl2data2ptr' in m:\n",
      "    955                     valid_idx = torch.where(m['lbl2data2ptr'])[0]\n",
      "\n",
      "ipdb> meta_lw\n",
      "[0.15, 0.15]\n",
      "ipdb> n\n",
      "> /home/aiscuser/scratch/Projects/xcai/xcai/models/MMM0XX.py(954)forward()\n",
      "    952 \n",
      "    953             for m,m_lw in zip(meta_inputs.values(), meta_lw):\n",
      "--> 954                 if 'lbl2data2ptr' in m:\n",
      "    955                     valid_idx = torch.where(m['lbl2data2ptr'])[0]\n",
      "    956                     if len(valid_idx) > 0:\n",
      "\n",
      "ipdb> n\n",
      "> /home/aiscuser/scratch/Projects/xcai/xcai/models/MMM0XX.py(955)forward()\n",
      "    953             for m,m_lw in zip(meta_inputs.values(), meta_lw):\n",
      "    954                 if 'lbl2data2ptr' in m:\n",
      "--> 955                     valid_idx = torch.where(m['lbl2data2ptr'])[0]\n",
      "    956                     if len(valid_idx) > 0:\n",
      "    957                         o, rep = self.get_representation(m['input_ids'], m['attention_mask'])\n",
      "\n",
      "ipdb> m.keys()\n",
      "dict_keys(['pdata2ptr', 'data2ptr', 'pidx', 'idx', 'input_ids', 'attention_mask', 'plbl2data2ptr', 'lbl2data2ptr'])\n",
      "ipdb> n\n",
      "> /home/aiscuser/scratch/Projects/xcai/xcai/models/MMM0XX.py(956)forward()\n",
      "    954                 if 'lbl2data2ptr' in m:\n",
      "    955                     valid_idx = torch.where(m['lbl2data2ptr'])[0]\n",
      "--> 956                     if len(valid_idx) > 0:\n",
      "    957                         o, rep = self.get_representation(m['input_ids'], m['attention_mask'])\n",
      "    958                         m_lml = self.gen_lfn(lbl2data_logits[valid_idx], m['input_ids'], m['lbl2data2ptr'][valid_idx], **kwargs)\n",
      "\n",
      "ipdb> n\n",
      "> /home/aiscuser/scratch/Projects/xcai/xcai/models/MMM0XX.py(957)forward()\n",
      "    955                     valid_idx = torch.where(m['lbl2data2ptr'])[0]\n",
      "    956                     if len(valid_idx) > 0:\n",
      "--> 957                         o, rep = self.get_representation(m['input_ids'], m['attention_mask'])\n",
      "    958                         m_lml = self.gen_lfn(lbl2data_logits[valid_idx], m['input_ids'], m['lbl2data2ptr'][valid_idx], **kwargs)\n",
      "    959                         m_drl = self.rep_lfn(lbl2data_repr[valid_idx], rep, m['lbl2data2ptr'][valid_idx], m['idx'], \n",
      "\n",
      "ipdb> \n",
      "> /home/aiscuser/scratch/Projects/xcai/xcai/models/MMM0XX.py(958)forward()\n",
      "    956                     if len(valid_idx) > 0:\n",
      "    957                         o, rep = self.get_representation(m['input_ids'], m['attention_mask'])\n",
      "--> 958                         m_lml = self.gen_lfn(lbl2data_logits[valid_idx], m['input_ids'], m['lbl2data2ptr'][valid_idx], **kwargs)\n",
      "    959                         m_drl = self.rep_lfn(lbl2data_repr[valid_idx], rep, m['lbl2data2ptr'][valid_idx], m['idx'], \n",
      "    960                                              m['plbl2data2ptr'][valid_idx], m['pidx'], **kwargs)\n",
      "\n",
      "ipdb> \n",
      "> /home/aiscuser/scratch/Projects/xcai/xcai/models/MMM0XX.py(959)forward()\n",
      "    957                         o, rep = self.get_representation(m['input_ids'], m['attention_mask'])\n",
      "    958                         m_lml = self.gen_lfn(lbl2data_logits[valid_idx], m['input_ids'], m['lbl2data2ptr'][valid_idx], **kwargs)\n",
      "--> 959                         m_drl = self.rep_lfn(lbl2data_repr[valid_idx], rep, m['lbl2data2ptr'][valid_idx], m['idx'], \n",
      "    960                                              m['plbl2data2ptr'][valid_idx], m['pidx'], **kwargs)\n",
      "    961                         loss += m_lw * (m_drl + self.lw* m_lml)\n",
      "\n",
      "ipdb> \n",
      "> /home/aiscuser/scratch/Projects/xcai/xcai/models/MMM0XX.py(960)forward()\n",
      "    958                         m_lml = self.gen_lfn(lbl2data_logits[valid_idx], m['input_ids'], m['lbl2data2ptr'][valid_idx], **kwargs)\n",
      "    959                         m_drl = self.rep_lfn(lbl2data_repr[valid_idx], rep, m['lbl2data2ptr'][valid_idx], m['idx'], \n",
      "--> 960                                              m['plbl2data2ptr'][valid_idx], m['pidx'], **kwargs)\n",
      "    961                         loss += m_lw * (m_drl + self.lw* m_lml)\n",
      "    962 \n",
      "\n",
      "ipdb> \n",
      "> /home/aiscuser/scratch/Projects/xcai/xcai/models/MMM0XX.py(959)forward()\n",
      "    957                         o, rep = self.get_representation(m['input_ids'], m['attention_mask'])\n",
      "    958                         m_lml = self.gen_lfn(lbl2data_logits[valid_idx], m['input_ids'], m['lbl2data2ptr'][valid_idx], **kwargs)\n",
      "--> 959                         m_drl = self.rep_lfn(lbl2data_repr[valid_idx], rep, m['lbl2data2ptr'][valid_idx], m['idx'], \n",
      "    960                                              m['plbl2data2ptr'][valid_idx], m['pidx'], **kwargs)\n",
      "    961                         loss += m_lw * (m_drl + self.lw* m_lml)\n",
      "\n",
      "ipdb> \n",
      "> /home/aiscuser/scratch/Projects/xcai/xcai/models/MMM0XX.py(960)forward()\n",
      "    958                         m_lml = self.gen_lfn(lbl2data_logits[valid_idx], m['input_ids'], m['lbl2data2ptr'][valid_idx], **kwargs)\n",
      "    959                         m_drl = self.rep_lfn(lbl2data_repr[valid_idx], rep, m['lbl2data2ptr'][valid_idx], m['idx'], \n",
      "--> 960                                              m['plbl2data2ptr'][valid_idx], m['pidx'], **kwargs)\n",
      "    961                         loss += m_lw * (m_drl + self.lw* m_lml)\n",
      "    962 \n",
      "\n",
      "ipdb> \n",
      "> /home/aiscuser/scratch/Projects/xcai/xcai/models/MMM0XX.py(959)forward()\n",
      "    957                         o, rep = self.get_representation(m['input_ids'], m['attention_mask'])\n",
      "    958                         m_lml = self.gen_lfn(lbl2data_logits[valid_idx], m['input_ids'], m['lbl2data2ptr'][valid_idx], **kwargs)\n",
      "--> 959                         m_drl = self.rep_lfn(lbl2data_repr[valid_idx], rep, m['lbl2data2ptr'][valid_idx], m['idx'], \n",
      "    960                                              m['plbl2data2ptr'][valid_idx], m['pidx'], **kwargs)\n",
      "    961                         loss += m_lw * (m_drl + self.lw* m_lml)\n",
      "\n",
      "ipdb> \n",
      "> /home/aiscuser/scratch/Projects/xcai/xcai/models/MMM0XX.py(961)forward()\n",
      "    959                         m_drl = self.rep_lfn(lbl2data_repr[valid_idx], rep, m['lbl2data2ptr'][valid_idx], m['idx'], \n",
      "    960                                              m['plbl2data2ptr'][valid_idx], m['pidx'], **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> 961                         loss += m_lw * (m_drl + self.lw* m_lml)\n",
      "    962 \n",
      "    963                 elif 'data2ptr' in m:\n",
      "\n",
      "ipdb> \n",
      "> /home/aiscuser/scratch/Projects/xcai/xcai/models/MMM0XX.py(953)forward()\n",
      "    951                 meta_lw = self.m_lw\n",
      "    952 \n",
      "--> 953             for m,m_lw in zip(meta_inputs.values(), meta_lw):\n",
      "    954                 if 'lbl2data2ptr' in m:\n",
      "    955                     valid_idx = torch.where(m['lbl2data2ptr'])[0]\n",
      "\n",
      "ipdb> \n",
      "> /home/aiscuser/scratch/Projects/xcai/xcai/models/MMM0XX.py(954)forward()\n",
      "    952 \n",
      "    953             for m,m_lw in zip(meta_inputs.values(), meta_lw):\n",
      "--> 954                 if 'lbl2data2ptr' in m:\n",
      "    955                     valid_idx = torch.where(m['lbl2data2ptr'])[0]\n",
      "    956                     if len(valid_idx) > 0:\n",
      "\n",
      "ipdb> \n",
      "> /home/aiscuser/scratch/Projects/xcai/xcai/models/MMM0XX.py(963)forward()\n",
      "    961                         loss += m_lw * (m_drl + self.lw* m_lml)\n",
      "    962 \n",
      "--> 963                 elif 'data2ptr' in m:\n",
      "    964                     valid_idx = torch.where(m['data2ptr'])[0]\n",
      "    965                     if len(valid_idx) > 0:\n",
      "\n",
      "ipdb> \n",
      "> /home/aiscuser/scratch/Projects/xcai/xcai/models/MMM0XX.py(964)forward()\n",
      "    962 \n",
      "    963                 elif 'data2ptr' in m:\n",
      "--> 964                     valid_idx = torch.where(m['data2ptr'])[0]\n",
      "    965                     if len(valid_idx) > 0:\n",
      "    966                         o, rep = self.get_representation(m['input_ids'], m['attention_mask'])\n",
      "\n",
      "ipdb> \n",
      "> /home/aiscuser/scratch/Projects/xcai/xcai/models/MMM0XX.py(965)forward()\n",
      "    963                 elif 'data2ptr' in m:\n",
      "    964                     valid_idx = torch.where(m['data2ptr'])[0]\n",
      "--> 965                     if len(valid_idx) > 0:\n",
      "    966                         o, rep = self.get_representation(m['input_ids'], m['attention_mask'])\n",
      "    967                         m_lml = self.gen_lfn(data_logits[valid_idx], m['input_ids'], m['data2ptr'][valid_idx], **kwargs)\n",
      "\n",
      "ipdb> n\n",
      "> /home/aiscuser/scratch/Projects/xcai/xcai/models/MMM0XX.py(966)forward()\n",
      "    964                     valid_idx = torch.where(m['data2ptr'])[0]\n",
      "    965                     if len(valid_idx) > 0:\n",
      "--> 966                         o, rep = self.get_representation(m['input_ids'], m['attention_mask'])\n",
      "    967                         m_lml = self.gen_lfn(data_logits[valid_idx], m['input_ids'], m['data2ptr'][valid_idx], **kwargs)\n",
      "    968                         m_drl = self.rep_lfn(data_repr[valid_idx], rep, m['data2ptr'][valid_idx], m['idx'], \n",
      "\n",
      "ipdb> n\n",
      "> /home/aiscuser/scratch/Projects/xcai/xcai/models/MMM0XX.py(967)forward()\n",
      "    965                     if len(valid_idx) > 0:\n",
      "    966                         o, rep = self.get_representation(m['input_ids'], m['attention_mask'])\n",
      "--> 967                         m_lml = self.gen_lfn(data_logits[valid_idx], m['input_ids'], m['data2ptr'][valid_idx], **kwargs)ipdb> \n",
      "\n",
      "    968                         m_drl = self.rep_lfn(data_repr[valid_idx], rep, m['data2ptr'][valid_idx], m['idx'], \n",
      "    969                                              m['pdata2ptr'][valid_idx], m['pidx'], **kwargs)\n",
      "\n",
      "> /home/aiscuser/scratch/Projects/xcai/xcai/models/MMM0XX.py(968)forward()\n",
      "    966                         o, rep = self.get_representation(m['input_ids'], m['attention_mask'])\n",
      "    967                         m_lml = self.gen_lfn(data_logits[valid_idx], m['input_ids'], m['data2ptr'][valid_idx], **kwargs)\n",
      "--> 968                         m_drl = self.rep_lfn(data_repr[valid_idx], rep, m['data2ptr'][valid_idx], m['idx'], \n",
      "    969                                              m['pdata2ptr'][valid_idx], m['pidx'], **kwargs)\n",
      "    970                         loss += m_lw * (m_drl + self.lw*m_lml)\n",
      "\n",
      "ipdb> n\n",
      "> /home/aiscuser/scratch/Projects/xcai/xcai/models/MMM0XX.py(969)forward()\n",
      "    967                         m_lml = self.gen_lfn(data_logits[valid_idx], m['input_ids'], m['data2ptr'][valid_idx], **kwargs)\n",
      "    968                         m_drl = self.rep_lfn(data_repr[valid_idx], rep, m['data2ptr'][valid_idx], m['idx'], \n",
      "--> 969                                              m['pdata2ptr'][valid_idx], m['pidx'], **kwargs)\n",
      "    970                         loss += m_lw * (m_drl + self.lw*m_lml)\n",
      "    971 \n",
      "\n",
      "ipdb> n\n",
      "> /home/aiscuser/scratch/Projects/xcai/xcai/models/MMM0XX.py(968)forward()\n",
      "    966                         o, rep = self.get_representation(m['input_ids'], m['attention_mask'])\n",
      "    967                         m_lml = self.gen_lfn(data_logits[valid_idx], m['input_ids'], m['data2ptr'][valid_idx], **kwargs)\n",
      "--> 968                         m_drl = self.rep_lfn(data_repr[valid_idx], rep, m['data2ptr'][valid_idx], m['idx'], \n",
      "    969                                              m['pdata2ptr'][valid_idx], m['pidx'], **kwargs)\n",
      "    970                         loss += m_lw * (m_drl + self.lw*m_lml)\n",
      "\n",
      "ipdb> \n",
      "> /home/aiscuser/scratch/Projects/xcai/xcai/models/MMM0XX.py(969)forward()\n",
      "    967                         m_lml = self.gen_lfn(data_logits[valid_idx], m['input_ids'], m['data2ptr'][valid_idx], **kwargs)\n",
      "    968                         m_drl = self.rep_lfn(data_repr[valid_idx], rep, m['data2ptr'][valid_idx], m['idx'], \n",
      "--> 969                                              m['pdata2ptr'][valid_idx], m['pidx'], **kwargs)\n",
      "    970                         loss += m_lw * (m_drl + self.lw*m_lml)\n",
      "    971 \n",
      "\n",
      "ipdb> \n",
      "> /home/aiscuser/scratch/Projects/xcai/xcai/models/MMM0XX.py(968)forward()\n",
      "    966                         o, rep = self.get_representation(m['input_ids'], m['attention_mask'])\n",
      "    967                         m_lml = self.gen_lfn(data_logits[valid_idx], m['input_ids'], m['data2ptr'][valid_idx], **kwargs)\n",
      "--> 968                         m_drl = self.rep_lfn(data_repr[valid_idx], rep, m['data2ptr'][valid_idx], m['idx'], \n",
      "    969                                              m['pdata2ptr'][valid_idx], m['pidx'], **kwargs)\n",
      "    970                         loss += m_lw * (m_drl + self.lw*m_lml)\n",
      "\n",
      "ipdb> \n",
      "> /home/aiscuser/scratch/Projects/xcai/xcai/models/MMM0XX.py(970)forward()\n",
      "    968                         m_drl = self.rep_lfn(data_repr[valid_idx], rep, m['data2ptr'][valid_idx], m['idx'], \n",
      "    969                                              m['pdata2ptr'][valid_idx], m['pidx'], **kwargs)\n",
      "--> 970                         loss += m_lw * (m_drl + self.lw*m_lml)\n",
      "    971 \n",
      "    972                 else: raise ValueError('Invalid metadata input arguments.')\n",
      "\n",
      "ipdb> \n",
      "> /home/aiscuser/scratch/Projects/xcai/xcai/models/MMM0XX.py(953)forward()\n",
      "    951                 meta_lw = self.m_lw\n",
      "    952 \n",
      "--> 953             for m,m_lw in zip(meta_inputs.values(), meta_lw):\n",
      "    954                 if 'lbl2data2ptr' in m:\n",
      "    955                     valid_idx = torch.where(m['lbl2data2ptr'])[0]\n",
      "\n",
      "ipdb> \n",
      "> /home/aiscuser/scratch/Projects/xcai/xcai/models/MMM0XX.py(974)forward()\n",
      "    972                 else: raise ValueError('Invalid metadata input arguments.')\n",
      "    973 \n",
      "--> 974         if not return_dict:\n",
      "    975             o = (data_logits,data_repr,lbl2data_repr) + data_o[2:]\n",
      "    976             return ((loss,lm_loss,dr_loss) + o) if loss is not None else o\n",
      "\n",
      "ipdb> \n",
      "> /home/aiscuser/scratch/Projects/xcai/xcai/models/MMM0XX.py(978)forward()\n",
      "    976             return ((loss,lm_loss,dr_loss) + o) if loss is not None else o\n",
      "    977 \n",
      "--> 978         return XCModelOutput(\n",
      "    979             loss=loss,\n",
      "    980             lm_loss=lm_loss,\n",
      "\n",
      "ipdb> \n",
      "> /home/aiscuser/scratch/Projects/xcai/xcai/models/MMM0XX.py(979)forward()\n",
      "    977 \n",
      "    978         return XCModelOutput(\n",
      "--> 979             loss=loss,\n",
      "    980             lm_loss=lm_loss,\n",
      "    981             dr_loss=dr_loss,\n",
      "\n",
      "ipdb> \n",
      "> /home/aiscuser/scratch/Projects/xcai/xcai/models/MMM0XX.py(980)forward()\n",
      "    978         return XCModelOutput(\n",
      "    979             loss=loss,\n",
      "--> 980             lm_loss=lm_loss,\n",
      "    981             dr_loss=dr_loss,\n",
      "    982             logits=data_logits,\n",
      "\n",
      "ipdb> c\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "Caught KeyError in replica 1 on device 1.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/envs/ptca/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py\", line 64, in _worker\n    output = module(*input, **kwargs)\n  File \"/opt/conda/envs/ptca/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/aiscuser/scratch/Projects/xcai/xcai/models/MMM0XX.py\", line 931, in forward\n    import pdb; pdb.set_trace()\n  File \"/opt/.singularity/lib/python3.9/site-packages/IPython/core/debugger.py\", line 1099, in set_trace\n    Pdb().set_trace(frame or sys._getframe().f_back)\n  File \"/opt/.singularity/lib/python3.9/site-packages/IPython/core/debugger.py\", line 401, in set_trace\n    return super().set_trace(frame)\n  File \"/opt/conda/envs/ptca/lib/python3.9/bdb.py\", line 328, in set_trace\n    self.reset()\n  File \"/opt/conda/envs/ptca/lib/python3.9/pdb.py\", line 197, in reset\n    bdb.Bdb.reset(self)\n  File \"/opt/conda/envs/ptca/lib/python3.9/bdb.py\", line 57, in reset\n    linecache.checkcache()\n  File \"/opt/.singularity/lib/python3.9/site-packages/IPython/core/compilerop.py\", line 185, in check_linecache_ipython\n    linecache._checkcache_ori(*args)\n  File \"/opt/conda/envs/ptca/lib/python3.9/linecache.py\", line 64, in checkcache\n    entry = cache[filename]\nKeyError: '/tmp/ipykernel_1810131/869285730.py'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1810131/1093534927.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/ptca/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1883\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1884\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1885\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1886\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1887\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/scratch/Projects/xcai/xcai/learner.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m                 \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m             if (\n",
      "\u001b[0;32m/opt/conda/envs/ptca/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3237\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3238\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3240\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/ptca/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3262\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3263\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3264\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3265\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3266\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/ptca/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/ptca/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/ptca/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/ptca/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/ptca/lib/python3.9/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: Caught KeyError in replica 1 on device 1.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/envs/ptca/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py\", line 64, in _worker\n    output = module(*input, **kwargs)\n  File \"/opt/conda/envs/ptca/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/aiscuser/scratch/Projects/xcai/xcai/models/MMM0XX.py\", line 931, in forward\n    import pdb; pdb.set_trace()\n  File \"/opt/.singularity/lib/python3.9/site-packages/IPython/core/debugger.py\", line 1099, in set_trace\n    Pdb().set_trace(frame or sys._getframe().f_back)\n  File \"/opt/.singularity/lib/python3.9/site-packages/IPython/core/debugger.py\", line 401, in set_trace\n    return super().set_trace(frame)\n  File \"/opt/conda/envs/ptca/lib/python3.9/bdb.py\", line 328, in set_trace\n    self.reset()\n  File \"/opt/conda/envs/ptca/lib/python3.9/pdb.py\", line 197, in reset\n    bdb.Bdb.reset(self)\n  File \"/opt/conda/envs/ptca/lib/python3.9/bdb.py\", line 57, in reset\n    linecache.checkcache()\n  File \"/opt/.singularity/lib/python3.9/site-packages/IPython/core/compilerop.py\", line 185, in check_linecache_ipython\n    linecache._checkcache_ori(*args)\n  File \"/opt/conda/envs/ptca/lib/python3.9/linecache.py\", line 64, in checkcache\n    entry = cache[filename]\nKeyError: '/tmp/ipykernel_1810131/869285730.py'\n"
     ]
    }
   ],
   "source": [
    "learn.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc60dbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cd155e-912d-4780-b60d-b7c6749b30b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "if __name__ == '__main__':\n",
    "    mp.freeze_support()\n",
    "    learn.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0c09e4-4a84-4e72-8d93-9477b1db3ef3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
