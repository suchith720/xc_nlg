# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/16-ngame-training-pipeline-with-clustering.ipynb.

# %% auto 0
__all__ = ['block', 'args', 'metric', 'model', 'learn']

# %% ../nbs/16-ngame-training-pipeline-with-clustering.ipynb 4
import os,torch, torch.multiprocessing as mp
from xcai.basics import *
from xcai.models.MMM00X import DBT012

# %% ../nbs/16-ngame-training-pipeline-with-clustering.ipynb 6
os.environ['WANDB_PROJECT']='xc-nlg_16-ngame-training-pipeline-with-clustering-3'

# %% ../nbs/16-ngame-training-pipeline-with-clustering.ipynb 7
block = XCBlock.from_cfg('/home/aiscuser/scratch/datasets', 'data', valid_pct=0.001, tfm='ng', 
                         tokenizer='sentence-transformers/msmarco-distilbert-base-v4')

# %% ../nbs/16-ngame-training-pipeline-with-clustering.ipynb 8
args = XCLearningArguments(
    output_dir='/home/aiscuser/outputs/16-ngame-training-pipeline-with-clustering-3',
    logging_first_step=True,
    per_device_train_batch_size=1024,
    per_device_eval_batch_size=64,
    representation_num_beams=200,
    representation_accumulation_steps=100,
    save_strategy="steps",
    evaluation_strategy='steps',
    eval_steps=100,
    save_steps=100,
    save_total_limit=5,
    num_train_epochs=50,
    predict_with_representation=True,
    label_names=['plbl2data_idx', 'plbl2data_data2ptr'],
    target_indices_key='plbl2data_idx',
    target_pointer_key='plbl2data_data2ptr',
    adam_epsilon=1e-6,
    warmup_steps=100,
    weight_decay=0.01,
    learning_rate=2e-4,
    group_by_cluster=True,
    num_clustering_warmup_epochs=1,
    num_cluster_update_epochs=1,
    clustering_type='EXPO',
    minimum_cluster_size=1,
)

# %% ../nbs/16-ngame-training-pipeline-with-clustering.ipynb 9
metric = PrecRecl(block.n_lbl, block.test.data_lbl_filterer, prop=block.train.dset.data.data_lbl,
                  pk=10, rk=200, rep_pk=[1, 3, 5, 10], rep_rk=[10, 100, 200])

# %% ../nbs/16-ngame-training-pipeline-with-clustering.ipynb 10
model = DBT012.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', margin=0.3, tau=0.1, 
                               apply_softmax=True)

# %% ../nbs/16-ngame-training-pipeline-with-clustering.ipynb 12
learn = XCLearner(
    model=model, 
    args=args,
    train_dataset=block.train.dset,
    eval_dataset=block.test.dset,
    data_collator=block.collator,
    compute_metrics=metric,
    
)

# %% ../nbs/16-ngame-training-pipeline-with-clustering.ipynb 14
if __name__ == '__main__':
    mp.freeze_support()
    learn.train()
