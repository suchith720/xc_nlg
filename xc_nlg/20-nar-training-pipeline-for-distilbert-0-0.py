# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/20-nar-training-pipeline-for-distilbert.ipynb.

# %% auto 0
__all__ = ['block', 'args', 'output_dir', 'mname', 'metric', 'model', 'trie', 'learn', 'o', 'pred_dir']

# %% ../nbs/20-nar-training-pipeline-for-distilbert.ipynb 4
import os, torch, torch.nn.functional as F, pickle
from tqdm.auto import tqdm
from xcai.basics import *
from xcai.models.MMM0XX import DBT007
from xcai.transform import TriePruneInputIdsTfm

# %% ../nbs/20-nar-training-pipeline-for-distilbert.ipynb 10
os.environ['WANDB_MODE'] = 'disabled'

# %% ../nbs/20-nar-training-pipeline-for-distilbert.ipynb 11
os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'
os.environ['WANDB_PROJECT']='xc-nlg_20-nar-training-pipeline-for-distilbert'

# %% ../nbs/20-nar-training-pipeline-for-distilbert.ipynb 12
block = XCBlock.from_cfg('/home/aiscuser/scratch/datasets', 'data', tfm='xcnlg', tokenizer='distilbert-base-uncased', 
                         smp_features=[('lbl2data',1,2)])

# %% ../nbs/20-nar-training-pipeline-for-distilbert.ipynb 31
args = XCLearningArguments(
    output_dir='/home/scai/phd/aiz218323/scratch/outputs/20-nar-training-pipeline-for-distilbert-2-1',
    logging_first_step=True,
    per_device_train_batch_size=800,
    per_device_eval_batch_size=800,
    representation_num_beams=200,
    representation_accumulation_steps=100,
    save_strategy="steps",
    evaluation_strategy='steps',
    eval_steps=2000,
    save_steps=2000,
    save_total_limit=5,
    num_train_epochs=100,
    adam_epsilon=1e-8,
    warmup_steps=0,
    weight_decay=0.1,
    learning_rate=2e-4,
    generation_num_beams=10,
    generation_length_penalty=1.5,
    predict_with_generation=True,
    label_names=['lbl2data_idx'],
    target_indices_key='plbl2data_idx',
    target_pointer_key='plbl2data_data2ptr',
)

# %% ../nbs/20-nar-training-pipeline-for-distilbert.ipynb 40
output_dir = f"/home/scai/phd/aiz218323/scratch/outputs/{os.path.basename(args.output_dir)}"
mname = f'{output_dir}/{os.path.basename(get_best_model(output_dir))}'

# %% ../nbs/20-nar-training-pipeline-for-distilbert.ipynb 41
metric = PrecRecl(block.n_lbl, block.test.data_lbl_filterer, prop=block.train.dset.data.data_lbl,
                  pk=10, rk=200, rep_pk=[1, 3, 5, 10], rep_rk=[10, 100, 200])

# %% ../nbs/20-nar-training-pipeline-for-distilbert.ipynb 42
model = DBT007.from_pretrained(mname, tn_targ=10_000, ig_tok=0, #vocab_weights=tok_idf,
                               reduction='mean')

# %% ../nbs/20-nar-training-pipeline-for-distilbert.ipynb 43
trie = XCTrie.from_block(block)

# %% ../nbs/20-nar-training-pipeline-for-distilbert.ipynb 44
learn = XCLearner(
    model=model, 
    args=args,
    trie=trie,
    train_dataset=block.train.dset,
    eval_dataset=block.test.dset,
    data_collator=block.collator,
    compute_metrics=metric,
)

# %% ../nbs/20-nar-training-pipeline-for-distilbert.ipynb 45
o = learn.predict(block.test.dset)

# %% ../nbs/20-nar-training-pipeline-for-distilbert.ipynb 47
pred_dir = f"{mname}/predictions/"
os.makedirs(pred_dir, exist_ok=True)

with open(f'{pred_dir}/test_predictions.pkl', 'wb') as file: 
    pickle.dump(o, file)

# %% ../nbs/20-nar-training-pipeline-for-distilbert.ipynb 49
print(o.metrics)
