# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/23-1-ramen-fusion-prediction.ipynb.

# %% auto 0
__all__ = ['block', 'args', 'mname', 'bsz', 'model', 'trie', 'train_dset', 'metric', 'learn', 'pred_dir', 'test_dset',
           'get_best_model', 'XCEvalLoopOutput', 'XCPredictionOutput', 'get_output_sparse']

# %% ../nbs/23-1-ramen-fusion-prediction.ipynb 4
import os,torch, torch.multiprocessing as mp, pickle
from xcai.basics import *
from xcai.models.MMM0XX import DBT014

# %% ../nbs/23-1-ramen-fusion-prediction.ipynb 7
os.environ['CUDA_VISIBLE_DEVICES'] = '2,3'
os.environ['WANDB_PROJECT']='xc-nlg_28-2-ramen-fusion-prediction'

# %% ../nbs/23-1-ramen-fusion-prediction.ipynb 9
import re, json
from typing import Optional

def get_best_model(mdir:str, pat:Optional[str]=r'^checkpoint-(\d+)'):
    nm = sorted([int(re.match(pat, o).group(1)) for o in os.listdir(mdir) if re.match(pat, o)])[-1]
    fname = f'{mdir}/checkpoint-{nm}/trainer_state.json'
    with open(fname, 'r') as file: mname = json.load(file)['best_model_checkpoint']
    return f'{mdir}/checkpoint-{nm}' if mname is None else mname


# %% ../nbs/23-1-ramen-fusion-prediction.ipynb 11
block = XCBlock.from_cfg('/home/aiscuser/scratch/datasets', 'data', valid_pct=0.001, tfm='xcnlg', 
                         tokenizer='distilbert-base-uncased', smp_features=[('lbl2data',1,2)])

# %% ../nbs/23-1-ramen-fusion-prediction.ipynb 12
args = XCLearningArguments(
    output_dir='/home/aiscuser/scratch/Projects/xc_nlg/outputs/23-ramen-style-oak-training-pipeline-with-multitriplet-loss-with-clustering-2-6/',
    logging_first_step=True,
    per_device_train_batch_size=800,
    per_device_eval_batch_size=800,
    representation_num_beams=200,
    representation_accumulation_steps=100,
    save_strategy="steps",
    evaluation_strategy='steps',
    eval_steps=1000,
    save_steps=1000,
    save_total_limit=5,
    num_train_epochs=50,
    predict_with_representation=True,
    adam_epsilon=1e-6,
    warmup_steps=100,
    weight_decay=0.1,
    learning_rate=2e-4,
    generation_num_beams=10,
    generation_length_penalty=1.5,
    predict_with_generation=True,
    representation_search_type='BRUTEFORCE',
    group_by_cluster=True,
    num_clustering_warmup_epochs=2,
    num_cluster_update_epochs=2,
    num_cluster_size_update_epochs=4,
    clustering_type='EXPO',
    minimum_cluster_size=1,
    maximum_cluster_size=300,
    output_concatenation_weight=1.0,
    target_indices_key='plbl2data_idx',
    target_pointer_key='plbl2data_data2ptr',
)

# %% ../nbs/23-1-ramen-fusion-prediction.ipynb 13
mname = f'{args.output_dir}/{os.path.basename(get_best_model(args.output_dir))}'
bsz = max(args.per_device_train_batch_size, args.per_device_eval_batch_size)*torch.cuda.device_count()

model = DBT014.from_pretrained(mname, ig_tok=0, bsz=bsz, tn_targ=1000, margin=0.3, tau=0.1,
                               n_negatives=5, apply_softmax=True, lw=0.01, m_lw=0.1, meta_prefix='hlk',
                               init_drh=False)

# %% ../nbs/23-1-ramen-fusion-prediction.ipynb 15
trie = XCTrie.from_block(block)

# %% ../nbs/23-1-ramen-fusion-prediction.ipynb 16
from torch.utils.data import DataLoader, Dataset
from scipy import sparse
from typing import NamedTuple
import numpy as np, time

from fastcore.utils import *
from fastcore.meta import *
from fastcore.dispatch import *

from transformers.modeling_utils import unwrap_model
from transformers.trainer_utils import has_length, denumpify_detensorize, speed_metrics
from transformers.trainer_pt_utils import (
    find_batch_size, 
    nested_concat, nested_numpify, 
    IterableDatasetShard, 
    get_dataloader_sampler, 
    get_model_param_count,
    LengthGroupedSampler
)

# %% ../nbs/23-1-ramen-fusion-prediction.ipynb 17
class XCEvalLoopOutput(NamedTuple):
    pred_idx: Union[np.ndarray, Tuple[np.ndarray]]
    pred_ptr: Union[np.ndarray, Tuple[np.ndarray]]
    pred_score: Union[np.ndarray, Tuple[np.ndarray]]
    targ_idx: Optional[Union[np.ndarray, Tuple[np.ndarray]]]
    targ_ptr: Optional[Union[np.ndarray, Tuple[np.ndarray]]]
    gen_output: Optional[Dict]
    repr_output: Optional[Dict]
    metrics: Optional[Dict[str, float]]
    num_samples: Optional[int]

class XCPredictionOutput(NamedTuple):
    pred_idx: Union[np.ndarray, Tuple[np.ndarray]]
    pred_ptr: Union[np.ndarray, Tuple[np.ndarray]]
    pred_score: Optional[Union[np.ndarray, Tuple[np.ndarray]]]
    gen_output: Optional[Dict]
    repr_output: Optional[Dict]
    metrics: Optional[Dict[str, float]]
    num_samples: Optional[int]
    

# %% ../nbs/23-1-ramen-fusion-prediction.ipynb 18
@patch
def predict(self:XCLearner, test_dataset: Dataset, ignore_keys:Optional[List[str]]=None, 
            metric_key_prefix: str = "test", **gen_kwargs):
    
    gen_kwargs = gen_kwargs.copy()
    if gen_kwargs.get("length_penalty") is None and self.args.generation_length_penalty is not None:
        gen_kwargs["length_penalty"] = self.args.generation_length_penalty
    if gen_kwargs.get("gen_num_beams") is None and self.args.generation_num_beams is not None:
        gen_kwargs["gen_num_beams"] = self.args.generation_num_beams
    if gen_kwargs.get("repr_num_beams") is None and self.args.representation_num_beams is not None:
        gen_kwargs["repr_num_beams"] = self.args.representation_num_beams

    self.gather_function, self._gen_kwargs = self.accelerator.gather, gen_kwargs
    self._memory_tracker.start()

    if self._perform_representation(unwrap_model(self.model)) and not self.args.prediction_loss_only: 
        self._build_lbl_index(test_dataset)

    test_dataloader = self.get_test_dataloader(test_dataset)
    start_time = time.time()

    output = self.evaluation_loop(test_dataloader, description="Prediction", ignore_keys=ignore_keys, metric_key_prefix=metric_key_prefix)
    total_batch_size = self.args.eval_batch_size * self.args.world_size
    if f"{metric_key_prefix}_jit_compilation_time" in output.metrics:
        start_time += output.metrics[f"{metric_key_prefix}_jit_compilation_time"]
    output.metrics.update(
        speed_metrics(metric_key_prefix,start_time,num_samples=output.num_samples,num_steps=math.ceil(output.num_samples / total_batch_size),)
    )
    self.control = self.callback_handler.on_predict(self.args, self.state, self.control, output.metrics)
    self._memory_tracker.stop_and_update_metrics(output.metrics)
    return XCPredictionOutput(pred_idx=output.pred_idx, pred_ptr=output.pred_ptr, pred_score=output.pred_score, 
                              gen_output=output.gen_output, repr_output=output.repr_output, metrics=output.metrics, 
                              num_samples=output.num_samples)


# %% ../nbs/23-1-ramen-fusion-prediction.ipynb 19
@patch
def evaluation_loop(
    self:XCLearner,
    dataloader:DataLoader,
    description:str,
    prediction_loss_only:Optional[bool] = None,
    predict_with_generation:Optional[bool]=None,
    predict_with_representation:Optional[bool]=None,
    ignore_keys:Optional[List[str]] = None,
    metric_key_prefix:str="eval",
) -> XCEvalLoopOutput:
    args = self.args
    prediction_loss_only = prediction_loss_only if prediction_loss_only is not None else args.prediction_loss_only

    model = self._wrap_model(self.model, training=False, dataloader=dataloader)

    if len(self.accelerator._models) == 0 and model is self.model:
        model = self.accelerator.prepare(model) if self.is_deepspeed_enabled else self.accelerator.prepare_model(model, evaluation_mode=True)
        if self.is_fsdp_enabled: self.model = model
        if model is not self.model: self.model_wrapped = model
        if self.is_deepspeed_enabled: self.deepspeed = self.model_wrapped

    batch_size = self.args.eval_batch_size
    model.eval()
    self.callback_handler.eval_dataloader = dataloader
    eval_dataset = getattr(dataloader, "dataset", None)
    
    if args.past_index >= 0: self._past = None

    losses_host, all_losses = None, None
    host_output, all_output = {}, {}
    
    observed_num_examples = 0
    for step, inputs in enumerate(dataloader):
        observed_batch_size = find_batch_size(inputs)
        if observed_batch_size is not None:
            observed_num_examples += observed_batch_size
            if batch_size is None: batch_size = observed_batch_size
                
        loss, output = self.prediction_step(model, inputs, prediction_loss_only, predict_with_generation, predict_with_representation, ignore_keys=ignore_keys)
        
        if loss is not None:
            losses = self.gather_function((loss.repeat(batch_size)))
            losses_host = losses if losses_host is None else nested_concat(losses_host, losses, padding_index=-100)
        for k in output: host_output[k] = self._gather_host_output(output[k], host_output.get(k, None))
            
        self.control = self.callback_handler.on_prediction_step(args, self.state, self.control)
        
        if args.eval_accumulation_steps is not None and (step + 1) % args.eval_accumulation_steps == 0:
            if losses_host is not None: all_losses = losses_host if all_losses is None else nested_concat(all_losses, losses, padding_index=-100)
            for k in host_output: all_output[k], host_output[k] = self._gather_all_output(host_output[k], all_output.get(k, None)), None
    
    self.gather_function = self.accelerator.gather_for_metrics
    if args.past_index and hasattr(self, "_past"): delattr(self, "_past")

    if losses_host is not None: all_losses = losses_host if all_losses is None else nested_concat(all_losses, losses, padding_index=-100)
    for k in host_output: all_output[k], host_output[k] = self._gather_all_output(host_output[k], all_output.get(k, None)), None
        
    if has_length(eval_dataset): num_samples = len(eval_dataset)
    elif isinstance(eval_dataset, IterableDatasetShard) and getattr(eval_dataset, "num_examples", 0) > 0:
        num_samples = eval_dataset.num_examples
    else:
        if has_length(dataloader): num_samples = self.num_examples(dataloader)
        else: num_samples = observed_num_examples
    if num_samples == 0 and observed_num_examples > 0: num_samples = observed_num_examples
        
    gen_output, repr_output = None, None
    metric_input_keys = ['targ_idx', 'targ_ptr', 'pred_idx', 'pred_ptr', 'pred_score']
    if 'pred_idx_gen' in all_output and all_output['pred_idx_gen'] is not None:
        gen_output = {o:all_output[f'{o}_gen' if o.startswith('pred_') else o] for o in metric_input_keys}
    if 'pred_idx_repr' in all_output and all_output['pred_idx_repr'] is not None:
        repr_output = {o:all_output[f'{o}_repr' if o.startswith('pred_') else o] for o in metric_input_keys}
    

    if (self.compute_metrics is not None and 
        'targ_idx' in all_output and all_output['targ_idx'] is not None and 
        'pred_idx' in all_output and all_output['pred_idx'] is not None):
        
        metrics = self.compute_metrics(**{o:all_output[o] for o in metric_input_keys})
        if gen_output is not None:
            m = self.compute_metrics(**gen_output)
            metrics.update({f'{k}_GEN':v for k,v in m.items()})
        if repr_output is not None:
            m = self.compute_metrics(**repr_output)
            metrics.update({f'{k}_REPR':v for k,v in m.items()})      
    else: metrics = {}
        
    metrics = denumpify_detensorize(metrics)

    if all_losses is not None: metrics[f"{metric_key_prefix}_loss"] = all_losses.mean().item()
    if hasattr(self, "jit_compilation_time"): metrics[f"{metric_key_prefix}_jit_compilation_time"] = self.jit_compilation_time
        
    for key in list(metrics.keys()):
        if not key.startswith(f"{metric_key_prefix}_"): metrics[f"{metric_key_prefix}_{key}"] = metrics.pop(key)
    
    return XCEvalLoopOutput(pred_idx=all_output.get('pred_idx'), pred_ptr=all_output.get('pred_ptr'), 
                            pred_score=all_output.get('pred_score'),targ_idx=all_output.get('targ_idx'), 
                            targ_ptr=all_output.get('targ_ptr'), gen_output=gen_output, repr_output=repr_output,
                            metrics=metrics, num_samples=num_samples)
    

# %% ../nbs/23-1-ramen-fusion-prediction.ipynb 20
def get_output_sparse(pred_idx, pred_ptr, pred_score, targ_idx, targ_ptr, n_lbl):
    n_data = pred_ptr.shape[0]
    
    pred_ptr = torch.cat([torch.zeros((1,), dtype=torch.long), pred_ptr.cumsum(dim=0)])
    
    targ_ptr = torch.cat([torch.zeros((1,), dtype=torch.long), targ_ptr.cumsum(dim=0)])
    targ_score = torch.ones((targ_idx.shape[0],), dtype=torch.long)
    
    pred = sparse.csr_matrix((pred_score,pred_idx,pred_ptr), shape=(n_data, n_lbl))
    targ = sparse.csr_matrix((targ_score,targ_idx,targ_ptr), shape=(n_data, n_lbl))
    return pred, targ


# %% ../nbs/23-1-ramen-fusion-prediction.ipynb 22
train_dset = block.train.dset.sample(n=50_000, seed=50)
metric = PrecRecl(block.n_lbl, train_dset.data.data_lbl_filterer, prop=block.train.dset.data.data_lbl,
                  pk=10, rk=200, rep_pk=[1, 3, 5, 10], rep_rk=[10, 100, 200])

learn = XCLearner(
    model=model, 
    args=args,
    trie=trie,
    train_dataset=block.train.dset,
    eval_dataset=train_dset,
    data_collator=block.collator,
    compute_metrics=metric,
)

# %% ../nbs/23-1-ramen-fusion-prediction.ipynb 23
if __name__ == '__main__':
    mp.freeze_support()
    train_pred = learn.predict(train_dset)
    
display_metric(train_pred.metrics)

# %% ../nbs/23-1-ramen-fusion-prediction.ipynb 24
pred_dir = f'{mname}/predictions/'
os.makedirs(pred_dir, exist_ok=True)
with open(f'{pred_dir}/train_predictions.pkl', 'wb') as file: pickle.dump(train_pred, file)

# %% ../nbs/23-1-ramen-fusion-prediction.ipynb 26
test_dset = block.test.dset.sample(n=2000, seed=50)
metric = PrecRecl(block.n_lbl, block.test.data_lbl_filterer, prop=block.train.dset.data.data_lbl,
                  pk=10, rk=200, rep_pk=[1, 3, 5, 10], rep_rk=[10, 100, 200])

learn = XCLearner(
    model=model, 
    args=args,
    trie=trie,
    train_dataset=block.train.dset,
    eval_dataset=test_dset,
    data_collator=block.collator,
    compute_metrics=metric,
)

# %% ../nbs/23-1-ramen-fusion-prediction.ipynb 28
if __name__ == '__main__':
    mp.freeze_support()
    test_pred = learn.predict(block.test.dset)
    
display_metric(test_pred.metrics)

# %% ../nbs/23-1-ramen-fusion-prediction.ipynb 29
pred_dir = f'{mname}/predictions/'
os.makedirs(pred_dir, exist_ok=True)
with open(f'{pred_dir}/test_predictions.pkl', 'wb') as file: pickle.dump(test_pred, file)
