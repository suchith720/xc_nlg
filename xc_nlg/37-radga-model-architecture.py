# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/37-radga-model-architecture.ipynb.

# %% auto 0
__all__ = ['DBT018', 'DBT019']

# %% ../nbs/37-radga-model-architecture.ipynb 4
import os,torch, torch.multiprocessing as mp, pickle
from xcai.basics import *
from xcai.models.MMM0XX import DBT013

# %% ../nbs/37-radga-model-architecture.ipynb 17
from xcai.models.MMM0XX import Pooling, XCModelOutput

# %% ../nbs/37-radga-model-architecture.ipynb 18
class DBT018(DBT013):
    
    @delegates(DBT013.__init__)
    def __init__(self, config, aug_meta_prefix:Optional[List]=None, tn_meta:Optional[int]=None, *args, **kwargs):
        super().__init__(config, *args, **kwargs)
        store_attr('aug_meta_prefix')
        self.fuser = Fuser(config)
        self.o = torch.ones(tn_meta, dtype=torch.long, device=self.device) if tn_meta is not None else None
        
    def _get_meta_inputs(self, meta_prefix:Optional[str], **kwargs):
        inputs = {}
        for t in [o for o in kwargs if meta_prefix is not None and re.match(f'^[p]?{meta_prefix}.*', o)]:
            p,q = t.split('_', maxsplit=1)
            if t[0] == 'p': inputs.setdefault(p[1:], {})[f'p{q}'] = kwargs[t]
            else: inputs.setdefault(p, {})[q] = kwargs[t]
        return inputs
    
    def get_output(
        self, 
        input_ids:Optional[torch.Tensor]=None, 
        attention_mask:Optional[torch.Tensor]=None, 
        **kwargs
    ):
        o = self.distilbert(
            input_ids=input_ids,
            attention_mask=attention_mask,
            **kwargs
        )
        return o[0]
    
    def resize_meta(self, meta:torch.Tensor, mask:torch.Tensor, n_data2meta:torch.Tensor):
        bsz, dim, tn_data2meta = n_data2meta.shape[0], meta.shape[-1], meta.shape[0]
        self.o = self.o.to(meta.device)
        o = (
            torch.ones(tn_data2meta, dtype=torch.long, device=meta.device) 
            if self.o is None or len(self.o) < tn_data2meta else self.o[:tn_data2meta]
        )

        max_n_data2meta = n_data2meta.max()
        xn_data2meta = max_n_data2meta-n_data2meta+1

        data2meta_ptr = n_data2meta.cumsum(dim=0)-1
        r_data2meta = o.scatter(0, data2meta_ptr, xn_data2meta)

        xmeta,xmask = meta.repeat_interleave(r_data2meta, dim=0),mask.repeat_interleave(r_data2meta, dim=0)
        m = o.scatter(0, data2meta_ptr, 0).repeat_interleave(r_data2meta, dim=0).view(bsz, -1)
        m[:, -1] = 1; m = m.view(-1, 1)
        xmask *= m

        return xmeta.view(bsz, -1, dim),xmask.view(bsz, -1)
    
    def get_meta_fused_output(
        self, 
        input_ids:Optional[torch.Tensor]=None, 
        attention_mask:Optional[torch.Tensor]=None, 
        **kwargs
    ):
        data_h,data_mh = self.get_output(input_ids, attention_mask), None
        
        meta_inputs = self._get_meta_inputs(self.aug_meta_prefix, **kwargs)
        for m in meta_inputs.values():
            valid_idx = torch.where(m['data2ptr'] > 0)[0]
            dmh = data_h.clone()
            if len(valid_idx):
                meta_h = self.get_output(m['input_ids'], m['attention_mask'])
                meta_h, meta_attention_mask = self.resize_meta(meta_h, m['attention_mask'], m['data2ptr'][valid_idx])
                dmh[valid_idx] = self.fuser(data_h[valid_idx], meta_h, attention_mask[valid_idx], meta_attention_mask)[0]
            data_mh = dmh if data_mh is None else data_mh+dmh
            
        data_mh = data_h if data_mh is None else data_mh/len(meta_inputs)
        return (data_mh,)
        
    def get_meta_fused_genrep(
        self, 
        input_ids:Optional[torch.Tensor]=None, 
        attention_mask:Optional[torch.Tensor]=None, 
        **kwargs
    ):    
        o = self.get_meta_fused_output(
            input_ids=input_ids,
            attention_mask=attention_mask,
            **kwargs
        )
        torch.cuda.empty_cache()
        
        rep = self.dr_transform(o[0])
        rep = self.dr_layer_norm(rep)
        rep = self.dr_projector(rep)
        rep = F.normalize(Pooling.mean_pooling(rep, attention_mask), dim=1)
        
        logits = self.vocab_transform(o[0])
        logits = self.activation(logits)
        logits = self.vocab_layer_norm(logits)
        logits = self.vocab_projector(logits)
        return o,logits,rep
    
    def forward(
        self,
        data_input_ids:Optional[torch.Tensor]=None,
        data_attention_mask:Optional[torch.Tensor]=None,
        lbl2data_data2ptr:Optional[torch.Tensor]=None,
        lbl2data_idx:Optional[torch.Tensor]=None,
        lbl2data_input_ids:Optional[torch.Tensor]=None,
        lbl2data_attention_mask:Optional[torch.Tensor]=None,
        plbl2data_data2ptr:Optional[torch.Tensor]=None,
        plbl2data_idx:Optional[torch.Tensor]=None,
        output_attentions: Optional[bool] = None,
        output_hidden_states: Optional[bool] = None,
        return_dict: Optional[bool] = None,
        **kwargs
    ):  
        return_dict = return_dict if return_dict is not None else self.config.use_return_dict
        
        data_o, data_logits, data_repr = self.get_meta_fused_genrep(data_input_ids, data_attention_mask, **kwargs)
        
        loss = lm_loss = dr_loss = lbl2data_repr = None
        if lbl2data_input_ids is not None:
            lbl2data_o, lbl2data_repr = self.get_representation(lbl2data_input_ids, lbl2data_attention_mask)
            lm_loss = self.gen_lfn(data_logits, lbl2data_input_ids, lbl2data_data2ptr, **kwargs)
            dr_loss = self.rep_lfn(data_repr, lbl2data_repr, lbl2data_data2ptr, lbl2data_idx, 
                                   plbl2data_data2ptr, plbl2data_idx, **kwargs)
            loss = dr_loss + self.lw*lm_loss
            
        if not return_dict:
            o = (data_logits,data_repr,lbl2data_repr) + data_o[2:]
            return ((loss,lm_loss,dr_loss) + o) if loss is not None else o
        
        return XCModelOutput(
            loss=loss,
            lm_loss=lm_loss,
            dr_loss=dr_loss,
            logits=data_logits,
            data_repr=data_repr,
            lbl2data_repr=lbl2data_repr,
            data_hidden_states=data_o[0],
        )


# %% ../nbs/37-radga-model-architecture.ipynb 19
class DBT019(DBT018):
    
    @delegates(DBT018.__init__)
    def __init__(self, config, m_lw:Optional[float]=0.2, pred_meta_prefix:Optional[List]=None, *args, **kwargs):
        super().__init__(config, *args, **kwargs)
        store_attr('m_lw,pred_meta_prefix')
        
    def forward(
        self,
        data_input_ids:Optional[torch.Tensor]=None,
        data_attention_mask:Optional[torch.Tensor]=None,
        lbl2data_data2ptr:Optional[torch.Tensor]=None,
        lbl2data_idx:Optional[torch.Tensor]=None,
        lbl2data_input_ids:Optional[torch.Tensor]=None,
        lbl2data_attention_mask:Optional[torch.Tensor]=None,
        plbl2data_data2ptr:Optional[torch.Tensor]=None,
        plbl2data_idx:Optional[torch.Tensor]=None,
        output_attentions: Optional[bool] = None,
        output_hidden_states: Optional[bool] = None,
        return_dict: Optional[bool] = None,
        **kwargs
    ):
        return_dict = return_dict if return_dict is not None else self.config.use_return_dict
        
        data_o, data_logits, data_repr = self.get_meta_fused_genrep(data_input_ids, data_attention_mask, **kwargs)
        
        loss = lm_loss = dr_loss = lbl2data_repr = None
        if lbl2data_input_ids is not None:
            lbl2data_o, lbl2data_repr = self.get_representation(lbl2data_input_ids, lbl2data_attention_mask)
            lm_loss = self.gen_lfn(data_logits, lbl2data_input_ids, lbl2data_data2ptr, **kwargs)
            dr_loss = self.rep_lfn(data_repr, lbl2data_repr, lbl2data_data2ptr, lbl2data_idx, 
                                   plbl2data_data2ptr, plbl2data_idx, **kwargs)
            loss = dr_loss + self.lw*lm_loss
            
            meta_inputs = self._get_meta_inputs(self.pred_meta_prefix, **kwargs)
            m_lw = self.m_lw/len(meta_inputs)
            for m in meta_inputs.values():
                valid_idx = torch.where(m['data2ptr'])[0]
                if len(valid_idx) > 0:
                    o, rep = self.get_representation(m['input_ids'], m['attention_mask'])
                    m_lml = self.gen_lfn(data_logits[valid_idx], m['input_ids'], m['data2ptr'][valid_idx], **kwargs)
                    m_drl = self.rep_lfn(data_repr[valid_idx], rep, m['data2ptr'][valid_idx], m['idx'], 
                                         m['pdata2ptr'][valid_idx], m['pidx'], **kwargs)
                    loss += m_lw * (m_drl + self.lw*m_lml)
            
        if not return_dict:
            o = (data_logits,data_repr,lbl2data_repr) + data_o[2:]
            return ((loss,lm_loss,dr_loss) + o) if loss is not None else o
        
        return XCModelOutput(
            loss=loss,
            lm_loss=lm_loss,
            dr_loss=dr_loss,
            logits=data_logits,
            data_repr=data_repr,
            lbl2data_repr=lbl2data_repr,
            data_hidden_states=data_o[0],
        )
    
