# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/23-1-ramen-fusion-prediction.ipynb.

# %% auto 0
__all__ = ['block', 'args', 'mname', 'bsz', 'model', 'trie', 'train_dset', 'metric', 'learn', 'pred_dir', 'test_dset']

# %% ../nbs/23-1-ramen-fusion-prediction.ipynb 3
import os,torch, torch.multiprocessing as mp, pickle, numpy as np
from scipy import sparse
from xcai.basics import *
from xcai.models.MMM0XX import DBT014

# %% ../nbs/23-1-ramen-fusion-prediction.ipynb 5
os.environ['WANDB_MODE'] = 'disabled'

# %% ../nbs/23-1-ramen-fusion-prediction.ipynb 6
os.environ['CUDA_VISIBLE_DEVICES'] = '2,3'
os.environ['WANDB_PROJECT']='23-1-ramen-fusion-prediction-1-0'

# %% ../nbs/23-1-ramen-fusion-prediction.ipynb 8
block = XCBlock.from_cfg('/home/aiscuser/scratch/datasets', 'data', valid_pct=0.001, tfm='xcnlg', 
                         tokenizer='distilbert-base-uncased', smp_features=[('lbl2data',1,2)])

# %% ../nbs/23-1-ramen-fusion-prediction.ipynb 9
args = XCLearningArguments(
    output_dir='/home/aiscuser/scratch/Projects/xc_nlg/outputs/23-ramen-style-oak-training-pipeline-with-multitriplet-loss-with-clustering-2-6/',
    logging_first_step=True,
    per_device_train_batch_size=800,
    per_device_eval_batch_size=800,
    representation_num_beams=200,
    representation_accumulation_steps=100,
    predict_with_representation=True,
    generation_num_beams=10,
    generation_length_penalty=1.5,
    predict_with_generation=True,
    representation_search_type='BRUTEFORCE',
    target_indices_key='plbl2data_idx',
    target_pointer_key='plbl2data_data2ptr',
)

# %% ../nbs/23-1-ramen-fusion-prediction.ipynb 11
mname = f'{args.output_dir}/{os.path.basename(get_best_model(args.output_dir))}'
bsz = max(args.per_device_train_batch_size, args.per_device_eval_batch_size)*torch.cuda.device_count()

model = DBT014.from_pretrained(mname, ig_tok=0, bsz=bsz, tn_targ=1000, margin=0.3, tau=0.1,
                               n_negatives=5, apply_softmax=True, lw=0.01, m_lw=0.1, meta_prefix='hlk')

# %% ../nbs/23-1-ramen-fusion-prediction.ipynb 12
trie = XCTrie.from_block(block)

# %% ../nbs/23-1-ramen-fusion-prediction.ipynb 14
train_dset = block.train.dset.sample(n=50_000, seed=50)
metric = PrecRecl(block.n_lbl, train_dset.data.data_lbl_filterer, prop=block.train.dset.data.data_lbl,
                  pk=10, rk=200, rep_pk=[1, 3, 5, 10], rep_rk=[10, 100, 200])

learn = XCLearner(model=model, args=args, trie=trie, train_dataset=block.train.dset, eval_dataset=train_dset,
                  data_collator=block.collator, compute_metrics=metric)

#| export
if __name__ == '__main__':
    mp.freeze_support()
    train_pred = learn.predict(train_dset)
    
display_metric(train_pred.metrics)

# %% ../nbs/23-1-ramen-fusion-prediction.ipynb 15
pred_dir = f'{mname}/predictions/'
os.makedirs(pred_dir, exist_ok=True)
with open(f'{pred_dir}/train_predictions.pkl', 'wb') as file: pickle.dump(train_pred, file)

# %% ../nbs/23-1-ramen-fusion-prediction.ipynb 17
test_dset = block.test.dset.sample(n=2000, seed=50)
metric = PrecRecl(block.n_lbl, block.test.data_lbl_filterer, prop=block.train.dset.data.data_lbl,
                  pk=10, rk=200, rep_pk=[1, 3, 5, 10], rep_rk=[10, 100, 200])

learn = XCLearner(model=model, args=args, trie=trie, train_dataset=block.train.dset, eval_dataset=test_dset,
                  data_collator=block.collator, compute_metrics=metric)

if __name__ == '__main__':
    mp.freeze_support()
    test_pred = learn.predict(block.test.dset)
    
display_metric(test_pred.metrics)

# %% ../nbs/23-1-ramen-fusion-prediction.ipynb 18
pred_dir = f'{mname}/predictions/'
os.makedirs(pred_dir, exist_ok=True)
with open(f'{pred_dir}/test_predictions.pkl', 'wb') as file: pickle.dump(test_pred, file)
